2022-07-01 20:06:41.279968
epoch:1	train_loss:1.9570273160934448	train_acc:0.14285714285714285	test_acc:0.103	test_f1:0.026680481802875276
epoch:2	train_loss:1.9490718841552734	train_acc:0.15714285714285714	test_acc:0.103	test_f1:0.026680481802875276
epoch:3	train_loss:1.9430828094482422	train_acc:0.17142857142857143	test_acc:0.104	test_f1:0.028675136116152446
epoch:4	train_loss:1.9366384744644165	train_acc:0.16428571428571428	test_acc:0.107	test_f1:0.03444545730780918
epoch:5	train_loss:1.9306976795196533	train_acc:0.20714285714285716	test_acc:0.12	test_f1:0.05633336501599974
epoch:6	train_loss:1.9346448183059692	train_acc:0.2	test_acc:0.147	test_f1:0.09214048539083977
epoch:7	train_loss:1.9278202056884766	train_acc:0.20714285714285716	test_acc:0.158	test_f1:0.10900026479761422
epoch:8	train_loss:1.92672598361969	train_acc:0.22857142857142856	test_acc:0.2	test_f1:0.19463405812505408
epoch:9	train_loss:1.9168648719787598	train_acc:0.36428571428571427	test_acc:0.234	test_f1:0.19936092117436188
epoch:10	train_loss:1.9156723022460938	train_acc:0.3142857142857143	test_acc:0.277	test_f1:0.25121866378358193
epoch:11	train_loss:1.9076788425445557	train_acc:0.4142857142857143	test_acc:0.276	test_f1:0.25893608618725
epoch:12	train_loss:1.892330527305603	train_acc:0.5285714285714286	test_acc:0.258	test_f1:0.2462746148394457
epoch:13	train_loss:1.9026789665222168	train_acc:0.45714285714285713	test_acc:0.252	test_f1:0.2312278957037834
epoch:14	train_loss:1.895198106765747	train_acc:0.4142857142857143	test_acc:0.267	test_f1:0.24953252858224845
epoch:15	train_loss:1.8910969495773315	train_acc:0.4142857142857143	test_acc:0.279	test_f1:0.26250060273782233
epoch:16	train_loss:1.8844177722930908	train_acc:0.4928571428571429	test_acc:0.301	test_f1:0.29235018104871463
epoch:17	train_loss:1.8702994585037231	train_acc:0.5	test_acc:0.323	test_f1:0.31649643277599704
epoch:18	train_loss:1.8627498149871826	train_acc:0.5714285714285714	test_acc:0.345	test_f1:0.3452632424817537
epoch:19	train_loss:1.8629311323165894	train_acc:0.5428571428571428	test_acc:0.395	test_f1:0.399972555359584
epoch:20	train_loss:1.8474496603012085	train_acc:0.5714285714285714	test_acc:0.443	test_f1:0.44521086120458564
epoch:21	train_loss:1.8377456665039062	train_acc:0.6571428571428571	test_acc:0.483	test_f1:0.49617068355311017
epoch:22	train_loss:1.8417224884033203	train_acc:0.5357142857142857	test_acc:0.52	test_f1:0.5306636655417986
epoch:23	train_loss:1.8169242143630981	train_acc:0.65	test_acc:0.539	test_f1:0.549927913882621
epoch:24	train_loss:1.8236303329467773	train_acc:0.5714285714285714	test_acc:0.562	test_f1:0.5755617798369375
epoch:25	train_loss:1.80180025100708	train_acc:0.6214285714285714	test_acc:0.589	test_f1:0.6011854199773284
epoch:26	train_loss:1.7925939559936523	train_acc:0.6857142857142857	test_acc:0.611	test_f1:0.6210077295679232
epoch:27	train_loss:1.7927607297897339	train_acc:0.65	test_acc:0.641	test_f1:0.6463189528167589
epoch:28	train_loss:1.7749449014663696	train_acc:0.7571428571428571	test_acc:0.652	test_f1:0.6556838048629893
epoch:29	train_loss:1.7531238794326782	train_acc:0.6785714285714286	test_acc:0.687	test_f1:0.6854737927590916
epoch:30	train_loss:1.7584352493286133	train_acc:0.7142857142857143	test_acc:0.716	test_f1:0.7085281999190444
epoch:31	train_loss:1.7467862367630005	train_acc:0.7214285714285714	test_acc:0.731	test_f1:0.7234975286222461
epoch:32	train_loss:1.7282263040542603	train_acc:0.7857142857142857	test_acc:0.738	test_f1:0.7290383842426612
epoch:33	train_loss:1.7137019634246826	train_acc:0.7642857142857142	test_acc:0.732	test_f1:0.7207588890699478
epoch:34	train_loss:1.7067251205444336	train_acc:0.7785714285714286	test_acc:0.738	test_f1:0.7269017382589824
epoch:35	train_loss:1.6964659690856934	train_acc:0.8071428571428572	test_acc:0.733	test_f1:0.72433783662292
epoch:36	train_loss:1.6701942682266235	train_acc:0.8142857142857143	test_acc:0.728	test_f1:0.7225728106266202
epoch:37	train_loss:1.6641427278518677	train_acc:0.7785714285714286	test_acc:0.731	test_f1:0.7287481694499648
epoch:38	train_loss:1.6292681694030762	train_acc:0.8	test_acc:0.729	test_f1:0.7299715758074413
epoch:39	train_loss:1.615256428718567	train_acc:0.8357142857142857	test_acc:0.727	test_f1:0.7299776396594277
epoch:40	train_loss:1.5968551635742188	train_acc:0.7857142857142857	test_acc:0.728	test_f1:0.7333945346017595
epoch:41	train_loss:1.596757411956787	train_acc:0.7642857142857142	test_acc:0.729	test_f1:0.7354092248357437
epoch:42	train_loss:1.570706844329834	train_acc:0.8214285714285714	test_acc:0.73	test_f1:0.7368098599453302
epoch:43	train_loss:1.5412019491195679	train_acc:0.8071428571428572	test_acc:0.736	test_f1:0.7450493793089619
epoch:44	train_loss:1.5464619398117065	train_acc:0.7928571428571428	test_acc:0.739	test_f1:0.747383269949963
epoch:45	train_loss:1.5246779918670654	train_acc:0.7428571428571429	test_acc:0.747	test_f1:0.7526757217684329
epoch:46	train_loss:1.4867585897445679	train_acc:0.8214285714285714	test_acc:0.749	test_f1:0.753521532261199
epoch:47	train_loss:1.4657413959503174	train_acc:0.8642857142857143	test_acc:0.761	test_f1:0.7637396020692163
epoch:48	train_loss:1.4275614023208618	train_acc:0.8642857142857143	test_acc:0.767	test_f1:0.7666793779068728
epoch:49	train_loss:1.457791805267334	train_acc:0.8285714285714286	test_acc:0.773	test_f1:0.7710443035602947
epoch:50	train_loss:1.3882172107696533	train_acc:0.8571428571428571	test_acc:0.774	test_f1:0.7713959493461571
训练并测试结束，共训练50轮，总用时1.6131079196929932s
最佳正确率为:0.774,对应的macro_f1为:0.7713959493461571,对应的训练轮次为:50



2022-07-01 20:10:39.968354
epoch:1	train_loss:1.9728437662124634	train_acc:0.1357142857142857	test_acc:0.064	test_f1:0.01721818670971213
epoch:2	train_loss:1.9705816507339478	train_acc:0.1357142857142857	test_acc:0.064	test_f1:0.01721818670971213
epoch:3	train_loss:1.963960886001587	train_acc:0.14285714285714285	test_acc:0.064	test_f1:0.01721818670971213
epoch:4	train_loss:1.944273591041565	train_acc:0.14285714285714285	test_acc:0.064	test_f1:0.017201988979975814
epoch:5	train_loss:1.9450033903121948	train_acc:0.19285714285714287	test_acc:0.064	test_f1:0.017201988979975814
epoch:6	train_loss:1.9424540996551514	train_acc:0.15	test_acc:0.065	test_f1:0.019382688874214297
epoch:7	train_loss:1.9236162900924683	train_acc:0.19285714285714287	test_acc:0.066	test_f1:0.021530870396672983
epoch:8	train_loss:1.9274466037750244	train_acc:0.2	test_acc:0.066	test_f1:0.021530870396672983
epoch:9	train_loss:1.9271903038024902	train_acc:0.17142857142857143	test_acc:0.069	test_f1:0.026655319207861673
epoch:10	train_loss:1.922204852104187	train_acc:0.17857142857142858	test_acc:0.11	test_f1:0.06877003675033232
epoch:11	train_loss:1.9155399799346924	train_acc:0.2642857142857143	test_acc:0.289	test_f1:0.16894061480042666
epoch:12	train_loss:1.8929316997528076	train_acc:0.3142857142857143	test_acc:0.38	test_f1:0.20330437820900069
epoch:13	train_loss:1.8942286968231201	train_acc:0.3	test_acc:0.431	test_f1:0.2483107183378281
epoch:14	train_loss:1.896572232246399	train_acc:0.2714285714285714	test_acc:0.472	test_f1:0.30841160554662084
epoch:15	train_loss:1.8889188766479492	train_acc:0.35714285714285715	test_acc:0.518	test_f1:0.3778753887400823
epoch:16	train_loss:1.872245192527771	train_acc:0.44285714285714284	test_acc:0.623	test_f1:0.5300850521325071
epoch:17	train_loss:1.8770720958709717	train_acc:0.4642857142857143	test_acc:0.645	test_f1:0.5858489684296181
epoch:18	train_loss:1.864675521850586	train_acc:0.38571428571428573	test_acc:0.63	test_f1:0.5941313481964333
epoch:19	train_loss:1.8557491302490234	train_acc:0.5214285714285715	test_acc:0.573	test_f1:0.5506363974588971
epoch:20	train_loss:1.8467235565185547	train_acc:0.5142857142857142	test_acc:0.533	test_f1:0.5133100396356569
epoch:21	train_loss:1.8565828800201416	train_acc:0.4357142857142857	test_acc:0.522	test_f1:0.4984753381579409
epoch:22	train_loss:1.841667652130127	train_acc:0.4928571428571429	test_acc:0.515	test_f1:0.4875214380000745
epoch:23	train_loss:1.8328838348388672	train_acc:0.5285714285714286	test_acc:0.525	test_f1:0.4998972985571907
epoch:24	train_loss:1.8272881507873535	train_acc:0.5357142857142857	test_acc:0.554	test_f1:0.5364833606143905
epoch:25	train_loss:1.805285096168518	train_acc:0.6357142857142857	test_acc:0.582	test_f1:0.5825381631988759
epoch:26	train_loss:1.79958975315094	train_acc:0.55	test_acc:0.619	test_f1:0.6246434958163094
epoch:27	train_loss:1.792433261871338	train_acc:0.5928571428571429	test_acc:0.638	test_f1:0.6446445959738253
epoch:28	train_loss:1.7807716131210327	train_acc:0.6357142857142857	test_acc:0.665	test_f1:0.6837663513653617
epoch:29	train_loss:1.7850141525268555	train_acc:0.6142857142857143	test_acc:0.672	test_f1:0.6956988343714298
epoch:30	train_loss:1.7589221000671387	train_acc:0.6428571428571429	test_acc:0.671	test_f1:0.7012658792625077
epoch:31	train_loss:1.7605829238891602	train_acc:0.6428571428571429	test_acc:0.672	test_f1:0.7062692372537283
epoch:32	train_loss:1.7129067182540894	train_acc:0.7285714285714285	test_acc:0.672	test_f1:0.7031032275997617
epoch:33	train_loss:1.7129228115081787	train_acc:0.7214285714285714	test_acc:0.666	test_f1:0.6955951208831858
epoch:34	train_loss:1.710422396659851	train_acc:0.7714285714285715	test_acc:0.658	test_f1:0.6878509255114362
epoch:35	train_loss:1.7082489728927612	train_acc:0.7142857142857143	test_acc:0.652	test_f1:0.6838457769295229
epoch:36	train_loss:1.6821894645690918	train_acc:0.7571428571428571	test_acc:0.65	test_f1:0.682978713292262
epoch:37	train_loss:1.6746717691421509	train_acc:0.7857142857142857	test_acc:0.653	test_f1:0.6845035305384256
epoch:38	train_loss:1.6571290493011475	train_acc:0.7714285714285715	test_acc:0.661	test_f1:0.6875046604461991
epoch:39	train_loss:1.6166390180587769	train_acc:0.7785714285714286	test_acc:0.665	test_f1:0.6854417327356463
epoch:40	train_loss:1.6460132598876953	train_acc:0.7285714285714285	test_acc:0.678	test_f1:0.6964990955981888
epoch:41	train_loss:1.60714852809906	train_acc:0.7142857142857143	test_acc:0.69	test_f1:0.7049592971194859
epoch:42	train_loss:1.5797691345214844	train_acc:0.8	test_acc:0.706	test_f1:0.7227307699217489
epoch:43	train_loss:1.5693674087524414	train_acc:0.7642857142857142	test_acc:0.714	test_f1:0.7305069718456421
epoch:44	train_loss:1.5725550651550293	train_acc:0.7928571428571428	test_acc:0.724	test_f1:0.7383745623634873
epoch:45	train_loss:1.5424612760543823	train_acc:0.8	test_acc:0.728	test_f1:0.7392081742729444
epoch:46	train_loss:1.5416591167449951	train_acc:0.8071428571428572	test_acc:0.739	test_f1:0.7477219294919258
epoch:47	train_loss:1.5162806510925293	train_acc:0.8	test_acc:0.746	test_f1:0.7548569701793963
epoch:48	train_loss:1.5110911130905151	train_acc:0.7928571428571428	test_acc:0.761	test_f1:0.7653665904877457
epoch:49	train_loss:1.4893720149993896	train_acc:0.7857142857142857	test_acc:0.774	test_f1:0.7763551408450929
epoch:50	train_loss:1.4817357063293457	train_acc:0.7857142857142857	test_acc:0.783	test_f1:0.7804177192339316
训练并测试结束，共训练50轮，总用时1.5221621990203857s
最佳正确率为:0.783,对应的macro_f1为:0.7804177192339316,对应的训练轮次为:50



2022-07-01 20:10:46.859496
epoch:1	train_loss:1.9701151847839355	train_acc:0.15	test_acc:0.092	test_f1:0.02598318900064276
epoch:2	train_loss:1.9509248733520508	train_acc:0.17857142857142858	test_acc:0.11	test_f1:0.052720854600605535
epoch:3	train_loss:1.9578386545181274	train_acc:0.09285714285714286	test_acc:0.137	test_f1:0.0817160986652512
epoch:4	train_loss:1.9460538625717163	train_acc:0.16428571428571428	test_acc:0.164	test_f1:0.09987575635674896
epoch:5	train_loss:1.9432684183120728	train_acc:0.19285714285714287	test_acc:0.185	test_f1:0.11088329935327661
epoch:6	train_loss:1.9431873559951782	train_acc:0.2	test_acc:0.195	test_f1:0.11316756422293929
epoch:7	train_loss:1.932194471359253	train_acc:0.20714285714285716	test_acc:0.209	test_f1:0.10954589735930056
epoch:8	train_loss:1.9330949783325195	train_acc:0.20714285714285716	test_acc:0.244	test_f1:0.16414845867861297
epoch:9	train_loss:1.9230198860168457	train_acc:0.25	test_acc:0.325	test_f1:0.2611491502167876
epoch:10	train_loss:1.9101104736328125	train_acc:0.29285714285714287	test_acc:0.291	test_f1:0.22082470993507947
epoch:11	train_loss:1.9126571416854858	train_acc:0.2857142857142857	test_acc:0.276	test_f1:0.22238462225199476
epoch:12	train_loss:1.908168077468872	train_acc:0.3142857142857143	test_acc:0.265	test_f1:0.2229989093853284
epoch:13	train_loss:1.9005968570709229	train_acc:0.35714285714285715	test_acc:0.286	test_f1:0.25616389433302816
epoch:14	train_loss:1.8918596506118774	train_acc:0.4	test_acc:0.307	test_f1:0.27005362603123334
epoch:15	train_loss:1.8919708728790283	train_acc:0.35714285714285715	test_acc:0.363	test_f1:0.3074057781835671
epoch:16	train_loss:1.887731671333313	train_acc:0.39285714285714285	test_acc:0.447	test_f1:0.35337906837828426
epoch:17	train_loss:1.8910537958145142	train_acc:0.36428571428571427	test_acc:0.491	test_f1:0.3711240711205099
epoch:18	train_loss:1.8747056722640991	train_acc:0.42142857142857143	test_acc:0.523	test_f1:0.3890708328543245
epoch:19	train_loss:1.8700532913208008	train_acc:0.38571428571428573	test_acc:0.542	test_f1:0.39941738930027865
epoch:20	train_loss:1.8563432693481445	train_acc:0.40714285714285714	test_acc:0.557	test_f1:0.4125235411356046
epoch:21	train_loss:1.852632761001587	train_acc:0.45714285714285713	test_acc:0.563	test_f1:0.4217821522781359
epoch:22	train_loss:1.8487046957015991	train_acc:0.4857142857142857	test_acc:0.572	test_f1:0.4375503075556345
epoch:23	train_loss:1.8334581851959229	train_acc:0.5	test_acc:0.583	test_f1:0.4548191926157791
epoch:24	train_loss:1.8221482038497925	train_acc:0.5571428571428572	test_acc:0.596	test_f1:0.47722964372531923
epoch:25	train_loss:1.8127847909927368	train_acc:0.5785714285714286	test_acc:0.61	test_f1:0.5006552538833569
epoch:26	train_loss:1.815010666847229	train_acc:0.5428571428571428	test_acc:0.62	test_f1:0.5322063397654011
epoch:27	train_loss:1.8222978115081787	train_acc:0.4928571428571429	test_acc:0.63	test_f1:0.5659708041922497
epoch:28	train_loss:1.8115330934524536	train_acc:0.5642857142857143	test_acc:0.643	test_f1:0.6051300131589967
epoch:29	train_loss:1.791831374168396	train_acc:0.5857142857142857	test_acc:0.652	test_f1:0.6202376542634828
epoch:30	train_loss:1.776852011680603	train_acc:0.6428571428571429	test_acc:0.667	test_f1:0.640050322670651
epoch:31	train_loss:1.7647881507873535	train_acc:0.6285714285714286	test_acc:0.676	test_f1:0.6514511183076046
epoch:32	train_loss:1.747871994972229	train_acc:0.6857142857142857	test_acc:0.679	test_f1:0.6519970780218258
epoch:33	train_loss:1.7588145732879639	train_acc:0.7	test_acc:0.684	test_f1:0.6572100375556097
epoch:34	train_loss:1.7168222665786743	train_acc:0.7142857142857143	test_acc:0.689	test_f1:0.6616630129104715
epoch:35	train_loss:1.7054424285888672	train_acc:0.6214285714285714	test_acc:0.701	test_f1:0.6727120114538396
epoch:36	train_loss:1.7073651552200317	train_acc:0.6714285714285714	test_acc:0.699	test_f1:0.6696895183200484
epoch:37	train_loss:1.6980334520339966	train_acc:0.6642857142857143	test_acc:0.699	test_f1:0.6687535154481351
epoch:38	train_loss:1.6885613203048706	train_acc:0.6571428571428571	test_acc:0.699	test_f1:0.6681831778873119
epoch:39	train_loss:1.6585816144943237	train_acc:0.7071428571428572	test_acc:0.706	test_f1:0.6778148752719445
epoch:40	train_loss:1.6576855182647705	train_acc:0.6857142857142857	test_acc:0.717	test_f1:0.690254497265972
epoch:41	train_loss:1.66094970703125	train_acc:0.6714285714285714	test_acc:0.729	test_f1:0.7034206868102825
epoch:42	train_loss:1.6366462707519531	train_acc:0.6785714285714286	test_acc:0.739	test_f1:0.7139626007805254
epoch:43	train_loss:1.5978221893310547	train_acc:0.7071428571428572	test_acc:0.747	test_f1:0.7223715223441557
epoch:44	train_loss:1.6074695587158203	train_acc:0.7285714285714285	test_acc:0.753	test_f1:0.7310983478259754
epoch:45	train_loss:1.5813124179840088	train_acc:0.8071428571428572	test_acc:0.757	test_f1:0.7384503013768088
epoch:46	train_loss:1.5504930019378662	train_acc:0.7857142857142857	test_acc:0.763	test_f1:0.7466463157546598
epoch:47	train_loss:1.516457438468933	train_acc:0.8285714285714286	test_acc:0.764	test_f1:0.7500924939750934
epoch:48	train_loss:1.525219202041626	train_acc:0.7928571428571428	test_acc:0.766	test_f1:0.7520663026590473
epoch:49	train_loss:1.5049501657485962	train_acc:0.7714285714285715	test_acc:0.774	test_f1:0.7594570387032408
epoch:50	train_loss:1.467955231666565	train_acc:0.8642857142857143	test_acc:0.788	test_f1:0.7734855723039369
训练并测试结束，共训练50轮，总用时1.5250020027160645s
最佳正确率为:0.788,对应的macro_f1为:0.7734855723039369,对应的训练轮次为:50



2022-07-01 20:11:11.677323
epoch:1	train_loss:1.9620877504348755	train_acc:0.14285714285714285	test_acc:0.149	test_f1:0.03705085167226159
epoch:2	train_loss:1.9600238800048828	train_acc:0.15	test_acc:0.149	test_f1:0.03705085167226159
epoch:3	train_loss:1.9499790668487549	train_acc:0.17142857142857143	test_acc:0.15	test_f1:0.03926415101508859
epoch:4	train_loss:1.9473589658737183	train_acc:0.16428571428571428	test_acc:0.15	test_f1:0.03926415101508859
epoch:5	train_loss:1.9467333555221558	train_acc:0.15	test_acc:0.15	test_f1:0.03926415101508859
epoch:6	train_loss:1.9330884218215942	train_acc:0.18571428571428572	test_acc:0.15	test_f1:0.03926415101508859
epoch:7	train_loss:1.9420652389526367	train_acc:0.14285714285714285	test_acc:0.15	test_f1:0.03926415101508859
epoch:8	train_loss:1.9319061040878296	train_acc:0.19285714285714287	test_acc:0.151	test_f1:0.04144446079929952
epoch:9	train_loss:1.9245513677597046	train_acc:0.22857142857142856	test_acc:0.153	test_f1:0.04570907161013398
epoch:10	train_loss:1.9232720136642456	train_acc:0.2	test_acc:0.164	test_f1:0.08218707816054416
epoch:11	train_loss:1.910610556602478	train_acc:0.25	test_acc:0.194	test_f1:0.14490409871392038
epoch:12	train_loss:1.903897762298584	train_acc:0.30714285714285716	test_acc:0.24	test_f1:0.16760200235492226
epoch:13	train_loss:1.903777003288269	train_acc:0.32142857142857145	test_acc:0.268	test_f1:0.23126893101838397
epoch:14	train_loss:1.904716968536377	train_acc:0.34285714285714286	test_acc:0.292	test_f1:0.32066723727904656
epoch:15	train_loss:1.8985787630081177	train_acc:0.39285714285714285	test_acc:0.284	test_f1:0.33062968970774576
epoch:16	train_loss:1.895870327949524	train_acc:0.36428571428571427	test_acc:0.298	test_f1:0.3534361153072563
epoch:17	train_loss:1.8853585720062256	train_acc:0.39285714285714285	test_acc:0.329	test_f1:0.38452245476307406
epoch:18	train_loss:1.8830195665359497	train_acc:0.40714285714285714	test_acc:0.358	test_f1:0.4176382696131183
epoch:19	train_loss:1.8711708784103394	train_acc:0.4642857142857143	test_acc:0.399	test_f1:0.4581005846376988
epoch:20	train_loss:1.8641752004623413	train_acc:0.5214285714285715	test_acc:0.468	test_f1:0.516034783653655
epoch:21	train_loss:1.8610397577285767	train_acc:0.5142857142857142	test_acc:0.547	test_f1:0.57206541722398
epoch:22	train_loss:1.8513303995132446	train_acc:0.5785714285714286	test_acc:0.58	test_f1:0.590614391400128
epoch:23	train_loss:1.8487110137939453	train_acc:0.5785714285714286	test_acc:0.577	test_f1:0.5894941524226791
epoch:24	train_loss:1.8197709321975708	train_acc:0.6214285714285714	test_acc:0.587	test_f1:0.5956876499942718
epoch:25	train_loss:1.82488214969635	train_acc:0.6571428571428571	test_acc:0.599	test_f1:0.6069478887154306
epoch:26	train_loss:1.831568956375122	train_acc:0.6142857142857143	test_acc:0.616	test_f1:0.623804652783497
epoch:27	train_loss:1.7959643602371216	train_acc:0.6571428571428571	test_acc:0.631	test_f1:0.6405956090987042
epoch:28	train_loss:1.7825452089309692	train_acc:0.6857142857142857	test_acc:0.648	test_f1:0.6616756482748035
epoch:29	train_loss:1.7775369882583618	train_acc:0.6571428571428571	test_acc:0.646	test_f1:0.6608370575347176
epoch:30	train_loss:1.755321741104126	train_acc:0.7071428571428572	test_acc:0.646	test_f1:0.6647159736699193
epoch:31	train_loss:1.7421618700027466	train_acc:0.75	test_acc:0.658	test_f1:0.6781655551553072
epoch:32	train_loss:1.7558614015579224	train_acc:0.6571428571428571	test_acc:0.661	test_f1:0.6815210262469261
epoch:33	train_loss:1.7328613996505737	train_acc:0.7142857142857143	test_acc:0.662	test_f1:0.6810984557093237
epoch:34	train_loss:1.7076412439346313	train_acc:0.7285714285714285	test_acc:0.67	test_f1:0.6888804700818192
epoch:35	train_loss:1.6867669820785522	train_acc:0.7928571428571428	test_acc:0.69	test_f1:0.7058306530507491
epoch:36	train_loss:1.6727098226547241	train_acc:0.7857142857142857	test_acc:0.7	test_f1:0.7123720414162555
epoch:37	train_loss:1.6706516742706299	train_acc:0.7642857142857142	test_acc:0.703	test_f1:0.7165040936049507
epoch:38	train_loss:1.6771734952926636	train_acc:0.7142857142857143	test_acc:0.716	test_f1:0.7265236882701211
epoch:39	train_loss:1.6421234607696533	train_acc:0.7071428571428572	test_acc:0.716	test_f1:0.7272957863572149
epoch:40	train_loss:1.5972322225570679	train_acc:0.7857142857142857	test_acc:0.714	test_f1:0.7266313195343399
epoch:41	train_loss:1.6122028827667236	train_acc:0.7357142857142858	test_acc:0.713	test_f1:0.7254711310432416
epoch:42	train_loss:1.5847643613815308	train_acc:0.7785714285714286	test_acc:0.718	test_f1:0.7333568374255313
epoch:43	train_loss:1.585300326347351	train_acc:0.8142857142857143	test_acc:0.722	test_f1:0.7365525636740629
epoch:44	train_loss:1.5505207777023315	train_acc:0.8	test_acc:0.725	test_f1:0.7389881920204083
epoch:45	train_loss:1.5273269414901733	train_acc:0.8285714285714286	test_acc:0.735	test_f1:0.7462964313265611
epoch:46	train_loss:1.5189223289489746	train_acc:0.85	test_acc:0.742	test_f1:0.7511067909087856
epoch:47	train_loss:1.4766699075698853	train_acc:0.8	test_acc:0.746	test_f1:0.7517118589000891
epoch:48	train_loss:1.4812332391738892	train_acc:0.8071428571428572	test_acc:0.753	test_f1:0.7563319738710451
epoch:49	train_loss:1.4435536861419678	train_acc:0.8428571428571429	test_acc:0.765	test_f1:0.7661633796593873
epoch:50	train_loss:1.4311703443527222	train_acc:0.8357142857142857	test_acc:0.773	test_f1:0.7722352085094082
训练并测试结束，共训练50轮，总用时1.5660288333892822s
最佳正确率为:0.773,对应的macro_f1为:0.7722352085094082,对应的训练轮次为:50



2022-07-01 20:11:45.748888
epoch:1	train_loss:1.9828670024871826	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:2	train_loss:1.978607416152954	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:3	train_loss:1.9711774587631226	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:4	train_loss:1.964668869972229	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:5	train_loss:1.9570438861846924	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:6	train_loss:1.9498779773712158	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:7	train_loss:1.9421181678771973	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:8	train_loss:1.9377349615097046	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:9	train_loss:1.9330867528915405	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:10	train_loss:1.923435091972351	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:11	train_loss:1.9162213802337646	train_acc:0.15	test_acc:0.319	test_f1:0.06909996750785227
epoch:12	train_loss:1.917807698249817	train_acc:0.15714285714285714	test_acc:0.319	test_f1:0.06909996750785227
epoch:13	train_loss:1.9105030298233032	train_acc:0.18571428571428572	test_acc:0.319	test_f1:0.06909996750785227
epoch:14	train_loss:1.9036439657211304	train_acc:0.2	test_acc:0.33	test_f1:0.09568302445051888
epoch:15	train_loss:1.8983217477798462	train_acc:0.25	test_acc:0.366	test_f1:0.1688142555988439
epoch:16	train_loss:1.8904271125793457	train_acc:0.26071428571428573	test_acc:0.464	test_f1:0.3095413686056929
epoch:17	train_loss:1.8926827907562256	train_acc:0.31785714285714284	test_acc:0.548	test_f1:0.38837839721481254
epoch:18	train_loss:1.8740746974945068	train_acc:0.3607142857142857	test_acc:0.59	test_f1:0.44151641302858363
epoch:19	train_loss:1.8655803203582764	train_acc:0.4	test_acc:0.594	test_f1:0.46541659354507
epoch:20	train_loss:1.8632688522338867	train_acc:0.4	test_acc:0.581	test_f1:0.47986868246488007
epoch:21	train_loss:1.8473318815231323	train_acc:0.5178571428571429	test_acc:0.582	test_f1:0.48839510501781014
epoch:22	train_loss:1.8390520811080933	train_acc:0.525	test_acc:0.592	test_f1:0.5092164624410435
epoch:23	train_loss:1.83099365234375	train_acc:0.55	test_acc:0.611	test_f1:0.5452041420507471
epoch:24	train_loss:1.8163923025131226	train_acc:0.5821428571428572	test_acc:0.632	test_f1:0.577837509101814
epoch:25	train_loss:1.8065775632858276	train_acc:0.5892857142857143	test_acc:0.645	test_f1:0.6046920853698177
epoch:26	train_loss:1.802655816078186	train_acc:0.6107142857142858	test_acc:0.656	test_f1:0.6229859178598947
epoch:27	train_loss:1.7939969301223755	train_acc:0.6142857142857143	test_acc:0.672	test_f1:0.6546643276625025
epoch:28	train_loss:1.7889807224273682	train_acc:0.6428571428571429	test_acc:0.694	test_f1:0.6833272471337551
epoch:29	train_loss:1.7711528539657593	train_acc:0.6321428571428571	test_acc:0.72	test_f1:0.7170282476211084
epoch:30	train_loss:1.7655961513519287	train_acc:0.6357142857142857	test_acc:0.731	test_f1:0.7293946381074055
epoch:31	train_loss:1.7329941987991333	train_acc:0.7178571428571429	test_acc:0.74	test_f1:0.7375896437640176
epoch:32	train_loss:1.7249462604522705	train_acc:0.7178571428571429	test_acc:0.744	test_f1:0.7413524689900818
epoch:33	train_loss:1.7174296379089355	train_acc:0.7428571428571429	test_acc:0.747	test_f1:0.7406078427974006
epoch:34	train_loss:1.6936233043670654	train_acc:0.7285714285714285	test_acc:0.765	test_f1:0.7584907789662768
epoch:35	train_loss:1.669783592224121	train_acc:0.7357142857142858	test_acc:0.773	test_f1:0.7668111641110257
epoch:36	train_loss:1.6631009578704834	train_acc:0.7464285714285714	test_acc:0.781	test_f1:0.7707301541502739
epoch:37	train_loss:1.643239140510559	train_acc:0.7392857142857143	test_acc:0.786	test_f1:0.7710136852748725
epoch:38	train_loss:1.633609414100647	train_acc:0.7571428571428571	test_acc:0.794	test_f1:0.7762773020071387
epoch:39	train_loss:1.6173428297042847	train_acc:0.7321428571428571	test_acc:0.795	test_f1:0.7765697477656289
epoch:40	train_loss:1.6009995937347412	train_acc:0.75	test_acc:0.798	test_f1:0.7806256060506005
epoch:41	train_loss:1.5927505493164062	train_acc:0.7571428571428571	test_acc:0.802	test_f1:0.783646324691628
epoch:42	train_loss:1.5508646965026855	train_acc:0.7857142857142857	test_acc:0.803	test_f1:0.7874385214229213
epoch:43	train_loss:1.541959524154663	train_acc:0.7928571428571428	test_acc:0.803	test_f1:0.7875749290136655
epoch:44	train_loss:1.530321717262268	train_acc:0.7928571428571428	test_acc:0.8	test_f1:0.7854356782983789
epoch:45	train_loss:1.5011752843856812	train_acc:0.8285714285714286	test_acc:0.8	test_f1:0.7847148203862104
epoch:46	train_loss:1.4707567691802979	train_acc:0.8142857142857143	test_acc:0.8	test_f1:0.7846010358429307
epoch:47	train_loss:1.4795496463775635	train_acc:0.7821428571428571	test_acc:0.803	test_f1:0.7873477768347967
epoch:48	train_loss:1.448254942893982	train_acc:0.8214285714285714	test_acc:0.806	test_f1:0.7898033113529314
epoch:49	train_loss:1.417742133140564	train_acc:0.8214285714285714	test_acc:0.805	test_f1:0.7880572579909156
epoch:50	train_loss:1.4158833026885986	train_acc:0.8	test_acc:0.809	test_f1:0.791563437454216
训练并测试结束，共训练50轮，总用时1.6345362663269043s
最佳正确率为:0.809,对应的macro_f1为:0.791563437454216,对应的训练轮次为:50



2022-07-01 20:11:55.313062
epoch:1	train_loss:1.9698078632354736	train_acc:0.14285714285714285	test_acc:0.149	test_f1:0.03705085167226159
epoch:2	train_loss:1.9556256532669067	train_acc:0.1392857142857143	test_acc:0.149	test_f1:0.03705085167226159
epoch:3	train_loss:1.9524359703063965	train_acc:0.14285714285714285	test_acc:0.149	test_f1:0.03705085167226159
epoch:4	train_loss:1.948912501335144	train_acc:0.14285714285714285	test_acc:0.149	test_f1:0.03705085167226159
epoch:5	train_loss:1.9369258880615234	train_acc:0.16428571428571428	test_acc:0.149	test_f1:0.03705085167226159
epoch:6	train_loss:1.931375503540039	train_acc:0.17857142857142858	test_acc:0.151	test_f1:0.042557633341043476
epoch:7	train_loss:1.9305644035339355	train_acc:0.16785714285714284	test_acc:0.159	test_f1:0.06230577151086888
epoch:8	train_loss:1.9193741083145142	train_acc:0.225	test_acc:0.215	test_f1:0.17146520872939902
epoch:9	train_loss:1.916015625	train_acc:0.30714285714285716	test_acc:0.39	test_f1:0.4164540379264189
epoch:10	train_loss:1.9131921529769897	train_acc:0.3535714285714286	test_acc:0.489	test_f1:0.5088507792652788
epoch:11	train_loss:1.9106271266937256	train_acc:0.3892857142857143	test_acc:0.369	test_f1:0.42024398967400295
epoch:12	train_loss:1.9038680791854858	train_acc:0.38571428571428573	test_acc:0.294	test_f1:0.291039991892082
epoch:13	train_loss:1.8989429473876953	train_acc:0.39285714285714285	test_acc:0.326	test_f1:0.2872623880478692
epoch:14	train_loss:1.8920776844024658	train_acc:0.4	test_acc:0.368	test_f1:0.30484393387058734
epoch:15	train_loss:1.8869620561599731	train_acc:0.4142857142857143	test_acc:0.419	test_f1:0.3305703781051329
epoch:16	train_loss:1.8790919780731201	train_acc:0.3964285714285714	test_acc:0.455	test_f1:0.3523734306267204
epoch:17	train_loss:1.8779120445251465	train_acc:0.3821428571428571	test_acc:0.493	test_f1:0.3992146019096999
epoch:18	train_loss:1.8686139583587646	train_acc:0.45	test_acc:0.516	test_f1:0.4291149022226407
epoch:19	train_loss:1.852297306060791	train_acc:0.48928571428571427	test_acc:0.541	test_f1:0.45171463897244596
epoch:20	train_loss:1.8506768941879272	train_acc:0.4642857142857143	test_acc:0.554	test_f1:0.4664746385226005
epoch:21	train_loss:1.8421696424484253	train_acc:0.5214285714285715	test_acc:0.559	test_f1:0.4748692841595233
epoch:22	train_loss:1.8311964273452759	train_acc:0.6214285714285714	test_acc:0.594	test_f1:0.5340852038687052
epoch:23	train_loss:1.827945590019226	train_acc:0.5714285714285714	test_acc:0.648	test_f1:0.6152365899781059
epoch:24	train_loss:1.8133400678634644	train_acc:0.6535714285714286	test_acc:0.687	test_f1:0.6659396467567108
epoch:25	train_loss:1.8100117444992065	train_acc:0.6571428571428571	test_acc:0.704	test_f1:0.6882210927625262
epoch:26	train_loss:1.8001641035079956	train_acc:0.6785714285714286	test_acc:0.71	test_f1:0.6980765412361586
epoch:27	train_loss:1.7879235744476318	train_acc:0.6821428571428572	test_acc:0.706	test_f1:0.6972004275361908
epoch:28	train_loss:1.7771824598312378	train_acc:0.6178571428571429	test_acc:0.704	test_f1:0.6974583168015707
epoch:29	train_loss:1.756991982460022	train_acc:0.7142857142857143	test_acc:0.72	test_f1:0.7118480444083038
epoch:30	train_loss:1.7530783414840698	train_acc:0.7464285714285714	test_acc:0.731	test_f1:0.7234062492368308
epoch:31	train_loss:1.7438881397247314	train_acc:0.7	test_acc:0.738	test_f1:0.7280589168644779
epoch:32	train_loss:1.7122234106063843	train_acc:0.7464285714285714	test_acc:0.743	test_f1:0.7321479290562509
epoch:33	train_loss:1.7117512226104736	train_acc:0.7285714285714285	test_acc:0.747	test_f1:0.7364177606679513
epoch:34	train_loss:1.6924619674682617	train_acc:0.75	test_acc:0.751	test_f1:0.740383600072232
epoch:35	train_loss:1.6915113925933838	train_acc:0.7607142857142857	test_acc:0.754	test_f1:0.7424000562136234
epoch:36	train_loss:1.660125970840454	train_acc:0.775	test_acc:0.757	test_f1:0.7446776418695464
epoch:37	train_loss:1.6433554887771606	train_acc:0.7642857142857142	test_acc:0.753	test_f1:0.7414082330935013
epoch:38	train_loss:1.6515954732894897	train_acc:0.7607142857142857	test_acc:0.755	test_f1:0.7437331868760698
epoch:39	train_loss:1.6225755214691162	train_acc:0.7785714285714286	test_acc:0.749	test_f1:0.7366188607374989
epoch:40	train_loss:1.626367211341858	train_acc:0.7678571428571429	test_acc:0.749	test_f1:0.7374791114591133
epoch:41	train_loss:1.5901741981506348	train_acc:0.7714285714285715	test_acc:0.749	test_f1:0.7381154955557429
epoch:42	train_loss:1.5857257843017578	train_acc:0.7071428571428572	test_acc:0.761	test_f1:0.7522579619429511
epoch:43	train_loss:1.574836254119873	train_acc:0.7571428571428571	test_acc:0.77	test_f1:0.7612048303374205
epoch:44	train_loss:1.560276746749878	train_acc:0.7178571428571429	test_acc:0.774	test_f1:0.7658827002475211
epoch:45	train_loss:1.5496052503585815	train_acc:0.7571428571428571	test_acc:0.779	test_f1:0.7709761115361792
epoch:46	train_loss:1.5241328477859497	train_acc:0.8214285714285714	test_acc:0.782	test_f1:0.7741943452728085
epoch:47	train_loss:1.5053280591964722	train_acc:0.8571428571428571	test_acc:0.778	test_f1:0.770609191466609
epoch:48	train_loss:1.4950584173202515	train_acc:0.775	test_acc:0.781	test_f1:0.774781054292335
epoch:49	train_loss:1.467922568321228	train_acc:0.7785714285714286	test_acc:0.776	test_f1:0.7718407887723358
epoch:50	train_loss:1.4658267498016357	train_acc:0.7821428571428571	test_acc:0.772	test_f1:0.7687140191544465
训练并测试结束，共训练50轮，总用时1.5680534839630127s
最佳正确率为:0.782,对应的macro_f1为:0.7741943452728085,对应的训练轮次为:46



2022-07-01 20:12:03.832059
epoch:1	train_loss:1.9720577001571655	train_acc:0.14285714285714285	test_acc:0.091	test_f1:0.02383134738771769
epoch:2	train_loss:1.9647175073623657	train_acc:0.14285714285714285	test_acc:0.091	test_f1:0.02383134738771769
epoch:3	train_loss:1.9608643054962158	train_acc:0.14285714285714285	test_acc:0.091	test_f1:0.02383134738771769
epoch:4	train_loss:1.9598993062973022	train_acc:0.14285714285714285	test_acc:0.091	test_f1:0.02383134738771769
epoch:5	train_loss:1.9525998830795288	train_acc:0.14285714285714285	test_acc:0.091	test_f1:0.02383134738771769
epoch:6	train_loss:1.9501155614852905	train_acc:0.14285714285714285	test_acc:0.091	test_f1:0.02383134738771769
epoch:7	train_loss:1.9380096197128296	train_acc:0.14285714285714285	test_acc:0.091	test_f1:0.02383134738771769
epoch:8	train_loss:1.930607795715332	train_acc:0.16428571428571428	test_acc:0.091	test_f1:0.02383134738771769
epoch:9	train_loss:1.9237570762634277	train_acc:0.15714285714285714	test_acc:0.091	test_f1:0.02383134738771769
epoch:10	train_loss:1.9213333129882812	train_acc:0.16071428571428573	test_acc:0.091	test_f1:0.02383134738771769
epoch:11	train_loss:1.9163763523101807	train_acc:0.16071428571428573	test_acc:0.091	test_f1:0.02383134738771769
epoch:12	train_loss:1.914363980293274	train_acc:0.21785714285714286	test_acc:0.093	test_f1:0.03253312344221435
epoch:13	train_loss:1.913785696029663	train_acc:0.21428571428571427	test_acc:0.101	test_f1:0.051918434408468404
epoch:14	train_loss:1.9097423553466797	train_acc:0.23214285714285715	test_acc:0.135	test_f1:0.11021706463416157
epoch:15	train_loss:1.8931503295898438	train_acc:0.33214285714285713	test_acc:0.418	test_f1:0.3051258772155954
epoch:16	train_loss:1.8883793354034424	train_acc:0.34285714285714286	test_acc:0.472	test_f1:0.32240772856408967
epoch:17	train_loss:1.8883017301559448	train_acc:0.3	test_acc:0.496	test_f1:0.3421101519366271
epoch:18	train_loss:1.873503565788269	train_acc:0.3607142857142857	test_acc:0.529	test_f1:0.3911962656182292
epoch:19	train_loss:1.8873893022537231	train_acc:0.3535714285714286	test_acc:0.566	test_f1:0.4562003307354447
epoch:20	train_loss:1.8772825002670288	train_acc:0.37857142857142856	test_acc:0.589	test_f1:0.5193259085626062
epoch:21	train_loss:1.8715165853500366	train_acc:0.40714285714285714	test_acc:0.598	test_f1:0.5494745654334624
epoch:22	train_loss:1.8489832878112793	train_acc:0.48214285714285715	test_acc:0.617	test_f1:0.577708957555662
epoch:23	train_loss:1.8433506488800049	train_acc:0.48214285714285715	test_acc:0.622	test_f1:0.5830071551953048
epoch:24	train_loss:1.8373218774795532	train_acc:0.5642857142857143	test_acc:0.623	test_f1:0.5883958930353003
epoch:25	train_loss:1.831627368927002	train_acc:0.5321428571428571	test_acc:0.639	test_f1:0.6049750637070337
epoch:26	train_loss:1.8126989603042603	train_acc:0.5785714285714286	test_acc:0.649	test_f1:0.6118500162329485
epoch:27	train_loss:1.8082914352416992	train_acc:0.5821428571428572	test_acc:0.651	test_f1:0.6125818354043263
epoch:28	train_loss:1.796671748161316	train_acc:0.575	test_acc:0.661	test_f1:0.6189898049645105
epoch:29	train_loss:1.7878128290176392	train_acc:0.6214285714285714	test_acc:0.67	test_f1:0.6222486215589628
epoch:30	train_loss:1.7940458059310913	train_acc:0.5678571428571428	test_acc:0.687	test_f1:0.6347687505075774
epoch:31	train_loss:1.7623494863510132	train_acc:0.6428571428571429	test_acc:0.697	test_f1:0.638465178638632
epoch:32	train_loss:1.750522494316101	train_acc:0.6178571428571429	test_acc:0.709	test_f1:0.6522028004784899
epoch:33	train_loss:1.7353202104568481	train_acc:0.6392857142857142	test_acc:0.719	test_f1:0.6750583728544898
epoch:34	train_loss:1.7199609279632568	train_acc:0.6785714285714286	test_acc:0.721	test_f1:0.6834980964158294
epoch:35	train_loss:1.7112845182418823	train_acc:0.6607142857142857	test_acc:0.719	test_f1:0.6840050866598578
epoch:36	train_loss:1.7148326635360718	train_acc:0.675	test_acc:0.721	test_f1:0.6957597890851577
epoch:37	train_loss:1.6847491264343262	train_acc:0.6857142857142857	test_acc:0.726	test_f1:0.7102362787629969
epoch:38	train_loss:1.676895260810852	train_acc:0.6785714285714286	test_acc:0.737	test_f1:0.7280607907336127
epoch:39	train_loss:1.6531083583831787	train_acc:0.675	test_acc:0.741	test_f1:0.7344427937547392
epoch:40	train_loss:1.6381200551986694	train_acc:0.7214285714285714	test_acc:0.745	test_f1:0.7408480684359263
epoch:41	train_loss:1.637343406677246	train_acc:0.7571428571428571	test_acc:0.749	test_f1:0.7454992080279431
epoch:42	train_loss:1.5976121425628662	train_acc:0.7285714285714285	test_acc:0.757	test_f1:0.7533673546882876
epoch:43	train_loss:1.5806806087493896	train_acc:0.7214285714285714	test_acc:0.76	test_f1:0.7580120941894701
epoch:44	train_loss:1.567087173461914	train_acc:0.7392857142857143	test_acc:0.758	test_f1:0.7563453960318969
epoch:45	train_loss:1.5741100311279297	train_acc:0.7464285714285714	test_acc:0.762	test_f1:0.7625914838508895
epoch:46	train_loss:1.5458134412765503	train_acc:0.725	test_acc:0.762	test_f1:0.7595878037952399
epoch:47	train_loss:1.5130773782730103	train_acc:0.75	test_acc:0.766	test_f1:0.7627985863176384
epoch:48	train_loss:1.5107784271240234	train_acc:0.7035714285714286	test_acc:0.772	test_f1:0.7686312811250222
epoch:49	train_loss:1.5036509037017822	train_acc:0.7535714285714286	test_acc:0.773	test_f1:0.7712952182283698
epoch:50	train_loss:1.4718273878097534	train_acc:0.7642857142857142	test_acc:0.773	test_f1:0.7717283727805567
训练并测试结束，共训练50轮，总用时1.5550389289855957s
最佳正确率为:0.773,对应的macro_f1为:0.7717283727805567,对应的训练轮次为:50



2022-07-01 20:12:18.795916
epoch:1	train_loss:1.9663116931915283	train_acc:0.15	test_acc:0.064	test_f1:0.017185821697099892
epoch:2	train_loss:1.9592981338500977	train_acc:0.14761904761904762	test_acc:0.064	test_f1:0.017185821697099892
epoch:3	train_loss:1.9526095390319824	train_acc:0.14761904761904762	test_acc:0.064	test_f1:0.017185821697099892
epoch:4	train_loss:1.9498165845870972	train_acc:0.14761904761904762	test_acc:0.065	test_f1:0.019383014061764254
epoch:5	train_loss:1.9450370073318481	train_acc:0.1523809523809524	test_acc:0.065	test_f1:0.019383014061764254
epoch:6	train_loss:1.9364818334579468	train_acc:0.18333333333333332	test_acc:0.082	test_f1:0.04647732196454065
epoch:7	train_loss:1.9389946460723877	train_acc:0.20714285714285716	test_acc:0.238	test_f1:0.17141846089002075
epoch:8	train_loss:1.9326680898666382	train_acc:0.19047619047619047	test_acc:0.435	test_f1:0.2646449829504356
epoch:9	train_loss:1.9278857707977295	train_acc:0.26666666666666666	test_acc:0.455	test_f1:0.34169654606563327
epoch:10	train_loss:1.9244270324707031	train_acc:0.28809523809523807	test_acc:0.436	test_f1:0.32117226576459973
epoch:11	train_loss:1.9197900295257568	train_acc:0.2904761904761905	test_acc:0.406	test_f1:0.23961626445401213
epoch:12	train_loss:1.9121689796447754	train_acc:0.3	test_acc:0.41	test_f1:0.237923391857124
epoch:13	train_loss:1.910090684890747	train_acc:0.31666666666666665	test_acc:0.413	test_f1:0.23747275142113805
epoch:14	train_loss:1.907010555267334	train_acc:0.2904761904761905	test_acc:0.431	test_f1:0.25283043589174276
epoch:15	train_loss:1.9065988063812256	train_acc:0.3	test_acc:0.463	test_f1:0.28978854381452746
epoch:16	train_loss:1.903054118156433	train_acc:0.3119047619047619	test_acc:0.54	test_f1:0.3872671883640814
epoch:17	train_loss:1.8918743133544922	train_acc:0.3880952380952381	test_acc:0.603	test_f1:0.47830338761854047
epoch:18	train_loss:1.8898097276687622	train_acc:0.3952380952380952	test_acc:0.621	test_f1:0.5326779121842276
epoch:19	train_loss:1.8864836692810059	train_acc:0.4023809523809524	test_acc:0.573	test_f1:0.5564383982418104
epoch:20	train_loss:1.8816769123077393	train_acc:0.42142857142857143	test_acc:0.538	test_f1:0.5835507060771897
epoch:21	train_loss:1.8743245601654053	train_acc:0.46904761904761905	test_acc:0.524	test_f1:0.5783756585682501
epoch:22	train_loss:1.8733420372009277	train_acc:0.46904761904761905	test_acc:0.519	test_f1:0.5720287382919215
epoch:23	train_loss:1.863242268562317	train_acc:0.5071428571428571	test_acc:0.506	test_f1:0.5554728051426187
epoch:24	train_loss:1.8598544597625732	train_acc:0.4928571428571429	test_acc:0.517	test_f1:0.5629532049952392
epoch:25	train_loss:1.84932279586792	train_acc:0.5238095238095238	test_acc:0.525	test_f1:0.5733783219892452
epoch:26	train_loss:1.8345853090286255	train_acc:0.5714285714285714	test_acc:0.542	test_f1:0.5898451970329229
epoch:27	train_loss:1.8322705030441284	train_acc:0.6	test_acc:0.568	test_f1:0.6100417563046739
epoch:28	train_loss:1.8278610706329346	train_acc:0.5595238095238095	test_acc:0.598	test_f1:0.6336949431888151
epoch:29	train_loss:1.8191494941711426	train_acc:0.5738095238095238	test_acc:0.627	test_f1:0.6561999242139895
epoch:30	train_loss:1.8021907806396484	train_acc:0.6071428571428571	test_acc:0.651	test_f1:0.6715043469610541
epoch:31	train_loss:1.8071826696395874	train_acc:0.6238095238095238	test_acc:0.669	test_f1:0.6799585492127921
epoch:32	train_loss:1.8041807413101196	train_acc:0.569047619047619	test_acc:0.687	test_f1:0.6884815341850518
epoch:33	train_loss:1.7725646495819092	train_acc:0.6571428571428571	test_acc:0.706	test_f1:0.6998016525389763
epoch:34	train_loss:1.778917908668518	train_acc:0.65	test_acc:0.712	test_f1:0.7041368384933326
epoch:35	train_loss:1.7696924209594727	train_acc:0.6619047619047619	test_acc:0.712	test_f1:0.7044733387283448
epoch:36	train_loss:1.759751558303833	train_acc:0.6190476190476191	test_acc:0.712	test_f1:0.7079977030070358
epoch:37	train_loss:1.7509758472442627	train_acc:0.6857142857142857	test_acc:0.713	test_f1:0.7097226083718746
epoch:38	train_loss:1.726545810699463	train_acc:0.7023809523809523	test_acc:0.727	test_f1:0.7194730324937274
epoch:39	train_loss:1.7262322902679443	train_acc:0.6952380952380952	test_acc:0.725	test_f1:0.7137639797514134
epoch:40	train_loss:1.7193458080291748	train_acc:0.6761904761904762	test_acc:0.735	test_f1:0.7200958596372385
epoch:41	train_loss:1.7003995180130005	train_acc:0.6738095238095239	test_acc:0.748	test_f1:0.7319142601723059
epoch:42	train_loss:1.6793756484985352	train_acc:0.6928571428571428	test_acc:0.746	test_f1:0.7303592072779755
epoch:43	train_loss:1.6695843935012817	train_acc:0.7333333333333333	test_acc:0.754	test_f1:0.7352331106778512
epoch:44	train_loss:1.654877781867981	train_acc:0.7142857142857143	test_acc:0.753	test_f1:0.7349745180935564
epoch:45	train_loss:1.6596508026123047	train_acc:0.6857142857142857	test_acc:0.76	test_f1:0.7410350536792966
epoch:46	train_loss:1.632859706878662	train_acc:0.6642857142857143	test_acc:0.758	test_f1:0.7412370398770235
epoch:47	train_loss:1.6229604482650757	train_acc:0.7095238095238096	test_acc:0.76	test_f1:0.7440158204781074
epoch:48	train_loss:1.609984040260315	train_acc:0.7166666666666667	test_acc:0.758	test_f1:0.7428884215208715
epoch:49	train_loss:1.5908586978912354	train_acc:0.7238095238095238	test_acc:0.761	test_f1:0.7486025452708868
epoch:50	train_loss:1.5773757696151733	train_acc:0.7357142857142858	test_acc:0.764	test_f1:0.7543380945079472
训练并测试结束，共训练50轮，总用时1.6071314811706543s
最佳正确率为:0.764,对应的macro_f1为:0.7543380945079472,对应的训练轮次为:50



2022-07-01 20:12:25.629244
epoch:1	train_loss:1.9659184217453003	train_acc:0.1595238095238095	test_acc:0.285	test_f1:0.09693676836666214
epoch:2	train_loss:1.9682480096817017	train_acc:0.1523809523809524	test_acc:0.245	test_f1:0.09647585669781933
epoch:3	train_loss:1.9592210054397583	train_acc:0.1380952380952381	test_acc:0.185	test_f1:0.08055965186454903
epoch:4	train_loss:1.9489021301269531	train_acc:0.1380952380952381	test_acc:0.139	test_f1:0.05986062717770035
epoch:5	train_loss:1.94576096534729	train_acc:0.1738095238095238	test_acc:0.114	test_f1:0.043213863599207765
epoch:6	train_loss:1.9432514905929565	train_acc:0.18333333333333332	test_acc:0.106	test_f1:0.0380279294498259
epoch:7	train_loss:1.9321775436401367	train_acc:0.21904761904761905	test_acc:0.106	test_f1:0.04114465781376605
epoch:8	train_loss:1.9297890663146973	train_acc:0.20238095238095238	test_acc:0.138	test_f1:0.10012694208042346
epoch:9	train_loss:1.931464672088623	train_acc:0.24047619047619048	test_acc:0.243	test_f1:0.1936249041939831
epoch:10	train_loss:1.9237393140792847	train_acc:0.25	test_acc:0.257	test_f1:0.19637930834666253
epoch:11	train_loss:1.9169104099273682	train_acc:0.26904761904761904	test_acc:0.237	test_f1:0.2114042968092229
epoch:12	train_loss:1.9150030612945557	train_acc:0.2714285714285714	test_acc:0.253	test_f1:0.2558399435159142
epoch:13	train_loss:1.9084733724594116	train_acc:0.3380952380952381	test_acc:0.305	test_f1:0.3150596250177248
epoch:14	train_loss:1.9100840091705322	train_acc:0.3333333333333333	test_acc:0.338	test_f1:0.33031378418460144
epoch:15	train_loss:1.895574688911438	train_acc:0.37857142857142856	test_acc:0.37	test_f1:0.3334597698849652
epoch:16	train_loss:1.897348403930664	train_acc:0.3523809523809524	test_acc:0.407	test_f1:0.3528639681383302
epoch:17	train_loss:1.8987789154052734	train_acc:0.3238095238095238	test_acc:0.4	test_f1:0.36757674654154987
epoch:18	train_loss:1.8988518714904785	train_acc:0.3238095238095238	test_acc:0.413	test_f1:0.4169207270939926
epoch:19	train_loss:1.8806140422821045	train_acc:0.35	test_acc:0.448	test_f1:0.4752717191367669
epoch:20	train_loss:1.8646759986877441	train_acc:0.45476190476190476	test_acc:0.502	test_f1:0.531629788343756
epoch:21	train_loss:1.8658584356307983	train_acc:0.4642857142857143	test_acc:0.577	test_f1:0.6004795231660457
epoch:22	train_loss:1.851362705230713	train_acc:0.5047619047619047	test_acc:0.656	test_f1:0.6756605290943682
epoch:23	train_loss:1.8467700481414795	train_acc:0.5238095238095238	test_acc:0.727	test_f1:0.7321930642796649
epoch:24	train_loss:1.8532593250274658	train_acc:0.5190476190476191	test_acc:0.743	test_f1:0.7474903268240289
epoch:25	train_loss:1.830924153327942	train_acc:0.5976190476190476	test_acc:0.756	test_f1:0.759091869118785
epoch:26	train_loss:1.8257871866226196	train_acc:0.5738095238095238	test_acc:0.765	test_f1:0.7650997468335944
epoch:27	train_loss:1.819282054901123	train_acc:0.6	test_acc:0.77	test_f1:0.7678982306950501
epoch:28	train_loss:1.7992020845413208	train_acc:0.6785714285714286	test_acc:0.768	test_f1:0.7625044404048198
epoch:29	train_loss:1.790334939956665	train_acc:0.65	test_acc:0.766	test_f1:0.7563379173833849
epoch:30	train_loss:1.7838149070739746	train_acc:0.6666666666666666	test_acc:0.758	test_f1:0.7469604623096895
epoch:31	train_loss:1.7733285427093506	train_acc:0.6547619047619048	test_acc:0.749	test_f1:0.737914241901108
epoch:32	train_loss:1.7661170959472656	train_acc:0.6595238095238095	test_acc:0.761	test_f1:0.7499243044200197
epoch:33	train_loss:1.7351285219192505	train_acc:0.7309523809523809	test_acc:0.771	test_f1:0.7621897040457067
epoch:34	train_loss:1.7370480298995972	train_acc:0.7119047619047619	test_acc:0.769	test_f1:0.7605414546181549
epoch:35	train_loss:1.7146000862121582	train_acc:0.7095238095238096	test_acc:0.769	test_f1:0.7624562282945596
epoch:36	train_loss:1.7185237407684326	train_acc:0.6952380952380952	test_acc:0.774	test_f1:0.7693552569640262
epoch:37	train_loss:1.698905348777771	train_acc:0.7309523809523809	test_acc:0.779	test_f1:0.7745860172761461
epoch:38	train_loss:1.6821061372756958	train_acc:0.7333333333333333	test_acc:0.779	test_f1:0.7786549851789178
epoch:39	train_loss:1.662912368774414	train_acc:0.7238095238095238	test_acc:0.776	test_f1:0.7776926266738554
epoch:40	train_loss:1.6621012687683105	train_acc:0.7642857142857142	test_acc:0.771	test_f1:0.7702351176550657
epoch:41	train_loss:1.6376111507415771	train_acc:0.7476190476190476	test_acc:0.772	test_f1:0.7709047748641739
epoch:42	train_loss:1.6134326457977295	train_acc:0.7738095238095238	test_acc:0.779	test_f1:0.7776379213875242
epoch:43	train_loss:1.6224205493927002	train_acc:0.7523809523809524	test_acc:0.782	test_f1:0.7793858554775838
epoch:44	train_loss:1.5792975425720215	train_acc:0.8119047619047619	test_acc:0.776	test_f1:0.7709112316615706
epoch:45	train_loss:1.5633552074432373	train_acc:0.7976190476190477	test_acc:0.772	test_f1:0.7670589269452225
epoch:46	train_loss:1.5685369968414307	train_acc:0.75	test_acc:0.768	test_f1:0.7631872112455834
epoch:47	train_loss:1.5149483680725098	train_acc:0.7976190476190477	test_acc:0.768	test_f1:0.7625438993177578
epoch:48	train_loss:1.5009042024612427	train_acc:0.7833333333333333	test_acc:0.77	test_f1:0.7644523547780283
epoch:49	train_loss:1.491342306137085	train_acc:0.7785714285714286	test_acc:0.772	test_f1:0.7661753169933464
epoch:50	train_loss:1.4854289293289185	train_acc:0.7857142857142857	test_acc:0.777	test_f1:0.7723198349267532
训练并测试结束，共训练50轮，总用时1.5387680530548096s
最佳正确率为:0.782,对应的macro_f1为:0.7793858554775838,对应的训练轮次为:43



2022-07-01 20:12:34.364880
epoch:1	train_loss:1.9645345211029053	train_acc:0.14523809523809525	test_acc:0.319	test_f1:0.06909996750785227
epoch:2	train_loss:1.9581419229507446	train_acc:0.14047619047619048	test_acc:0.319	test_f1:0.06931015752308528
epoch:3	train_loss:1.9433751106262207	train_acc:0.17142857142857143	test_acc:0.319	test_f1:0.06931015752308528
epoch:4	train_loss:1.9402955770492554	train_acc:0.14761904761904762	test_acc:0.326	test_f1:0.08892392540674703
epoch:5	train_loss:1.9294604063034058	train_acc:0.18333333333333332	test_acc:0.384	test_f1:0.2099049698560674
epoch:6	train_loss:1.9304478168487549	train_acc:0.1880952380952381	test_acc:0.398	test_f1:0.27250849643928143
epoch:7	train_loss:1.9129387140274048	train_acc:0.2642857142857143	test_acc:0.253	test_f1:0.21642521430618392
epoch:8	train_loss:1.9192254543304443	train_acc:0.25952380952380955	test_acc:0.246	test_f1:0.2650803248057832
epoch:9	train_loss:1.9019384384155273	train_acc:0.2904761904761905	test_acc:0.271	test_f1:0.29170241581538753
epoch:10	train_loss:1.9002810716629028	train_acc:0.3476190476190476	test_acc:0.274	test_f1:0.28441543955899684
epoch:11	train_loss:1.890724539756775	train_acc:0.3261904761904762	test_acc:0.298	test_f1:0.3467885775499978
epoch:12	train_loss:1.8871427774429321	train_acc:0.3238095238095238	test_acc:0.281	test_f1:0.32220054521896724
epoch:13	train_loss:1.8810657262802124	train_acc:0.38333333333333336	test_acc:0.304	test_f1:0.33631344024432525
epoch:14	train_loss:1.8780816793441772	train_acc:0.3476190476190476	test_acc:0.365	test_f1:0.39519183810163794
epoch:15	train_loss:1.8633482456207275	train_acc:0.4119047619047619	test_acc:0.414	test_f1:0.4313376289409628
epoch:16	train_loss:1.860621690750122	train_acc:0.44761904761904764	test_acc:0.47	test_f1:0.47202449990242823
epoch:17	train_loss:1.8542711734771729	train_acc:0.43333333333333335	test_acc:0.532	test_f1:0.5185699501241156
epoch:18	train_loss:1.8328964710235596	train_acc:0.530952380952381	test_acc:0.571	test_f1:0.5456556859033639
epoch:19	train_loss:1.8375176191329956	train_acc:0.5380952380952381	test_acc:0.611	test_f1:0.5755408156098144
epoch:20	train_loss:1.811028003692627	train_acc:0.6476190476190476	test_acc:0.634	test_f1:0.587594458617081
epoch:21	train_loss:1.8068264722824097	train_acc:0.6238095238095238	test_acc:0.657	test_f1:0.6031601673093264
epoch:22	train_loss:1.796350359916687	train_acc:0.6428571428571429	test_acc:0.684	test_f1:0.630514458668377
epoch:23	train_loss:1.7945343255996704	train_acc:0.6428571428571429	test_acc:0.713	test_f1:0.6612849334480727
epoch:24	train_loss:1.7747591733932495	train_acc:0.6595238095238095	test_acc:0.739	test_f1:0.6948895121969532
epoch:25	train_loss:1.7640029191970825	train_acc:0.6952380952380952	test_acc:0.757	test_f1:0.7195170836004682
epoch:26	train_loss:1.7521324157714844	train_acc:0.7333333333333333	test_acc:0.77	test_f1:0.7448099839143353
epoch:27	train_loss:1.7451673746109009	train_acc:0.7404761904761905	test_acc:0.781	test_f1:0.7616022926969693
epoch:28	train_loss:1.7279150485992432	train_acc:0.7357142857142858	test_acc:0.784	test_f1:0.7682069792130894
epoch:29	train_loss:1.7067232131958008	train_acc:0.7595238095238095	test_acc:0.782	test_f1:0.770839771308067
epoch:30	train_loss:1.6909351348876953	train_acc:0.7404761904761905	test_acc:0.762	test_f1:0.754949368885197
epoch:31	train_loss:1.694061517715454	train_acc:0.7595238095238095	test_acc:0.75	test_f1:0.745007928112536
epoch:32	train_loss:1.6859290599822998	train_acc:0.7357142857142858	test_acc:0.749	test_f1:0.7442492196302259
epoch:33	train_loss:1.649098515510559	train_acc:0.7595238095238095	test_acc:0.747	test_f1:0.7415505069048406
epoch:34	train_loss:1.632163166999817	train_acc:0.7428571428571429	test_acc:0.749	test_f1:0.7437422529172375
epoch:35	train_loss:1.6239101886749268	train_acc:0.7785714285714286	test_acc:0.752	test_f1:0.7460833766554537
epoch:36	train_loss:1.6230350732803345	train_acc:0.7476190476190476	test_acc:0.759	test_f1:0.7517363199836539
epoch:37	train_loss:1.6002000570297241	train_acc:0.7476190476190476	test_acc:0.769	test_f1:0.762823416255982
epoch:38	train_loss:1.563239574432373	train_acc:0.8071428571428572	test_acc:0.764	test_f1:0.7565274590181886
epoch:39	train_loss:1.557523250579834	train_acc:0.7904761904761904	test_acc:0.776	test_f1:0.7670883093057338
epoch:40	train_loss:1.5429444313049316	train_acc:0.7714285714285715	test_acc:0.781	test_f1:0.7712236953019198
epoch:41	train_loss:1.509775161743164	train_acc:0.8	test_acc:0.79	test_f1:0.7786057677838715
epoch:42	train_loss:1.4913055896759033	train_acc:0.7952380952380952	test_acc:0.79	test_f1:0.777135128766825
epoch:43	train_loss:1.4817278385162354	train_acc:0.8285714285714286	test_acc:0.788	test_f1:0.7727593595646385
epoch:44	train_loss:1.4746835231781006	train_acc:0.8142857142857143	test_acc:0.785	test_f1:0.769720973587898
epoch:45	train_loss:1.4409124851226807	train_acc:0.819047619047619	test_acc:0.778	test_f1:0.7659254620506755
epoch:46	train_loss:1.4109801054000854	train_acc:0.8261904761904761	test_acc:0.773	test_f1:0.762555297477577
epoch:47	train_loss:1.3915154933929443	train_acc:0.7976190476190477	test_acc:0.776	test_f1:0.7659168042872372
epoch:48	train_loss:1.3787668943405151	train_acc:0.8071428571428572	test_acc:0.784	test_f1:0.7747251835481137
epoch:49	train_loss:1.373967170715332	train_acc:0.8023809523809524	test_acc:0.786	test_f1:0.7777814353713596
epoch:50	train_loss:1.3421927690505981	train_acc:0.8095238095238095	test_acc:0.787	test_f1:0.779191535707113
训练并测试结束，共训练50轮，总用时1.5541186332702637s
最佳正确率为:0.79,对应的macro_f1为:0.777135128766825,对应的训练轮次为:42



2022-07-01 20:13:12.603989
epoch:1	train_loss:1.821189045906067	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:2	train_loss:1.8145722150802612	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:3	train_loss:1.8074148893356323	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:4	train_loss:1.8006037473678589	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:5	train_loss:1.7988207340240479	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:6	train_loss:1.7922420501708984	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:7	train_loss:1.7829076051712036	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:8	train_loss:1.7809540033340454	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:9	train_loss:1.7741175889968872	train_acc:0.175	test_acc:0.16	test_f1:0.04597701149425288
epoch:10	train_loss:1.7735744714736938	train_acc:0.175	test_acc:0.16	test_f1:0.04597701149425288
epoch:11	train_loss:1.7758475542068481	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:12	train_loss:1.7671000957489014	train_acc:0.18333333333333332	test_acc:0.16	test_f1:0.04597701149425288
epoch:13	train_loss:1.7675985097885132	train_acc:0.18333333333333332	test_acc:0.16	test_f1:0.04597701149425288
epoch:14	train_loss:1.7491581439971924	train_acc:0.26666666666666666	test_acc:0.163	test_f1:0.05150163127691218
epoch:15	train_loss:1.7607322931289673	train_acc:0.23333333333333334	test_acc:0.184	test_f1:0.08520949015648661
epoch:16	train_loss:1.7509993314743042	train_acc:0.25	test_acc:0.244	test_f1:0.15145147369235423
epoch:17	train_loss:1.7481151819229126	train_acc:0.35	test_acc:0.333	test_f1:0.24308656730640818
epoch:18	train_loss:1.748112440109253	train_acc:0.43333333333333335	test_acc:0.454	test_f1:0.3510482810880538
epoch:19	train_loss:1.7353390455245972	train_acc:0.475	test_acc:0.541	test_f1:0.45623764259307387
epoch:20	train_loss:1.7356021404266357	train_acc:0.425	test_acc:0.592	test_f1:0.5170366257755032
epoch:21	train_loss:1.7339861392974854	train_acc:0.44166666666666665	test_acc:0.616	test_f1:0.5410968785515459
epoch:22	train_loss:1.7183696031570435	train_acc:0.5666666666666667	test_acc:0.62	test_f1:0.545929247486835
epoch:23	train_loss:1.7204890251159668	train_acc:0.45	test_acc:0.619	test_f1:0.5437024542298549
epoch:24	train_loss:1.7087708711624146	train_acc:0.5166666666666667	test_acc:0.617	test_f1:0.5393882284156651
epoch:25	train_loss:1.689331293106079	train_acc:0.6	test_acc:0.612	test_f1:0.5317996009178704
epoch:26	train_loss:1.6818891763687134	train_acc:0.5916666666666667	test_acc:0.592	test_f1:0.5083829396187941
epoch:27	train_loss:1.687182068824768	train_acc:0.5833333333333334	test_acc:0.579	test_f1:0.48991924837591966
epoch:28	train_loss:1.6768641471862793	train_acc:0.6166666666666667	test_acc:0.571	test_f1:0.4781725710908002
epoch:29	train_loss:1.6813559532165527	train_acc:0.6166666666666667	test_acc:0.568	test_f1:0.47301762407701836
epoch:30	train_loss:1.6742069721221924	train_acc:0.575	test_acc:0.567	test_f1:0.4726828221024251
epoch:31	train_loss:1.6513360738754272	train_acc:0.5833333333333334	test_acc:0.57	test_f1:0.4745319721750964
epoch:32	train_loss:1.6388522386550903	train_acc:0.625	test_acc:0.571	test_f1:0.47513077757047933
epoch:33	train_loss:1.6340687274932861	train_acc:0.6166666666666667	test_acc:0.571	test_f1:0.47798123427182665
epoch:34	train_loss:1.6370341777801514	train_acc:0.6666666666666666	test_acc:0.571	test_f1:0.48820143555007905
epoch:35	train_loss:1.6184240579605103	train_acc:0.675	test_acc:0.573	test_f1:0.49543539104555645
epoch:36	train_loss:1.6159430742263794	train_acc:0.65	test_acc:0.583	test_f1:0.5102083449945068
epoch:37	train_loss:1.602285385131836	train_acc:0.6666666666666666	test_acc:0.582	test_f1:0.5035427751687388
epoch:38	train_loss:1.6054514646530151	train_acc:0.575	test_acc:0.584	test_f1:0.49729681483568305
epoch:39	train_loss:1.5775738954544067	train_acc:0.6916666666666667	test_acc:0.596	test_f1:0.5107745423368549
epoch:40	train_loss:1.576088547706604	train_acc:0.6416666666666667	test_acc:0.597	test_f1:0.514529012843571
epoch:41	train_loss:1.573034405708313	train_acc:0.625	test_acc:0.605	test_f1:0.5248875575898417
epoch:42	train_loss:1.540224313735962	train_acc:0.7	test_acc:0.611	test_f1:0.5309902187718745
epoch:43	train_loss:1.53831148147583	train_acc:0.6833333333333333	test_acc:0.614	test_f1:0.5344077850735128
epoch:44	train_loss:1.5066853761672974	train_acc:0.6666666666666666	test_acc:0.627	test_f1:0.54447741035812
epoch:45	train_loss:1.519378423690796	train_acc:0.6083333333333333	test_acc:0.636	test_f1:0.5526288744685651
epoch:46	train_loss:1.4920387268066406	train_acc:0.6833333333333333	test_acc:0.652	test_f1:0.567058403609996
epoch:47	train_loss:1.508423924446106	train_acc:0.6916666666666667	test_acc:0.671	test_f1:0.5834341346214639
epoch:48	train_loss:1.4853911399841309	train_acc:0.6583333333333333	test_acc:0.685	test_f1:0.5956640104994264
epoch:49	train_loss:1.46709144115448	train_acc:0.6666666666666666	test_acc:0.688	test_f1:0.5982445243434741
epoch:50	train_loss:1.4579755067825317	train_acc:0.6416666666666667	test_acc:0.693	test_f1:0.6093416785126416
训练并测试结束，共训练50轮，总用时2.0701375007629395s
最佳正确率为:0.693,对应的macro_f1为:0.6093416785126416,对应的训练轮次为:50



2022-07-01 20:13:27.447429
epoch:1	train_loss:1.8033016920089722	train_acc:0.17083333333333334	test_acc:0.231	test_f1:0.06255077173030056
epoch:2	train_loss:1.8058682680130005	train_acc:0.1625	test_acc:0.231	test_f1:0.06255077173030056
epoch:3	train_loss:1.7882764339447021	train_acc:0.18333333333333332	test_acc:0.231	test_f1:0.06255077173030056
epoch:4	train_loss:1.7939714193344116	train_acc:0.1625	test_acc:0.231	test_f1:0.06270358306188925
epoch:5	train_loss:1.7845226526260376	train_acc:0.17916666666666667	test_acc:0.228	test_f1:0.09573350215836313
epoch:6	train_loss:1.78257417678833	train_acc:0.20416666666666666	test_acc:0.395	test_f1:0.3099563884395738
epoch:7	train_loss:1.7751424312591553	train_acc:0.29583333333333334	test_acc:0.205	test_f1:0.11419937113713242
epoch:8	train_loss:1.773913860321045	train_acc:0.23333333333333334	test_acc:0.186	test_f1:0.08465222409489871
epoch:9	train_loss:1.7706612348556519	train_acc:0.25416666666666665	test_acc:0.191	test_f1:0.09307327133298011
epoch:10	train_loss:1.7738640308380127	train_acc:0.21666666666666667	test_acc:0.192	test_f1:0.09222255095880749
epoch:11	train_loss:1.7751120328903198	train_acc:0.2125	test_acc:0.208	test_f1:0.11440304288123897
epoch:12	train_loss:1.7665294408798218	train_acc:0.22916666666666666	test_acc:0.225	test_f1:0.1278959387304053
epoch:13	train_loss:1.7700779438018799	train_acc:0.25	test_acc:0.237	test_f1:0.1496911206250689
epoch:14	train_loss:1.7518171072006226	train_acc:0.3458333333333333	test_acc:0.265	test_f1:0.20241548242379684
epoch:15	train_loss:1.7529261112213135	train_acc:0.3	test_acc:0.338	test_f1:0.2898182848790352
epoch:16	train_loss:1.7412855625152588	train_acc:0.42083333333333334	test_acc:0.46	test_f1:0.43887397383986143
epoch:17	train_loss:1.7502740621566772	train_acc:0.37916666666666665	test_acc:0.553	test_f1:0.5336349824357146
epoch:18	train_loss:1.7368826866149902	train_acc:0.44583333333333336	test_acc:0.599	test_f1:0.5728420950586799
epoch:19	train_loss:1.741034984588623	train_acc:0.3958333333333333	test_acc:0.645	test_f1:0.6131105254112074
epoch:20	train_loss:1.7359375953674316	train_acc:0.42916666666666664	test_acc:0.668	test_f1:0.6313437711361582
epoch:21	train_loss:1.7255139350891113	train_acc:0.4875	test_acc:0.671	test_f1:0.6311545921283064
epoch:22	train_loss:1.7223247289657593	train_acc:0.5583333333333333	test_acc:0.664	test_f1:0.6225910210252968
epoch:23	train_loss:1.7099041938781738	train_acc:0.5708333333333333	test_acc:0.66	test_f1:0.6170630980225464
epoch:24	train_loss:1.7021117210388184	train_acc:0.5541666666666667	test_acc:0.665	test_f1:0.6227014683675898
epoch:25	train_loss:1.7026230096817017	train_acc:0.5166666666666667	test_acc:0.66	test_f1:0.6206409102622411
epoch:26	train_loss:1.6959331035614014	train_acc:0.5833333333333334	test_acc:0.669	test_f1:0.6283110324113576
epoch:27	train_loss:1.6863502264022827	train_acc:0.6083333333333333	test_acc:0.661	test_f1:0.619757734605261
epoch:28	train_loss:1.6736888885498047	train_acc:0.6375	test_acc:0.662	test_f1:0.6261376842532954
epoch:29	train_loss:1.6785448789596558	train_acc:0.6125	test_acc:0.662	test_f1:0.6274144576251215
epoch:30	train_loss:1.671790361404419	train_acc:0.65	test_acc:0.65	test_f1:0.6148903695559392
epoch:31	train_loss:1.656201720237732	train_acc:0.6166666666666667	test_acc:0.65	test_f1:0.6159790986208599
epoch:32	train_loss:1.6465487480163574	train_acc:0.6958333333333333	test_acc:0.657	test_f1:0.6219091077623146
epoch:33	train_loss:1.646849513053894	train_acc:0.6583333333333333	test_acc:0.66	test_f1:0.6218997073678428
epoch:34	train_loss:1.6326384544372559	train_acc:0.6708333333333333	test_acc:0.666	test_f1:0.6272821301333807
epoch:35	train_loss:1.621673345565796	train_acc:0.7	test_acc:0.68	test_f1:0.6428505750873396
epoch:36	train_loss:1.6061843633651733	train_acc:0.7166666666666667	test_acc:0.687	test_f1:0.6502450119760741
epoch:37	train_loss:1.6035304069519043	train_acc:0.725	test_acc:0.678	test_f1:0.6400945189609356
epoch:38	train_loss:1.598227620124817	train_acc:0.6625	test_acc:0.675	test_f1:0.6358450984512946
epoch:39	train_loss:1.5699554681777954	train_acc:0.7416666666666667	test_acc:0.67	test_f1:0.6315729072305475
epoch:40	train_loss:1.5651471614837646	train_acc:0.7125	test_acc:0.662	test_f1:0.6268641722654827
epoch:41	train_loss:1.5546185970306396	train_acc:0.7083333333333334	test_acc:0.66	test_f1:0.627319083028336
epoch:42	train_loss:1.549747109413147	train_acc:0.7416666666666667	test_acc:0.665	test_f1:0.6337665957444488
epoch:43	train_loss:1.5285067558288574	train_acc:0.7458333333333333	test_acc:0.67	test_f1:0.6400538475460297
epoch:44	train_loss:1.5048497915267944	train_acc:0.7541666666666667	test_acc:0.678	test_f1:0.6478783163266991
epoch:45	train_loss:1.502247929573059	train_acc:0.725	test_acc:0.691	test_f1:0.6587479692645773
epoch:46	train_loss:1.5119413137435913	train_acc:0.7333333333333333	test_acc:0.702	test_f1:0.6656949989935007
epoch:47	train_loss:1.49183189868927	train_acc:0.7583333333333333	test_acc:0.704	test_f1:0.6671260212291305
epoch:48	train_loss:1.45041823387146	train_acc:0.7708333333333334	test_acc:0.705	test_f1:0.6684079848034509
epoch:49	train_loss:1.4623360633850098	train_acc:0.7541666666666667	test_acc:0.706	test_f1:0.6697863451080179
epoch:50	train_loss:1.4303454160690308	train_acc:0.7625	test_acc:0.707	test_f1:0.6722937095748636
训练并测试结束，共训练50轮，总用时2.0723812580108643s
最佳正确率为:0.707,对应的macro_f1为:0.6722937095748636,对应的训练轮次为:50



2022-07-01 20:13:40.521999
epoch:1	train_loss:1.8289211988449097	train_acc:0.16666666666666666	test_acc:0.181	test_f1:0.05108664973186564
epoch:2	train_loss:1.80336332321167	train_acc:0.175	test_acc:0.181	test_f1:0.05108664973186564
epoch:3	train_loss:1.803812861442566	train_acc:0.16666666666666666	test_acc:0.181	test_f1:0.05108664973186564
epoch:4	train_loss:1.791282057762146	train_acc:0.18333333333333332	test_acc:0.181	test_f1:0.05108664973186564
epoch:5	train_loss:1.7922614812850952	train_acc:0.18333333333333332	test_acc:0.181	test_f1:0.05108664973186564
epoch:6	train_loss:1.7685409784317017	train_acc:0.225	test_acc:0.181	test_f1:0.05108664973186564
epoch:7	train_loss:1.7799818515777588	train_acc:0.13333333333333333	test_acc:0.186	test_f1:0.060882398936586125
epoch:8	train_loss:1.7696138620376587	train_acc:0.21666666666666667	test_acc:0.26	test_f1:0.16109419951633067
epoch:9	train_loss:1.7550723552703857	train_acc:0.31666666666666665	test_acc:0.448	test_f1:0.3078612924916579
epoch:10	train_loss:1.750809907913208	train_acc:0.3	test_acc:0.472	test_f1:0.3211353364202804
epoch:11	train_loss:1.7515252828598022	train_acc:0.3416666666666667	test_acc:0.392	test_f1:0.2494087647960114
epoch:12	train_loss:1.7552279233932495	train_acc:0.30833333333333335	test_acc:0.391	test_f1:0.28016214903523695
epoch:13	train_loss:1.7331866025924683	train_acc:0.39166666666666666	test_acc:0.412	test_f1:0.32829456732078827
epoch:14	train_loss:1.739456295967102	train_acc:0.35	test_acc:0.418	test_f1:0.3253057692627697
epoch:15	train_loss:1.729812741279602	train_acc:0.49166666666666664	test_acc:0.415	test_f1:0.3046478859226316
epoch:16	train_loss:1.7185760736465454	train_acc:0.4166666666666667	test_acc:0.404	test_f1:0.2796682647091711
epoch:17	train_loss:1.7189395427703857	train_acc:0.44166666666666665	test_acc:0.409	test_f1:0.28529151053913754
epoch:18	train_loss:1.7252815961837769	train_acc:0.4166666666666667	test_acc:0.428	test_f1:0.3321992663962866
epoch:19	train_loss:1.7196829319000244	train_acc:0.425	test_acc:0.441	test_f1:0.36346121674457726
epoch:20	train_loss:1.702774167060852	train_acc:0.48333333333333334	test_acc:0.447	test_f1:0.37650784745304106
epoch:21	train_loss:1.6960927248001099	train_acc:0.5166666666666667	test_acc:0.486	test_f1:0.41152526201591727
epoch:22	train_loss:1.6877363920211792	train_acc:0.525	test_acc:0.495	test_f1:0.4266715412026872
epoch:23	train_loss:1.682054877281189	train_acc:0.5333333333333333	test_acc:0.485	test_f1:0.4322123135774145
epoch:24	train_loss:1.6708978414535522	train_acc:0.6083333333333333	test_acc:0.483	test_f1:0.44107830335087006
epoch:25	train_loss:1.6480482816696167	train_acc:0.6333333333333333	test_acc:0.495	test_f1:0.4543842453482248
epoch:26	train_loss:1.6683307886123657	train_acc:0.5166666666666667	test_acc:0.512	test_f1:0.47130562969197204
epoch:27	train_loss:1.6371536254882812	train_acc:0.7	test_acc:0.536	test_f1:0.49166272654040943
epoch:28	train_loss:1.645999550819397	train_acc:0.6333333333333333	test_acc:0.548	test_f1:0.4980494246354725
epoch:29	train_loss:1.6293418407440186	train_acc:0.65	test_acc:0.558	test_f1:0.5050816637300414
epoch:30	train_loss:1.6321319341659546	train_acc:0.6833333333333333	test_acc:0.573	test_f1:0.523486450245867
epoch:31	train_loss:1.618651270866394	train_acc:0.6833333333333333	test_acc:0.6	test_f1:0.5609302723421035
epoch:32	train_loss:1.5961540937423706	train_acc:0.7583333333333333	test_acc:0.628	test_f1:0.5915845259135285
epoch:33	train_loss:1.594262957572937	train_acc:0.725	test_acc:0.646	test_f1:0.61215157900124
epoch:34	train_loss:1.5787874460220337	train_acc:0.725	test_acc:0.665	test_f1:0.627560991523178
epoch:35	train_loss:1.5858074426651	train_acc:0.7583333333333333	test_acc:0.668	test_f1:0.6292369538426384
epoch:36	train_loss:1.5468779802322388	train_acc:0.75	test_acc:0.668	test_f1:0.633186866265549
epoch:37	train_loss:1.5529420375823975	train_acc:0.775	test_acc:0.67	test_f1:0.637497218283292
epoch:38	train_loss:1.5310168266296387	train_acc:0.7666666666666667	test_acc:0.677	test_f1:0.6440795600904942
epoch:39	train_loss:1.517896294593811	train_acc:0.7916666666666666	test_acc:0.683	test_f1:0.6513034069042467
epoch:40	train_loss:1.5148391723632812	train_acc:0.85	test_acc:0.686	test_f1:0.6555382047997458
epoch:41	train_loss:1.5205934047698975	train_acc:0.7833333333333333	test_acc:0.684	test_f1:0.6534379598819088
epoch:42	train_loss:1.4772814512252808	train_acc:0.8083333333333333	test_acc:0.686	test_f1:0.6534098646335055
epoch:43	train_loss:1.4657680988311768	train_acc:0.8333333333333334	test_acc:0.685	test_f1:0.6500116988433903
epoch:44	train_loss:1.470401644706726	train_acc:0.775	test_acc:0.691	test_f1:0.6547338008726085
epoch:45	train_loss:1.4427601099014282	train_acc:0.8416666666666667	test_acc:0.689	test_f1:0.6523313842074899
epoch:46	train_loss:1.4323108196258545	train_acc:0.775	test_acc:0.694	test_f1:0.6551697839269622
epoch:47	train_loss:1.40939462184906	train_acc:0.8083333333333333	test_acc:0.697	test_f1:0.658047721996981
epoch:48	train_loss:1.3960459232330322	train_acc:0.8333333333333334	test_acc:0.692	test_f1:0.6532339496950385
epoch:49	train_loss:1.390004277229309	train_acc:0.775	test_acc:0.692	test_f1:0.6534217986476031
epoch:50	train_loss:1.3913949728012085	train_acc:0.8083333333333333	test_acc:0.696	test_f1:0.660159130227482
训练并测试结束，共训练50轮，总用时2.089035749435425s
最佳正确率为:0.697,对应的macro_f1为:0.658047721996981,对应的训练轮次为:47



2022-07-01 20:13:50.105959
epoch:1	train_loss:1.820716142654419	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:2	train_loss:1.8108060359954834	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:3	train_loss:1.8071694374084473	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:4	train_loss:1.8005489110946655	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:5	train_loss:1.7902216911315918	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:6	train_loss:1.7880704402923584	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:7	train_loss:1.7794660329818726	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:8	train_loss:1.7752655744552612	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:9	train_loss:1.7740633487701416	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:10	train_loss:1.7681456804275513	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:11	train_loss:1.7647885084152222	train_acc:0.175	test_acc:0.231	test_f1:0.06255077173030056
epoch:12	train_loss:1.7594497203826904	train_acc:0.18333333333333332	test_acc:0.231	test_f1:0.06255077173030056
epoch:13	train_loss:1.7538142204284668	train_acc:0.23333333333333334	test_acc:0.231	test_f1:0.06255077173030056
epoch:14	train_loss:1.7532799243927002	train_acc:0.2	test_acc:0.231	test_f1:0.06255077173030056
epoch:15	train_loss:1.7487514019012451	train_acc:0.31666666666666665	test_acc:0.233	test_f1:0.06672329417542187
epoch:16	train_loss:1.7384949922561646	train_acc:0.35	test_acc:0.255	test_f1:0.11155313338216176
epoch:17	train_loss:1.7419483661651611	train_acc:0.35833333333333334	test_acc:0.33	test_f1:0.2338526016626048
epoch:18	train_loss:1.7339736223220825	train_acc:0.425	test_acc:0.518	test_f1:0.4463412279630492
epoch:19	train_loss:1.72660231590271	train_acc:0.5083333333333333	test_acc:0.617	test_f1:0.5597125931173222
epoch:20	train_loss:1.7262635231018066	train_acc:0.49166666666666664	test_acc:0.592	test_f1:0.5474972082093906
epoch:21	train_loss:1.7149205207824707	train_acc:0.525	test_acc:0.563	test_f1:0.5186281473707756
epoch:22	train_loss:1.7211213111877441	train_acc:0.475	test_acc:0.544	test_f1:0.4906648620566143
epoch:23	train_loss:1.6999307870864868	train_acc:0.5666666666666667	test_acc:0.541	test_f1:0.4854095014609901
epoch:24	train_loss:1.6969794034957886	train_acc:0.5833333333333334	test_acc:0.54	test_f1:0.4856329383298472
epoch:25	train_loss:1.6880080699920654	train_acc:0.5416666666666666	test_acc:0.532	test_f1:0.477185080393507
epoch:26	train_loss:1.684600591659546	train_acc:0.6	test_acc:0.528	test_f1:0.4711359034867133
epoch:27	train_loss:1.6812318563461304	train_acc:0.6083333333333333	test_acc:0.529	test_f1:0.4695933120956455
epoch:28	train_loss:1.6651414632797241	train_acc:0.575	test_acc:0.523	test_f1:0.46279004411554564
epoch:29	train_loss:1.6578274965286255	train_acc:0.6583333333333333	test_acc:0.515	test_f1:0.45488804826763274
epoch:30	train_loss:1.6276930570602417	train_acc:0.7416666666666667	test_acc:0.512	test_f1:0.4564438653185292
epoch:31	train_loss:1.6251095533370972	train_acc:0.6583333333333333	test_acc:0.518	test_f1:0.46362020169584345
epoch:32	train_loss:1.6186655759811401	train_acc:0.625	test_acc:0.528	test_f1:0.47851146171717107
epoch:33	train_loss:1.6103146076202393	train_acc:0.6916666666666667	test_acc:0.546	test_f1:0.500693599630619
epoch:34	train_loss:1.5929135084152222	train_acc:0.6666666666666666	test_acc:0.565	test_f1:0.5185646254922598
epoch:35	train_loss:1.588985562324524	train_acc:0.7083333333333334	test_acc:0.585	test_f1:0.5373746007532342
epoch:36	train_loss:1.598198652267456	train_acc:0.65	test_acc:0.601	test_f1:0.5541435477119787
epoch:37	train_loss:1.5650653839111328	train_acc:0.725	test_acc:0.61	test_f1:0.5666580298494858
epoch:38	train_loss:1.5399073362350464	train_acc:0.75	test_acc:0.618	test_f1:0.5753095957257175
epoch:39	train_loss:1.5352197885513306	train_acc:0.7166666666666667	test_acc:0.627	test_f1:0.5879411929998472
epoch:40	train_loss:1.53977370262146	train_acc:0.6916666666666667	test_acc:0.625	test_f1:0.5857901371026383
epoch:41	train_loss:1.510908842086792	train_acc:0.7083333333333334	test_acc:0.631	test_f1:0.594102117743755
epoch:42	train_loss:1.5105092525482178	train_acc:0.7166666666666667	test_acc:0.641	test_f1:0.6045560300781685
epoch:43	train_loss:1.4901436567306519	train_acc:0.7	test_acc:0.644	test_f1:0.6089641180183457
epoch:44	train_loss:1.4754081964492798	train_acc:0.7583333333333333	test_acc:0.655	test_f1:0.6200179750942246
epoch:45	train_loss:1.458604097366333	train_acc:0.725	test_acc:0.676	test_f1:0.6387046079168804
epoch:46	train_loss:1.4348886013031006	train_acc:0.7416666666666667	test_acc:0.693	test_f1:0.6542024587937765
epoch:47	train_loss:1.4290668964385986	train_acc:0.8	test_acc:0.689	test_f1:0.6500886810241867
epoch:48	train_loss:1.4003846645355225	train_acc:0.7833333333333333	test_acc:0.684	test_f1:0.647856759602823
epoch:49	train_loss:1.3772870302200317	train_acc:0.7916666666666666	test_acc:0.671	test_f1:0.6391358396208808
epoch:50	train_loss:1.3810604810714722	train_acc:0.7416666666666667	test_acc:0.659	test_f1:0.6282780242907365
训练并测试结束，共训练50轮，总用时2.089853525161743s
最佳正确率为:0.693,对应的macro_f1为:0.6542024587937765,对应的训练轮次为:46



2022-07-01 20:14:17.274958
epoch:1	train_loss:1.8402221202850342	train_acc:0.19166666666666668	test_acc:0.168	test_f1:0.05479615526481373
epoch:2	train_loss:1.832040548324585	train_acc:0.12916666666666668	test_acc:0.171	test_f1:0.06387816387816388
epoch:3	train_loss:1.8227752447128296	train_acc:0.18333333333333332	test_acc:0.175	test_f1:0.07707991242474001
epoch:4	train_loss:1.8127459287643433	train_acc:0.19166666666666668	test_acc:0.182	test_f1:0.09292018565015597
epoch:5	train_loss:1.8041261434555054	train_acc:0.225	test_acc:0.189	test_f1:0.10535535535535535
epoch:6	train_loss:1.7955199480056763	train_acc:0.16666666666666666	test_acc:0.192	test_f1:0.11954810782449006
epoch:7	train_loss:1.800059199333191	train_acc:0.20833333333333334	test_acc:0.193	test_f1:0.12745190346169535
epoch:8	train_loss:1.7850316762924194	train_acc:0.19583333333333333	test_acc:0.196	test_f1:0.13250015706629162
epoch:9	train_loss:1.7828540802001953	train_acc:0.22916666666666666	test_acc:0.201	test_f1:0.13643801484747065
epoch:10	train_loss:1.7864835262298584	train_acc:0.22083333333333333	test_acc:0.27	test_f1:0.21187205520867247
epoch:11	train_loss:1.775943398475647	train_acc:0.225	test_acc:0.354	test_f1:0.23520361243398183
epoch:12	train_loss:1.7756279706954956	train_acc:0.25	test_acc:0.32	test_f1:0.19570462602452246
epoch:13	train_loss:1.766522765159607	train_acc:0.24583333333333332	test_acc:0.38	test_f1:0.22433702791461416
epoch:14	train_loss:1.772500991821289	train_acc:0.21666666666666667	test_acc:0.37	test_f1:0.18758088438493217
epoch:15	train_loss:1.760857105255127	train_acc:0.25416666666666665	test_acc:0.336	test_f1:0.18342708548940537
epoch:16	train_loss:1.7699687480926514	train_acc:0.19583333333333333	test_acc:0.267	test_f1:0.1453668908401873
epoch:17	train_loss:1.7655013799667358	train_acc:0.2875	test_acc:0.253	test_f1:0.136773010303937
epoch:18	train_loss:1.7607436180114746	train_acc:0.2625	test_acc:0.251	test_f1:0.13758258578188945
epoch:19	train_loss:1.742501139640808	train_acc:0.31666666666666665	test_acc:0.255	test_f1:0.15340119780267217
epoch:20	train_loss:1.7441116571426392	train_acc:0.30833333333333335	test_acc:0.255	test_f1:0.16424376208188254
epoch:21	train_loss:1.746393084526062	train_acc:0.275	test_acc:0.292	test_f1:0.2084259059681138
epoch:22	train_loss:1.7475281953811646	train_acc:0.31666666666666665	test_acc:0.397	test_f1:0.33263827364735
epoch:23	train_loss:1.7407081127166748	train_acc:0.31666666666666665	test_acc:0.482	test_f1:0.4181877630620139
epoch:24	train_loss:1.7395704984664917	train_acc:0.3125	test_acc:0.56	test_f1:0.49775608837170987
epoch:25	train_loss:1.7347328662872314	train_acc:0.32916666666666666	test_acc:0.629	test_f1:0.5642239818957081
epoch:26	train_loss:1.7339996099472046	train_acc:0.39166666666666666	test_acc:0.684	test_f1:0.6185666150053329
epoch:27	train_loss:1.7286521196365356	train_acc:0.4	test_acc:0.682	test_f1:0.6199381902569167
epoch:28	train_loss:1.7206584215164185	train_acc:0.43333333333333335	test_acc:0.682	test_f1:0.6216706280831497
epoch:29	train_loss:1.7200959920883179	train_acc:0.43333333333333335	test_acc:0.651	test_f1:0.5989818317423689
epoch:30	train_loss:1.7056376934051514	train_acc:0.49583333333333335	test_acc:0.639	test_f1:0.5911437721131432
epoch:31	train_loss:1.6875898838043213	train_acc:0.5458333333333333	test_acc:0.632	test_f1:0.5886337732738186
epoch:32	train_loss:1.6911735534667969	train_acc:0.5541666666666667	test_acc:0.634	test_f1:0.5919608682455894
epoch:33	train_loss:1.6847331523895264	train_acc:0.5291666666666667	test_acc:0.642	test_f1:0.5991988888650271
epoch:34	train_loss:1.6835830211639404	train_acc:0.5458333333333333	test_acc:0.645	test_f1:0.5963998762716155
epoch:35	train_loss:1.6656594276428223	train_acc:0.5458333333333333	test_acc:0.65	test_f1:0.5994308242246938
epoch:36	train_loss:1.6718555688858032	train_acc:0.55	test_acc:0.661	test_f1:0.6081488499100377
epoch:37	train_loss:1.6599806547164917	train_acc:0.5541666666666667	test_acc:0.663	test_f1:0.6082826882084019
epoch:38	train_loss:1.658070683479309	train_acc:0.5791666666666667	test_acc:0.659	test_f1:0.6041376298331312
epoch:39	train_loss:1.6498210430145264	train_acc:0.6166666666666667	test_acc:0.672	test_f1:0.6211698540897236
epoch:40	train_loss:1.6548949480056763	train_acc:0.5583333333333333	test_acc:0.69	test_f1:0.6391402613378818
epoch:41	train_loss:1.6289533376693726	train_acc:0.6416666666666667	test_acc:0.698	test_f1:0.6438359998821204
epoch:42	train_loss:1.6406086683273315	train_acc:0.6125	test_acc:0.71	test_f1:0.6529323042133998
epoch:43	train_loss:1.614722490310669	train_acc:0.6458333333333334	test_acc:0.722	test_f1:0.6627006576611618
epoch:44	train_loss:1.6067900657653809	train_acc:0.6666666666666666	test_acc:0.724	test_f1:0.6640285227720736
epoch:45	train_loss:1.591910719871521	train_acc:0.625	test_acc:0.728	test_f1:0.6673728064240355
epoch:46	train_loss:1.5832843780517578	train_acc:0.6458333333333334	test_acc:0.731	test_f1:0.6701370474023114
epoch:47	train_loss:1.5737091302871704	train_acc:0.6958333333333333	test_acc:0.728	test_f1:0.6694714011056089
epoch:48	train_loss:1.5743367671966553	train_acc:0.675	test_acc:0.729	test_f1:0.6702833681748888
epoch:49	train_loss:1.5525832176208496	train_acc:0.6916666666666667	test_acc:0.727	test_f1:0.6683928938421767
epoch:50	train_loss:1.5459352731704712	train_acc:0.7041666666666667	test_acc:0.726	test_f1:0.6710962549210366
训练并测试结束，共训练50轮，总用时2.077528715133667s
最佳正确率为:0.731,对应的macro_f1为:0.6701370474023114,对应的训练轮次为:46



2022-07-01 20:14:26.099973
epoch:1	train_loss:1.8117294311523438	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:2	train_loss:1.8083032369613647	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:3	train_loss:1.8068816661834717	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:4	train_loss:1.7954562902450562	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:5	train_loss:1.7953146696090698	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:6	train_loss:1.7950842380523682	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:7	train_loss:1.7921656370162964	train_acc:0.16666666666666666	test_acc:0.231	test_f1:0.06255077173030056
epoch:8	train_loss:1.7867095470428467	train_acc:0.1625	test_acc:0.231	test_f1:0.06255077173030056
epoch:9	train_loss:1.7831394672393799	train_acc:0.17083333333333334	test_acc:0.231	test_f1:0.06255077173030056
epoch:10	train_loss:1.780807375907898	train_acc:0.17916666666666667	test_acc:0.231	test_f1:0.06255077173030056
epoch:11	train_loss:1.7779134511947632	train_acc:0.2125	test_acc:0.231	test_f1:0.06255077173030056
epoch:12	train_loss:1.7786329984664917	train_acc:0.22083333333333333	test_acc:0.243	test_f1:0.09052034773339428
epoch:13	train_loss:1.7733738422393799	train_acc:0.25416666666666665	test_acc:0.292	test_f1:0.16612979439464934
epoch:14	train_loss:1.7736917734146118	train_acc:0.2833333333333333	test_acc:0.38	test_f1:0.2591200984855592
epoch:15	train_loss:1.773796796798706	train_acc:0.24583333333333332	test_acc:0.403	test_f1:0.28874578486771935
epoch:16	train_loss:1.7661325931549072	train_acc:0.3458333333333333	test_acc:0.412	test_f1:0.30234986325131513
epoch:17	train_loss:1.7565739154815674	train_acc:0.38333333333333336	test_acc:0.455	test_f1:0.39681075874503496
epoch:18	train_loss:1.7601723670959473	train_acc:0.425	test_acc:0.442	test_f1:0.3872558211728991
epoch:19	train_loss:1.756786584854126	train_acc:0.38333333333333336	test_acc:0.39	test_f1:0.3110243799479405
epoch:20	train_loss:1.7486518621444702	train_acc:0.44166666666666665	test_acc:0.381	test_f1:0.30656632767851005
epoch:21	train_loss:1.753189206123352	train_acc:0.375	test_acc:0.377	test_f1:0.3080780006521149
epoch:22	train_loss:1.7465534210205078	train_acc:0.4	test_acc:0.385	test_f1:0.31608009082097116
epoch:23	train_loss:1.73867666721344	train_acc:0.42916666666666664	test_acc:0.389	test_f1:0.3275903739223653
epoch:24	train_loss:1.7298495769500732	train_acc:0.475	test_acc:0.382	test_f1:0.3259921551728342
epoch:25	train_loss:1.7358129024505615	train_acc:0.44583333333333336	test_acc:0.404	test_f1:0.365999756023007
epoch:26	train_loss:1.729013204574585	train_acc:0.48333333333333334	test_acc:0.431	test_f1:0.4011514560506311
epoch:27	train_loss:1.725792407989502	train_acc:0.4708333333333333	test_acc:0.449	test_f1:0.41925398771847905
epoch:28	train_loss:1.7236943244934082	train_acc:0.4125	test_acc:0.466	test_f1:0.4334521937403016
epoch:29	train_loss:1.7130690813064575	train_acc:0.4791666666666667	test_acc:0.475	test_f1:0.43947142800125505
epoch:30	train_loss:1.7130379676818848	train_acc:0.49583333333333335	test_acc:0.482	test_f1:0.4391133591775065
epoch:31	train_loss:1.709688425064087	train_acc:0.49166666666666664	test_acc:0.494	test_f1:0.44696562071085894
epoch:32	train_loss:1.6943873167037964	train_acc:0.55	test_acc:0.515	test_f1:0.4699475371387371
epoch:33	train_loss:1.69985830783844	train_acc:0.55	test_acc:0.529	test_f1:0.4834675680892467
epoch:34	train_loss:1.6908345222473145	train_acc:0.6125	test_acc:0.55	test_f1:0.5117072502534121
epoch:35	train_loss:1.6705825328826904	train_acc:0.6166666666666667	test_acc:0.588	test_f1:0.5523003534712007
epoch:36	train_loss:1.6686660051345825	train_acc:0.6291666666666667	test_acc:0.6	test_f1:0.5658625179736013
epoch:37	train_loss:1.6563931703567505	train_acc:0.65	test_acc:0.63	test_f1:0.5927198150542807
epoch:38	train_loss:1.664601445198059	train_acc:0.6708333333333333	test_acc:0.646	test_f1:0.6062797068308216
epoch:39	train_loss:1.6498137712478638	train_acc:0.675	test_acc:0.657	test_f1:0.6192504017877104
epoch:40	train_loss:1.6284428834915161	train_acc:0.7208333333333333	test_acc:0.673	test_f1:0.6351499971353648
epoch:41	train_loss:1.629571557044983	train_acc:0.7166666666666667	test_acc:0.679	test_f1:0.645590724224634
epoch:42	train_loss:1.6255451440811157	train_acc:0.6833333333333333	test_acc:0.678	test_f1:0.6466145604970966
epoch:43	train_loss:1.619844913482666	train_acc:0.6708333333333333	test_acc:0.673	test_f1:0.6421259085743545
epoch:44	train_loss:1.60340416431427	train_acc:0.7083333333333334	test_acc:0.675	test_f1:0.6440892879550429
epoch:45	train_loss:1.595639705657959	train_acc:0.7166666666666667	test_acc:0.668	test_f1:0.633949211492013
epoch:46	train_loss:1.5985150337219238	train_acc:0.7	test_acc:0.665	test_f1:0.6262010894700768
epoch:47	train_loss:1.5782266855239868	train_acc:0.7541666666666667	test_acc:0.674	test_f1:0.6334588437709584
epoch:48	train_loss:1.5490977764129639	train_acc:0.775	test_acc:0.684	test_f1:0.6413957468757882
epoch:49	train_loss:1.550349473953247	train_acc:0.7625	test_acc:0.687	test_f1:0.6417417828448432
epoch:50	train_loss:1.5372028350830078	train_acc:0.7291666666666666	test_acc:0.693	test_f1:0.6461977663160984
训练并测试结束，共训练50轮，总用时2.1924405097961426s
最佳正确率为:0.693,对应的macro_f1为:0.6461977663160984,对应的训练轮次为:50



2022-07-01 20:14:46.936449
epoch:1	train_loss:1.840857982635498	train_acc:0.16944444444444445	test_acc:0.077	test_f1:0.023831631073970908
epoch:2	train_loss:1.8264774084091187	train_acc:0.1527777777777778	test_acc:0.076	test_f1:0.023543990086741018
epoch:3	train_loss:1.8096503019332886	train_acc:0.19722222222222222	test_acc:0.078	test_f1:0.02644669614588911
epoch:4	train_loss:1.8058346509933472	train_acc:0.175	test_acc:0.078	test_f1:0.02647713290923846
epoch:5	train_loss:1.7990113496780396	train_acc:0.18055555555555555	test_acc:0.081	test_f1:0.029587190341070605
epoch:6	train_loss:1.7920435667037964	train_acc:0.20277777777777778	test_acc:0.083	test_f1:0.03233060916941981
epoch:7	train_loss:1.784280776977539	train_acc:0.19444444444444445	test_acc:0.088	test_f1:0.03907338508413333
epoch:8	train_loss:1.786054015159607	train_acc:0.24722222222222223	test_acc:0.09	test_f1:0.04178341218440434
epoch:9	train_loss:1.7805883884429932	train_acc:0.20277777777777778	test_acc:0.098	test_f1:0.051910731272442924
epoch:10	train_loss:1.7721741199493408	train_acc:0.26944444444444443	test_acc:0.107	test_f1:0.06857533760881492
epoch:11	train_loss:1.7707170248031616	train_acc:0.24166666666666667	test_acc:0.164	test_f1:0.1531953236519004
epoch:12	train_loss:1.7628660202026367	train_acc:0.3	test_acc:0.298	test_f1:0.314086644274758
epoch:13	train_loss:1.7621756792068481	train_acc:0.3	test_acc:0.378	test_f1:0.3084230710314995
epoch:14	train_loss:1.7649853229522705	train_acc:0.2638888888888889	test_acc:0.372	test_f1:0.28874919367544777
epoch:15	train_loss:1.7604551315307617	train_acc:0.25555555555555554	test_acc:0.36	test_f1:0.27523551957581993
epoch:16	train_loss:1.7649102210998535	train_acc:0.2388888888888889	test_acc:0.371	test_f1:0.28655012526303325
epoch:17	train_loss:1.7461844682693481	train_acc:0.33611111111111114	test_acc:0.402	test_f1:0.3117976575409886
epoch:18	train_loss:1.750412106513977	train_acc:0.29444444444444445	test_acc:0.436	test_f1:0.3363915718929269
epoch:19	train_loss:1.7557613849639893	train_acc:0.3138888888888889	test_acc:0.471	test_f1:0.3688839523881105
epoch:20	train_loss:1.7436177730560303	train_acc:0.3527777777777778	test_acc:0.513	test_f1:0.4064767300252709
epoch:21	train_loss:1.7370227575302124	train_acc:0.37777777777777777	test_acc:0.56	test_f1:0.4677328008708231
epoch:22	train_loss:1.7402652502059937	train_acc:0.4166666666666667	test_acc:0.651	test_f1:0.5905794847342368
epoch:23	train_loss:1.7282353639602661	train_acc:0.4444444444444444	test_acc:0.705	test_f1:0.6468094567371777
epoch:24	train_loss:1.7203645706176758	train_acc:0.475	test_acc:0.734	test_f1:0.6755501191193535
epoch:25	train_loss:1.7137378454208374	train_acc:0.5166666666666667	test_acc:0.749	test_f1:0.6902221822593523
epoch:26	train_loss:1.7107744216918945	train_acc:0.5277777777777778	test_acc:0.748	test_f1:0.6854051969548339
epoch:27	train_loss:1.7119567394256592	train_acc:0.5138888888888888	test_acc:0.716	test_f1:0.6561108292765991
epoch:28	train_loss:1.6987148523330688	train_acc:0.5611111111111111	test_acc:0.703	test_f1:0.6465807132322244
epoch:29	train_loss:1.6984002590179443	train_acc:0.5583333333333333	test_acc:0.685	test_f1:0.6273364696087703
epoch:30	train_loss:1.6892439126968384	train_acc:0.5694444444444444	test_acc:0.678	test_f1:0.625257869956108
epoch:31	train_loss:1.6833107471466064	train_acc:0.6	test_acc:0.684	test_f1:0.6379004413109072
epoch:32	train_loss:1.6749255657196045	train_acc:0.6138888888888889	test_acc:0.692	test_f1:0.6517571596428091
epoch:33	train_loss:1.6802946329116821	train_acc:0.5583333333333333	test_acc:0.699	test_f1:0.6621055379783899
epoch:34	train_loss:1.672039270401001	train_acc:0.5861111111111111	test_acc:0.701	test_f1:0.6637922047270233
epoch:35	train_loss:1.660400390625	train_acc:0.6472222222222223	test_acc:0.716	test_f1:0.6801313663193785
epoch:36	train_loss:1.6512622833251953	train_acc:0.6416666666666667	test_acc:0.728	test_f1:0.6945859975521355
epoch:37	train_loss:1.6440201997756958	train_acc:0.6472222222222223	test_acc:0.738	test_f1:0.7046768997925459
epoch:38	train_loss:1.6438658237457275	train_acc:0.675	test_acc:0.743	test_f1:0.7054330812430151
epoch:39	train_loss:1.6237250566482544	train_acc:0.7083333333333334	test_acc:0.747	test_f1:0.7037405547746961
epoch:40	train_loss:1.622150182723999	train_acc:0.6805555555555556	test_acc:0.748	test_f1:0.6981843735019342
epoch:41	train_loss:1.6240510940551758	train_acc:0.6638888888888889	test_acc:0.75	test_f1:0.6948216152056751
epoch:42	train_loss:1.6080322265625	train_acc:0.675	test_acc:0.75	test_f1:0.6910205249710207
epoch:43	train_loss:1.5968018770217896	train_acc:0.6666666666666666	test_acc:0.749	test_f1:0.6879938399098675
epoch:44	train_loss:1.6044065952301025	train_acc:0.6611111111111111	test_acc:0.749	test_f1:0.6877708085944976
epoch:45	train_loss:1.5874022245407104	train_acc:0.6583333333333333	test_acc:0.751	test_f1:0.6897660411523742
epoch:46	train_loss:1.5783895254135132	train_acc:0.6972222222222222	test_acc:0.749	test_f1:0.6880300654981846
epoch:47	train_loss:1.5752731561660767	train_acc:0.6472222222222223	test_acc:0.754	test_f1:0.689919746894379
epoch:48	train_loss:1.551812767982483	train_acc:0.6972222222222222	test_acc:0.758	test_f1:0.6933697683551848
epoch:49	train_loss:1.541144609451294	train_acc:0.6888888888888889	test_acc:0.759	test_f1:0.6966159457373302
epoch:50	train_loss:1.5259958505630493	train_acc:0.7055555555555556	test_acc:0.759	test_f1:0.6965985167696992
训练并测试结束，共训练50轮，总用时2.100040912628174s
最佳正确率为:0.759,对应的macro_f1为:0.6965985167696992,对应的训练轮次为:50



2022-07-01 20:14:55.285941
epoch:1	train_loss:1.8268935680389404	train_acc:0.16666666666666666	test_acc:0.181	test_f1:0.05108664973186564
epoch:2	train_loss:1.8159903287887573	train_acc:0.16666666666666666	test_acc:0.181	test_f1:0.05108664973186564
epoch:3	train_loss:1.810023307800293	train_acc:0.1638888888888889	test_acc:0.181	test_f1:0.05108664973186564
epoch:4	train_loss:1.803743600845337	train_acc:0.16944444444444445	test_acc:0.181	test_f1:0.05108664973186564
epoch:5	train_loss:1.8004404306411743	train_acc:0.16666666666666666	test_acc:0.181	test_f1:0.05108664973186564
epoch:6	train_loss:1.7917003631591797	train_acc:0.16666666666666666	test_acc:0.181	test_f1:0.05108664973186564
epoch:7	train_loss:1.795173168182373	train_acc:0.16944444444444445	test_acc:0.181	test_f1:0.05108664973186564
epoch:8	train_loss:1.7904925346374512	train_acc:0.1638888888888889	test_acc:0.181	test_f1:0.05108664973186564
epoch:9	train_loss:1.7848467826843262	train_acc:0.18611111111111112	test_acc:0.181	test_f1:0.05108664973186564
epoch:10	train_loss:1.7823290824890137	train_acc:0.21666666666666667	test_acc:0.182	test_f1:0.05301855335811193
epoch:11	train_loss:1.7825336456298828	train_acc:0.20277777777777778	test_acc:0.251	test_f1:0.13388778175801513
epoch:12	train_loss:1.7734622955322266	train_acc:0.25277777777777777	test_acc:0.318	test_f1:0.15708387942332894
epoch:13	train_loss:1.7686349153518677	train_acc:0.22777777777777777	test_acc:0.272	test_f1:0.16046442920065832
epoch:14	train_loss:1.767797827720642	train_acc:0.23333333333333334	test_acc:0.214	test_f1:0.10245793155605976
epoch:15	train_loss:1.7630599737167358	train_acc:0.2388888888888889	test_acc:0.185	test_f1:0.05689081879755626
epoch:16	train_loss:1.7623380422592163	train_acc:0.24444444444444444	test_acc:0.183	test_f1:0.05320039824696895
epoch:17	train_loss:1.7589555978775024	train_acc:0.25277777777777777	test_acc:0.183	test_f1:0.053329680729192606
epoch:18	train_loss:1.7544771432876587	train_acc:0.2972222222222222	test_acc:0.206	test_f1:0.09302040351476604
epoch:19	train_loss:1.7532382011413574	train_acc:0.28055555555555556	test_acc:0.296	test_f1:0.1842636617218207
epoch:20	train_loss:1.748039960861206	train_acc:0.35	test_acc:0.335	test_f1:0.19809019979587605
epoch:21	train_loss:1.7464134693145752	train_acc:0.38333333333333336	test_acc:0.345	test_f1:0.22181896038128032
epoch:22	train_loss:1.7391784191131592	train_acc:0.40555555555555556	test_acc:0.319	test_f1:0.23619936004348507
epoch:23	train_loss:1.7362420558929443	train_acc:0.3861111111111111	test_acc:0.307	test_f1:0.23755220486485304
epoch:24	train_loss:1.7265561819076538	train_acc:0.45	test_acc:0.299	test_f1:0.24719200013287823
epoch:25	train_loss:1.7375617027282715	train_acc:0.375	test_acc:0.32	test_f1:0.28069738830655916
epoch:26	train_loss:1.731200098991394	train_acc:0.38055555555555554	test_acc:0.353	test_f1:0.3235987776175244
epoch:27	train_loss:1.7249469757080078	train_acc:0.43333333333333335	test_acc:0.414	test_f1:0.40500764405655953
epoch:28	train_loss:1.709868311882019	train_acc:0.4666666666666667	test_acc:0.49	test_f1:0.4784719783386902
epoch:29	train_loss:1.7141165733337402	train_acc:0.45555555555555555	test_acc:0.571	test_f1:0.563820435871382
epoch:30	train_loss:1.6951069831848145	train_acc:0.5555555555555556	test_acc:0.617	test_f1:0.603837956089137
epoch:31	train_loss:1.699061393737793	train_acc:0.5222222222222223	test_acc:0.641	test_f1:0.621911034184332
epoch:32	train_loss:1.6914677619934082	train_acc:0.5638888888888889	test_acc:0.665	test_f1:0.6457890658432113
epoch:33	train_loss:1.689208984375	train_acc:0.5805555555555556	test_acc:0.676	test_f1:0.6529961730046422
epoch:34	train_loss:1.6755266189575195	train_acc:0.6194444444444445	test_acc:0.691	test_f1:0.6675509056738381
epoch:35	train_loss:1.6722230911254883	train_acc:0.6194444444444445	test_acc:0.694	test_f1:0.6700343619512384
epoch:36	train_loss:1.6549787521362305	train_acc:0.6583333333333333	test_acc:0.709	test_f1:0.6824734901569718
epoch:37	train_loss:1.6446895599365234	train_acc:0.675	test_acc:0.719	test_f1:0.6914591829086082
epoch:38	train_loss:1.6474381685256958	train_acc:0.6638888888888889	test_acc:0.721	test_f1:0.6925197553965523
epoch:39	train_loss:1.6411337852478027	train_acc:0.6583333333333333	test_acc:0.726	test_f1:0.6938588990870801
epoch:40	train_loss:1.6310769319534302	train_acc:0.6805555555555556	test_acc:0.734	test_f1:0.6981061466599549
epoch:41	train_loss:1.630138635635376	train_acc:0.6638888888888889	test_acc:0.733	test_f1:0.6974266327180456
epoch:42	train_loss:1.6050752401351929	train_acc:0.7	test_acc:0.733	test_f1:0.701266277900796
epoch:43	train_loss:1.604644775390625	train_acc:0.7	test_acc:0.72	test_f1:0.6892319697404443
epoch:44	train_loss:1.5927951335906982	train_acc:0.7194444444444444	test_acc:0.71	test_f1:0.6795722677388047
epoch:45	train_loss:1.5849263668060303	train_acc:0.6888888888888889	test_acc:0.708	test_f1:0.6774173079967983
epoch:46	train_loss:1.5666370391845703	train_acc:0.7055555555555556	test_acc:0.713	test_f1:0.6825620358826802
epoch:47	train_loss:1.5625072717666626	train_acc:0.7	test_acc:0.714	test_f1:0.6837682945907636
epoch:48	train_loss:1.5482481718063354	train_acc:0.7083333333333334	test_acc:0.715	test_f1:0.6845281369289661
epoch:49	train_loss:1.5415922403335571	train_acc:0.7527777777777778	test_acc:0.708	test_f1:0.6756959430795763
epoch:50	train_loss:1.536059856414795	train_acc:0.7166666666666667	test_acc:0.711	test_f1:0.6786748367391172
训练并测试结束，共训练50轮，总用时2.1384782791137695s
最佳正确率为:0.734,对应的macro_f1为:0.6981061466599549,对应的训练轮次为:40



2022-07-01 20:15:03.512725
epoch:1	train_loss:1.812267541885376	train_acc:0.18611111111111112	test_acc:0.181	test_f1:0.05108664973186564
epoch:2	train_loss:1.8019577264785767	train_acc:0.18055555555555555	test_acc:0.181	test_f1:0.05108664973186564
epoch:3	train_loss:1.7875508069992065	train_acc:0.18888888888888888	test_acc:0.181	test_f1:0.05108664973186564
epoch:4	train_loss:1.7876394987106323	train_acc:0.19444444444444445	test_acc:0.181	test_f1:0.05108664973186564
epoch:5	train_loss:1.787535548210144	train_acc:0.2222222222222222	test_acc:0.181	test_f1:0.05108664973186564
epoch:6	train_loss:1.7783774137496948	train_acc:0.18888888888888888	test_acc:0.181	test_f1:0.05108664973186564
epoch:7	train_loss:1.7799060344696045	train_acc:0.21944444444444444	test_acc:0.184	test_f1:0.05614837526009283
epoch:8	train_loss:1.775336503982544	train_acc:0.2111111111111111	test_acc:0.326	test_f1:0.22544532483043336
epoch:9	train_loss:1.7597025632858276	train_acc:0.25277777777777777	test_acc:0.391	test_f1:0.2528836630423134
epoch:10	train_loss:1.7605425119400024	train_acc:0.2777777777777778	test_acc:0.281	test_f1:0.17294959330591295
epoch:11	train_loss:1.7594066858291626	train_acc:0.30277777777777776	test_acc:0.262	test_f1:0.1465807483685058
epoch:12	train_loss:1.742340087890625	train_acc:0.3416666666666667	test_acc:0.261	test_f1:0.1490535786557081
epoch:13	train_loss:1.7548595666885376	train_acc:0.2722222222222222	test_acc:0.267	test_f1:0.16274551345226465
epoch:14	train_loss:1.7422512769699097	train_acc:0.30277777777777776	test_acc:0.277	test_f1:0.19582920333331974
epoch:15	train_loss:1.7322075366973877	train_acc:0.38055555555555554	test_acc:0.299	test_f1:0.2411174626828951
epoch:16	train_loss:1.7301831245422363	train_acc:0.3472222222222222	test_acc:0.34	test_f1:0.30011589225415247
epoch:17	train_loss:1.7398757934570312	train_acc:0.3416666666666667	test_acc:0.381	test_f1:0.34691694596108774
epoch:18	train_loss:1.7202750444412231	train_acc:0.37222222222222223	test_acc:0.433	test_f1:0.37814483511005226
epoch:19	train_loss:1.7224161624908447	train_acc:0.39166666666666666	test_acc:0.49	test_f1:0.4102204339760984
epoch:20	train_loss:1.717051386833191	train_acc:0.38055555555555554	test_acc:0.552	test_f1:0.4824814572031724
epoch:21	train_loss:1.7155041694641113	train_acc:0.4388888888888889	test_acc:0.606	test_f1:0.5538030284878058
epoch:22	train_loss:1.7047110795974731	train_acc:0.4444444444444444	test_acc:0.645	test_f1:0.5952067721719795
epoch:23	train_loss:1.694124698638916	train_acc:0.4861111111111111	test_acc:0.662	test_f1:0.6092241096564822
epoch:24	train_loss:1.6919126510620117	train_acc:0.4722222222222222	test_acc:0.687	test_f1:0.6368256980580468
epoch:25	train_loss:1.686874270439148	train_acc:0.525	test_acc:0.718	test_f1:0.6650527384416854
epoch:26	train_loss:1.6609641313552856	train_acc:0.5888888888888889	test_acc:0.742	test_f1:0.6902777653971582
epoch:27	train_loss:1.6719003915786743	train_acc:0.5944444444444444	test_acc:0.749	test_f1:0.6937968832909694
epoch:28	train_loss:1.6633882522583008	train_acc:0.6194444444444445	test_acc:0.744	test_f1:0.6911353392996619
epoch:29	train_loss:1.6579155921936035	train_acc:0.6083333333333333	test_acc:0.742	test_f1:0.6919831623058957
epoch:30	train_loss:1.6346431970596313	train_acc:0.6444444444444445	test_acc:0.74	test_f1:0.6917111963401122
epoch:31	train_loss:1.6289730072021484	train_acc:0.6611111111111111	test_acc:0.732	test_f1:0.6858010745349623
epoch:32	train_loss:1.624704122543335	train_acc:0.6472222222222223	test_acc:0.717	test_f1:0.6707231392924501
epoch:33	train_loss:1.6114444732666016	train_acc:0.6805555555555556	test_acc:0.71	test_f1:0.6653515860060067
epoch:34	train_loss:1.6101292371749878	train_acc:0.6805555555555556	test_acc:0.706	test_f1:0.6613961292567273
epoch:35	train_loss:1.6034107208251953	train_acc:0.6638888888888889	test_acc:0.715	test_f1:0.6706484480257672
epoch:36	train_loss:1.5979729890823364	train_acc:0.65	test_acc:0.736	test_f1:0.6886064244969621
epoch:37	train_loss:1.5812984704971313	train_acc:0.675	test_acc:0.747	test_f1:0.6981023271352784
epoch:38	train_loss:1.5665318965911865	train_acc:0.7	test_acc:0.751	test_f1:0.6991182639114721
epoch:39	train_loss:1.5529154539108276	train_acc:0.7027777777777777	test_acc:0.748	test_f1:0.696357466694313
epoch:40	train_loss:1.528279423713684	train_acc:0.7555555555555555	test_acc:0.748	test_f1:0.6899847162714127
epoch:41	train_loss:1.5436928272247314	train_acc:0.7027777777777777	test_acc:0.748	test_f1:0.6885314169433387
epoch:42	train_loss:1.5102510452270508	train_acc:0.7444444444444445	test_acc:0.747	test_f1:0.690508240099291
epoch:43	train_loss:1.5130317211151123	train_acc:0.7222222222222222	test_acc:0.746	test_f1:0.6959297796374272
epoch:44	train_loss:1.4970743656158447	train_acc:0.7555555555555555	test_acc:0.748	test_f1:0.699040520915544
epoch:45	train_loss:1.4822561740875244	train_acc:0.7333333333333333	test_acc:0.752	test_f1:0.7102891750673156
epoch:46	train_loss:1.4616190195083618	train_acc:0.7111111111111111	test_acc:0.753	test_f1:0.7126373362638662
epoch:47	train_loss:1.4541815519332886	train_acc:0.7611111111111111	test_acc:0.751	test_f1:0.712140345924359
epoch:48	train_loss:1.4695202112197876	train_acc:0.7138888888888889	test_acc:0.755	test_f1:0.714746945449733
epoch:49	train_loss:1.419851541519165	train_acc:0.7555555555555555	test_acc:0.758	test_f1:0.7175415705211914
epoch:50	train_loss:1.4180939197540283	train_acc:0.7833333333333333	test_acc:0.759	test_f1:0.7176456881433598
训练并测试结束，共训练50轮，总用时2.08785343170166s
最佳正确率为:0.759,对应的macro_f1为:0.7176456881433598,对应的训练轮次为:50



2022-07-01 20:31:04.714415
epoch:1	train_loss:1.1633027791976929	train_acc:0.3333333333333333	test_acc:0.407	test_f1:0.19284529732290925
epoch:2	train_loss:1.135208010673523	train_acc:0.3333333333333333	test_acc:0.407	test_f1:0.19284529732290925
epoch:3	train_loss:1.1377546787261963	train_acc:0.3333333333333333	test_acc:0.407	test_f1:0.19284529732290925
epoch:4	train_loss:1.148173213005066	train_acc:0.3333333333333333	test_acc:0.407	test_f1:0.19284529732290925
epoch:5	train_loss:1.12014901638031	train_acc:0.35	test_acc:0.407	test_f1:0.19284529732290925
epoch:6	train_loss:1.1037757396697998	train_acc:0.35	test_acc:0.407	test_f1:0.19284529732290925
epoch:7	train_loss:1.101645588874817	train_acc:0.36666666666666664	test_acc:0.406	test_f1:0.19250829777145564
epoch:8	train_loss:1.0999053716659546	train_acc:0.38333333333333336	test_acc:0.414	test_f1:0.21014161922154187
epoch:9	train_loss:1.0641155242919922	train_acc:0.48333333333333334	test_acc:0.446	test_f1:0.2673542475998063
epoch:10	train_loss:1.0675660371780396	train_acc:0.45	test_acc:0.5	test_f1:0.3413557592411584
epoch:11	train_loss:1.0487043857574463	train_acc:0.5	test_acc:0.542	test_f1:0.38704751892214934
epoch:12	train_loss:1.0485949516296387	train_acc:0.5	test_acc:0.559	test_f1:0.40365189092378423
epoch:13	train_loss:1.0520228147506714	train_acc:0.5166666666666667	test_acc:0.577	test_f1:0.42011243138982995
epoch:14	train_loss:1.0119296312332153	train_acc:0.65	test_acc:0.599	test_f1:0.45950591347433617
epoch:15	train_loss:1.011037826538086	train_acc:0.6666666666666666	test_acc:0.64	test_f1:0.5756134829410692
epoch:16	train_loss:1.0086150169372559	train_acc:0.6	test_acc:0.687	test_f1:0.6656211003202798
epoch:17	train_loss:1.0119730234146118	train_acc:0.5833333333333334	test_acc:0.713	test_f1:0.7044735117304376
epoch:18	train_loss:1.0115330219268799	train_acc:0.7	test_acc:0.723	test_f1:0.7190238125750542
epoch:19	train_loss:0.9669142365455627	train_acc:0.75	test_acc:0.725	test_f1:0.7211218715967366
epoch:20	train_loss:0.9774357676506042	train_acc:0.65	test_acc:0.726	test_f1:0.7232168874348325
epoch:21	train_loss:0.983519434928894	train_acc:0.7166666666666667	test_acc:0.725	test_f1:0.7236983073245963
epoch:22	train_loss:0.9616310000419617	train_acc:0.7833333333333333	test_acc:0.721	test_f1:0.7191712697665503
epoch:23	train_loss:0.9701429605484009	train_acc:0.75	test_acc:0.721	test_f1:0.7183217495930356
epoch:24	train_loss:0.9353814721107483	train_acc:0.7333333333333333	test_acc:0.722	test_f1:0.718801322639336
epoch:25	train_loss:0.9330400228500366	train_acc:0.7666666666666667	test_acc:0.725	test_f1:0.7227784602784603
epoch:26	train_loss:0.9430556893348694	train_acc:0.8	test_acc:0.726	test_f1:0.7240264363944603
epoch:27	train_loss:0.9225525259971619	train_acc:0.75	test_acc:0.722	test_f1:0.7205692425200967
epoch:28	train_loss:0.8967563509941101	train_acc:0.8	test_acc:0.722	test_f1:0.7199910826938027
epoch:29	train_loss:0.863098680973053	train_acc:0.8666666666666667	test_acc:0.723	test_f1:0.720411193661739
epoch:30	train_loss:0.8774054050445557	train_acc:0.75	test_acc:0.725	test_f1:0.7223694347570668
epoch:31	train_loss:0.8845041394233704	train_acc:0.7833333333333333	test_acc:0.725	test_f1:0.722405024788649
epoch:32	train_loss:0.8563452959060669	train_acc:0.8	test_acc:0.727	test_f1:0.7240932879962848
epoch:33	train_loss:0.8377726674079895	train_acc:0.85	test_acc:0.729	test_f1:0.726840209461891
epoch:34	train_loss:0.8370717167854309	train_acc:0.8333333333333334	test_acc:0.728	test_f1:0.7257047420972548
epoch:35	train_loss:0.8388124704360962	train_acc:0.7833333333333333	test_acc:0.727	test_f1:0.7249157859490393
epoch:36	train_loss:0.7779030203819275	train_acc:0.9	test_acc:0.728	test_f1:0.7263210156867226
epoch:37	train_loss:0.8088889718055725	train_acc:0.9	test_acc:0.729	test_f1:0.7271468015229051
epoch:38	train_loss:0.784282922744751	train_acc:0.8166666666666667	test_acc:0.73	test_f1:0.7280553813335144
epoch:39	train_loss:0.7468512058258057	train_acc:0.9	test_acc:0.732	test_f1:0.7300229340475547
epoch:40	train_loss:0.748414933681488	train_acc:0.8833333333333333	test_acc:0.731	test_f1:0.7291759740165044
epoch:41	train_loss:0.7479916214942932	train_acc:0.8833333333333333	test_acc:0.732	test_f1:0.7297104712577248
epoch:42	train_loss:0.7046082019805908	train_acc:0.9	test_acc:0.733	test_f1:0.7305340558358709
epoch:43	train_loss:0.7016721367835999	train_acc:0.8833333333333333	test_acc:0.735	test_f1:0.7324999999999999
epoch:44	train_loss:0.6942380666732788	train_acc:0.8833333333333333	test_acc:0.737	test_f1:0.7341882147537465
epoch:45	train_loss:0.6608036160469055	train_acc:0.9	test_acc:0.736	test_f1:0.7338900178622026
epoch:46	train_loss:0.6600276827812195	train_acc:0.9333333333333333	test_acc:0.743	test_f1:0.7405691448109265
epoch:47	train_loss:0.6406633853912354	train_acc:0.8666666666666667	test_acc:0.745	test_f1:0.7424189685969743
epoch:48	train_loss:0.654697835445404	train_acc:0.85	test_acc:0.746	test_f1:0.7428500578233074
epoch:49	train_loss:0.6208938956260681	train_acc:0.9333333333333333	test_acc:0.746	test_f1:0.7430410035061842
epoch:50	train_loss:0.6097915172576904	train_acc:0.9166666666666666	test_acc:0.749	test_f1:0.745419301320213
训练并测试结束，共训练50轮，总用时30.429068326950073s
最佳正确率为:0.749,对应的macro_f1为:0.745419301320213,对应的训练轮次为:50



2022-07-01 20:31:55.620203
epoch:1	train_loss:1.1149054765701294	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:2	train_loss:1.1052268743515015	train_acc:0.35	test_acc:0.18	test_f1:0.1016949152542373
epoch:3	train_loss:1.0941684246063232	train_acc:0.38333333333333336	test_acc:0.18	test_f1:0.1016949152542373
epoch:4	train_loss:1.0773950815200806	train_acc:0.4	test_acc:0.18	test_f1:0.1016949152542373
epoch:5	train_loss:1.0965923070907593	train_acc:0.35	test_acc:0.181	test_f1:0.10339147644159262
epoch:6	train_loss:1.0703600645065308	train_acc:0.43333333333333335	test_acc:0.186	test_f1:0.11176119014608481
epoch:7	train_loss:1.0571664571762085	train_acc:0.5333333333333333	test_acc:0.333	test_f1:0.30698172201543833
epoch:8	train_loss:1.0472627878189087	train_acc:0.6	test_acc:0.688	test_f1:0.6795296700317731
epoch:9	train_loss:1.0574859380722046	train_acc:0.55	test_acc:0.708	test_f1:0.6976476228417076
epoch:10	train_loss:1.0359406471252441	train_acc:0.6333333333333333	test_acc:0.641	test_f1:0.5325207874415122
epoch:11	train_loss:1.0379998683929443	train_acc:0.6166666666666667	test_acc:0.626	test_f1:0.4748081414748082
epoch:12	train_loss:1.0511025190353394	train_acc:0.4666666666666667	test_acc:0.624	test_f1:0.4667591449414225
epoch:13	train_loss:1.0410772562026978	train_acc:0.5166666666666667	test_acc:0.624	test_f1:0.46618723005038043
epoch:14	train_loss:1.0292854309082031	train_acc:0.5833333333333334	test_acc:0.632	test_f1:0.47766997186893273
epoch:15	train_loss:1.0142194032669067	train_acc:0.5333333333333333	test_acc:0.632	test_f1:0.4839043856690915
epoch:16	train_loss:1.0394067764282227	train_acc:0.5	test_acc:0.653	test_f1:0.5440611346904097
epoch:17	train_loss:0.9981659054756165	train_acc:0.6166666666666667	test_acc:0.681	test_f1:0.6310443108700766
epoch:18	train_loss:0.97975754737854	train_acc:0.6666666666666666	test_acc:0.705	test_f1:0.6861727980916172
epoch:19	train_loss:0.9875410199165344	train_acc:0.6833333333333333	test_acc:0.716	test_f1:0.706302224547407
epoch:20	train_loss:0.9711294770240784	train_acc:0.8166666666666667	test_acc:0.724	test_f1:0.7189592590457412
epoch:21	train_loss:0.9574759602546692	train_acc:0.8	test_acc:0.724	test_f1:0.7217677562172415
epoch:22	train_loss:0.9516342878341675	train_acc:0.8	test_acc:0.73	test_f1:0.7307004281669899
epoch:23	train_loss:0.9528750777244568	train_acc:0.7833333333333333	test_acc:0.729	test_f1:0.7304299711813448
epoch:24	train_loss:0.9372159242630005	train_acc:0.8	test_acc:0.728	test_f1:0.7290019766926831
epoch:25	train_loss:0.9128363132476807	train_acc:0.8333333333333334	test_acc:0.732	test_f1:0.7314853896585443
epoch:26	train_loss:0.8870069980621338	train_acc:0.8666666666666667	test_acc:0.732	test_f1:0.7305067778634915
epoch:27	train_loss:0.9021078944206238	train_acc:0.7666666666666667	test_acc:0.737	test_f1:0.7346931810147906
epoch:28	train_loss:0.8545539379119873	train_acc:0.9166666666666666	test_acc:0.738	test_f1:0.735525790179237
epoch:29	train_loss:0.8597554564476013	train_acc:0.9	test_acc:0.734	test_f1:0.7310976444888232
epoch:30	train_loss:0.861748993396759	train_acc:0.85	test_acc:0.735	test_f1:0.7318442298953247
epoch:31	train_loss:0.8199490308761597	train_acc:0.9166666666666666	test_acc:0.734	test_f1:0.7308266445654802
epoch:32	train_loss:0.8310301899909973	train_acc:0.8833333333333333	test_acc:0.738	test_f1:0.7350527592512028
epoch:33	train_loss:0.8073097467422485	train_acc:0.8666666666666667	test_acc:0.74	test_f1:0.7369313488413911
epoch:34	train_loss:0.7825000286102295	train_acc:0.8666666666666667	test_acc:0.743	test_f1:0.740285939876144
epoch:35	train_loss:0.7653042674064636	train_acc:0.9166666666666666	test_acc:0.747	test_f1:0.7445180740561762
epoch:36	train_loss:0.7896579504013062	train_acc:0.8833333333333333	test_acc:0.748	test_f1:0.745666349208164
epoch:37	train_loss:0.7608495354652405	train_acc:0.85	test_acc:0.756	test_f1:0.7535773004652199
epoch:38	train_loss:0.7515980005264282	train_acc:0.9	test_acc:0.752	test_f1:0.7491254938000534
epoch:39	train_loss:0.7053290605545044	train_acc:0.9166666666666666	test_acc:0.755	test_f1:0.7517178783806289
epoch:40	train_loss:0.7309678196907043	train_acc:0.9	test_acc:0.757	test_f1:0.7552254556454897
epoch:41	train_loss:0.6788016557693481	train_acc:0.9333333333333333	test_acc:0.756	test_f1:0.7548405521379502
epoch:42	train_loss:0.6636489629745483	train_acc:0.9333333333333333	test_acc:0.757	test_f1:0.7565927704284073
epoch:43	train_loss:0.6698459386825562	train_acc:0.9166666666666666	test_acc:0.754	test_f1:0.7528858488902883
epoch:44	train_loss:0.6472510695457458	train_acc:0.9333333333333333	test_acc:0.753	test_f1:0.7515420716545393
epoch:45	train_loss:0.6553738117218018	train_acc:0.9166666666666666	test_acc:0.757	test_f1:0.7549077597606949
epoch:46	train_loss:0.6445485949516296	train_acc:0.9333333333333333	test_acc:0.756	test_f1:0.7538335851992599
epoch:47	train_loss:0.6069576144218445	train_acc:0.8833333333333333	test_acc:0.759	test_f1:0.7568747203579419
epoch:48	train_loss:0.5472597479820251	train_acc:0.9	test_acc:0.758	test_f1:0.7556451612903224
epoch:49	train_loss:0.5916579961776733	train_acc:0.9166666666666666	test_acc:0.757	test_f1:0.7544176237277366
epoch:50	train_loss:0.5531241297721863	train_acc:0.9166666666666666	test_acc:0.759	test_f1:0.7565874395780848
训练并测试结束，共训练50轮，总用时33.67823338508606s
最佳正确率为:0.759,对应的macro_f1为:0.7565874395780848,对应的训练轮次为:50



2022-07-01 20:32:43.629178
epoch:1	train_loss:1.1372430324554443	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:2	train_loss:1.1003191471099854	train_acc:0.35	test_acc:0.183	test_f1:0.10691234856968342
epoch:3	train_loss:1.0870716571807861	train_acc:0.4	test_acc:0.319	test_f1:0.3057414993490833
epoch:4	train_loss:1.070542812347412	train_acc:0.5	test_acc:0.623	test_f1:0.615090775256553
epoch:5	train_loss:1.0587161779403687	train_acc:0.5666666666666667	test_acc:0.562	test_f1:0.5343604251171015
epoch:6	train_loss:1.047972321510315	train_acc:0.5666666666666667	test_acc:0.513	test_f1:0.46297677422536343
epoch:7	train_loss:1.0614522695541382	train_acc:0.38333333333333336	test_acc:0.502	test_f1:0.4453308262670543
epoch:8	train_loss:1.030535101890564	train_acc:0.65	test_acc:0.515	test_f1:0.46887306870838
epoch:9	train_loss:1.0379308462142944	train_acc:0.5833333333333334	test_acc:0.549	test_f1:0.519853640593788
epoch:10	train_loss:1.0287089347839355	train_acc:0.6166666666666667	test_acc:0.61	test_f1:0.5962301219101745
epoch:11	train_loss:1.0066777467727661	train_acc:0.6833333333333333	test_acc:0.654	test_f1:0.6487227353448909
epoch:12	train_loss:0.9816403985023499	train_acc:0.7	test_acc:0.683	test_f1:0.6815988741195339
epoch:13	train_loss:0.9856355786323547	train_acc:0.8333333333333334	test_acc:0.696	test_f1:0.697822016311134
epoch:14	train_loss:0.9670320153236389	train_acc:0.7333333333333333	test_acc:0.699	test_f1:0.6998950407036486
epoch:15	train_loss:0.9648096561431885	train_acc:0.7666666666666667	test_acc:0.697	test_f1:0.6971474227580883
epoch:16	train_loss:0.9479094743728638	train_acc:0.85	test_acc:0.696	test_f1:0.695347529488814
epoch:17	train_loss:0.9612056612968445	train_acc:0.7666666666666667	test_acc:0.696	test_f1:0.6955312658425541
epoch:18	train_loss:0.9556224942207336	train_acc:0.7166666666666667	test_acc:0.703	test_f1:0.7029043679567822
epoch:19	train_loss:0.9319661259651184	train_acc:0.8333333333333334	test_acc:0.71	test_f1:0.7095569656841318
epoch:20	train_loss:0.8859990239143372	train_acc:0.9	test_acc:0.708	test_f1:0.7075524685403134
epoch:21	train_loss:0.9065536260604858	train_acc:0.7666666666666667	test_acc:0.715	test_f1:0.7140400862471735
epoch:22	train_loss:0.8797339797019958	train_acc:0.8166666666666667	test_acc:0.715	test_f1:0.7140134983941735
epoch:23	train_loss:0.872668445110321	train_acc:0.8166666666666667	test_acc:0.711	test_f1:0.7086542167841153
epoch:24	train_loss:0.8627265095710754	train_acc:0.8833333333333333	test_acc:0.707	test_f1:0.7047721808803408
epoch:25	train_loss:0.8761581778526306	train_acc:0.8333333333333334	test_acc:0.708	test_f1:0.7076056356413697
epoch:26	train_loss:0.8455517292022705	train_acc:0.8166666666666667	test_acc:0.708	test_f1:0.7086335435983099
epoch:27	train_loss:0.8350938558578491	train_acc:0.8	test_acc:0.715	test_f1:0.7144744404502593
epoch:28	train_loss:0.8167285919189453	train_acc:0.8333333333333334	test_acc:0.717	test_f1:0.716532727939572
epoch:29	train_loss:0.7923679351806641	train_acc:0.8833333333333333	test_acc:0.718	test_f1:0.7173800034656038
epoch:30	train_loss:0.8408734202384949	train_acc:0.8	test_acc:0.716	test_f1:0.7157071783937455
epoch:31	train_loss:0.7808113098144531	train_acc:0.8333333333333334	test_acc:0.713	test_f1:0.7125746151577869
epoch:32	train_loss:0.7470926642417908	train_acc:0.8833333333333333	test_acc:0.713	test_f1:0.7128161308593172
epoch:33	train_loss:0.7502192258834839	train_acc:0.9166666666666666	test_acc:0.713	test_f1:0.7129996470029288
epoch:34	train_loss:0.7195063829421997	train_acc:0.9	test_acc:0.713	test_f1:0.7126281528447852
epoch:35	train_loss:0.742622435092926	train_acc:0.8333333333333334	test_acc:0.717	test_f1:0.7162910320882835
epoch:36	train_loss:0.709675133228302	train_acc:0.8666666666666667	test_acc:0.717	test_f1:0.7171318101811893
epoch:37	train_loss:0.6936632990837097	train_acc:0.9	test_acc:0.72	test_f1:0.7199449930660924
epoch:38	train_loss:0.6599239110946655	train_acc:0.9	test_acc:0.723	test_f1:0.7222098644078128
epoch:39	train_loss:0.6917075514793396	train_acc:0.9	test_acc:0.73	test_f1:0.7282760360394168
epoch:40	train_loss:0.6500843167304993	train_acc:0.9	test_acc:0.732	test_f1:0.729952012699265
epoch:41	train_loss:0.6310130953788757	train_acc:0.95	test_acc:0.732	test_f1:0.7296896528539638
epoch:42	train_loss:0.6202000975608826	train_acc:0.8833333333333333	test_acc:0.734	test_f1:0.7316849108940979
epoch:43	train_loss:0.6078575849533081	train_acc:0.9166666666666666	test_acc:0.739	test_f1:0.7366544161445141
epoch:44	train_loss:0.6023738384246826	train_acc:0.9333333333333333	test_acc:0.74	test_f1:0.7374295958392975
epoch:45	train_loss:0.5719420909881592	train_acc:0.9166666666666666	test_acc:0.742	test_f1:0.7393560927404494
epoch:46	train_loss:0.564977765083313	train_acc:0.9166666666666666	test_acc:0.746	test_f1:0.7419641825878781
epoch:47	train_loss:0.5073361992835999	train_acc:0.9666666666666667	test_acc:0.745	test_f1:0.7405410877457365
epoch:48	train_loss:0.5791221261024475	train_acc:0.8833333333333333	test_acc:0.747	test_f1:0.7425894545599663
epoch:49	train_loss:0.505146324634552	train_acc:0.95	test_acc:0.745	test_f1:0.7427028667568697
epoch:50	train_loss:0.5332778096199036	train_acc:0.9	test_acc:0.745	test_f1:0.7426783164411507
训练并测试结束，共训练50轮，总用时31.55980396270752s
最佳正确率为:0.747,对应的macro_f1为:0.7425894545599663,对应的训练轮次为:48



2022-07-01 20:33:46.163812
epoch:1	train_loss:1.1304268836975098	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:2	train_loss:1.118528127670288	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:3	train_loss:1.1130081415176392	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:4	train_loss:1.0972645282745361	train_acc:0.35	test_acc:0.18	test_f1:0.1016949152542373
epoch:5	train_loss:1.0947116613388062	train_acc:0.3416666666666667	test_acc:0.18	test_f1:0.1016949152542373
epoch:6	train_loss:1.0788551568984985	train_acc:0.425	test_acc:0.18	test_f1:0.1016949152542373
epoch:7	train_loss:1.0752437114715576	train_acc:0.375	test_acc:0.183	test_f1:0.10691234856968342
epoch:8	train_loss:1.0699855089187622	train_acc:0.44166666666666665	test_acc:0.32	test_f1:0.28342422662513556
epoch:9	train_loss:1.067283272743225	train_acc:0.5166666666666667	test_acc:0.628	test_f1:0.6246415225046977
epoch:10	train_loss:1.0628957748413086	train_acc:0.5583333333333333	test_acc:0.673	test_f1:0.6638812459575051
epoch:11	train_loss:1.0506680011749268	train_acc:0.6583333333333333	test_acc:0.591	test_f1:0.5580647755170193
epoch:12	train_loss:1.0459991693496704	train_acc:0.5583333333333333	test_acc:0.53	test_f1:0.47322320064970164
epoch:13	train_loss:1.0374455451965332	train_acc:0.575	test_acc:0.515	test_f1:0.4512554449129313
epoch:14	train_loss:1.0430511236190796	train_acc:0.5416666666666666	test_acc:0.503	test_f1:0.4310763888888889
epoch:15	train_loss:1.0484938621520996	train_acc:0.5083333333333333	test_acc:0.507	test_f1:0.4396418863070763
epoch:16	train_loss:1.0530273914337158	train_acc:0.44166666666666665	test_acc:0.525	test_f1:0.4725048799765936
epoch:17	train_loss:1.0244232416152954	train_acc:0.6083333333333333	test_acc:0.569	test_f1:0.5381115054640847
epoch:18	train_loss:1.0233852863311768	train_acc:0.575	test_acc:0.658	test_f1:0.6516293517218955
epoch:19	train_loss:0.993270218372345	train_acc:0.6833333333333333	test_acc:0.719	test_f1:0.7139833915761836
epoch:20	train_loss:1.0030229091644287	train_acc:0.65	test_acc:0.752	test_f1:0.7462201854351301
epoch:21	train_loss:1.0004689693450928	train_acc:0.675	test_acc:0.749	test_f1:0.7439930829764604
epoch:22	train_loss:0.971727192401886	train_acc:0.775	test_acc:0.742	test_f1:0.7375834025774871
epoch:23	train_loss:0.98085618019104	train_acc:0.7333333333333333	test_acc:0.743	test_f1:0.7386595074496523
epoch:24	train_loss:0.9767760634422302	train_acc:0.7166666666666667	test_acc:0.732	test_f1:0.7262033872560189
epoch:25	train_loss:0.9536227583885193	train_acc:0.8	test_acc:0.728	test_f1:0.7228205557046529
epoch:26	train_loss:0.9538843035697937	train_acc:0.7583333333333333	test_acc:0.725	test_f1:0.7193440741979966
epoch:27	train_loss:0.9547550678253174	train_acc:0.775	test_acc:0.718	test_f1:0.7118500377880032
epoch:28	train_loss:0.9187119603157043	train_acc:0.775	test_acc:0.72	test_f1:0.7141842975173421
epoch:29	train_loss:0.9137247800827026	train_acc:0.7416666666666667	test_acc:0.719	test_f1:0.7132607332977817
epoch:30	train_loss:0.9115151166915894	train_acc:0.7666666666666667	test_acc:0.722	test_f1:0.7156505026108549
epoch:31	train_loss:0.8867717385292053	train_acc:0.7833333333333333	test_acc:0.721	test_f1:0.7150345692756067
epoch:32	train_loss:0.877062201499939	train_acc:0.825	test_acc:0.724	test_f1:0.7188345290038368
epoch:33	train_loss:0.8664514422416687	train_acc:0.8166666666666667	test_acc:0.728	test_f1:0.7229851068957599
epoch:34	train_loss:0.8662182092666626	train_acc:0.7916666666666666	test_acc:0.731	test_f1:0.7264468271341382
epoch:35	train_loss:0.8450289964675903	train_acc:0.8166666666666667	test_acc:0.732	test_f1:0.7272106070680838
epoch:36	train_loss:0.8467942476272583	train_acc:0.7916666666666666	test_acc:0.733	test_f1:0.7282522698241545
epoch:37	train_loss:0.8285444378852844	train_acc:0.775	test_acc:0.732	test_f1:0.7271746661882147
epoch:38	train_loss:0.8129547834396362	train_acc:0.8416666666666667	test_acc:0.731	test_f1:0.7262456554026872
epoch:39	train_loss:0.8083819150924683	train_acc:0.8083333333333333	test_acc:0.731	test_f1:0.7262456554026872
epoch:40	train_loss:0.789657711982727	train_acc:0.7833333333333333	test_acc:0.734	test_f1:0.729028674235083
epoch:41	train_loss:0.7786238193511963	train_acc:0.8	test_acc:0.735	test_f1:0.7300866094172025
epoch:42	train_loss:0.7536652088165283	train_acc:0.8	test_acc:0.735	test_f1:0.7302170112557462
epoch:43	train_loss:0.756015956401825	train_acc:0.8416666666666667	test_acc:0.736	test_f1:0.7311343095024311
epoch:44	train_loss:0.743450939655304	train_acc:0.8083333333333333	test_acc:0.739	test_f1:0.7339915167817068
epoch:45	train_loss:0.7293821573257446	train_acc:0.8166666666666667	test_acc:0.74	test_f1:0.7355192851116467
epoch:46	train_loss:0.7151515483856201	train_acc:0.8583333333333333	test_acc:0.743	test_f1:0.7386404811346008
epoch:47	train_loss:0.6966578364372253	train_acc:0.875	test_acc:0.744	test_f1:0.7400144808148695
epoch:48	train_loss:0.6944091320037842	train_acc:0.8416666666666667	test_acc:0.748	test_f1:0.7435875583551986
epoch:49	train_loss:0.6699169278144836	train_acc:0.875	test_acc:0.748	test_f1:0.7439548573819262
epoch:50	train_loss:0.667324423789978	train_acc:0.85	test_acc:0.75	test_f1:0.7457309832047004
训练并测试结束，共训练50轮，总用时35.97340655326843s
最佳正确率为:0.752,对应的macro_f1为:0.7462201854351301,对应的训练轮次为:20



2022-07-01 20:34:37.059024
epoch:1	train_loss:1.1072916984558105	train_acc:0.26666666666666666	test_acc:0.326	test_f1:0.3098802320121759
epoch:2	train_loss:1.1032905578613281	train_acc:0.3	test_acc:0.564	test_f1:0.5505430868861141
epoch:3	train_loss:1.0884708166122437	train_acc:0.4666666666666667	test_acc:0.664	test_f1:0.6568046849198278
epoch:4	train_loss:1.081574559211731	train_acc:0.4583333333333333	test_acc:0.721	test_f1:0.7140927831584611
epoch:5	train_loss:1.0789902210235596	train_acc:0.5083333333333333	test_acc:0.716	test_f1:0.7102478321166729
epoch:6	train_loss:1.0642297267913818	train_acc:0.65	test_acc:0.71	test_f1:0.7046677363890078
epoch:7	train_loss:1.0635676383972168	train_acc:0.625	test_acc:0.718	test_f1:0.7131837427461339
epoch:8	train_loss:1.048250436782837	train_acc:0.6833333333333333	test_acc:0.732	test_f1:0.7265705762286073
epoch:9	train_loss:1.0410513877868652	train_acc:0.7166666666666667	test_acc:0.735	test_f1:0.73127320989721
epoch:10	train_loss:1.0306475162506104	train_acc:0.7666666666666667	test_acc:0.744	test_f1:0.7397243895504255
epoch:11	train_loss:1.0218132734298706	train_acc:0.7833333333333333	test_acc:0.742	test_f1:0.7376146030340208
epoch:12	train_loss:1.013627290725708	train_acc:0.7666666666666667	test_acc:0.739	test_f1:0.7349052471913377
epoch:13	train_loss:1.0041637420654297	train_acc:0.7666666666666667	test_acc:0.737	test_f1:0.7323406653110078
epoch:14	train_loss:0.9920671582221985	train_acc:0.8166666666666667	test_acc:0.737	test_f1:0.7327433924385014
epoch:15	train_loss:0.9772524237632751	train_acc:0.85	test_acc:0.738	test_f1:0.7336516145065718
epoch:16	train_loss:0.9547531008720398	train_acc:0.8083333333333333	test_acc:0.738	test_f1:0.7333075476372551
epoch:17	train_loss:0.9621763229370117	train_acc:0.8	test_acc:0.737	test_f1:0.7329720729080472
epoch:18	train_loss:0.939777135848999	train_acc:0.8333333333333334	test_acc:0.733	test_f1:0.7277534621388745
epoch:19	train_loss:0.9261999726295471	train_acc:0.8333333333333334	test_acc:0.73	test_f1:0.7245305509566836
epoch:20	train_loss:0.9188271164894104	train_acc:0.8333333333333334	test_acc:0.734	test_f1:0.7278392627375236
epoch:21	train_loss:0.9005917310714722	train_acc:0.8166666666666667	test_acc:0.735	test_f1:0.7298513238362861
epoch:22	train_loss:0.8860047459602356	train_acc:0.8166666666666667	test_acc:0.733	test_f1:0.7274257167346071
epoch:23	train_loss:0.8949734568595886	train_acc:0.775	test_acc:0.732	test_f1:0.7269429450495314
epoch:24	train_loss:0.862614095211029	train_acc:0.8666666666666667	test_acc:0.734	test_f1:0.7283099004748489
epoch:25	train_loss:0.8469558954238892	train_acc:0.875	test_acc:0.736	test_f1:0.730771401950443
epoch:26	train_loss:0.8322297930717468	train_acc:0.8333333333333334	test_acc:0.74	test_f1:0.7346025438144519
epoch:27	train_loss:0.8113069534301758	train_acc:0.8416666666666667	test_acc:0.739	test_f1:0.7328159393930759
epoch:28	train_loss:0.8363780379295349	train_acc:0.8166666666666667	test_acc:0.74	test_f1:0.7339633890639049
epoch:29	train_loss:0.7806429266929626	train_acc:0.8666666666666667	test_acc:0.741	test_f1:0.7348632626909755
epoch:30	train_loss:0.7658459544181824	train_acc:0.8666666666666667	test_acc:0.742	test_f1:0.7357620226308345
epoch:31	train_loss:0.7517030239105225	train_acc:0.875	test_acc:0.742	test_f1:0.7357620226308345
epoch:32	train_loss:0.7416209578514099	train_acc:0.85	test_acc:0.743	test_f1:0.7367096347593621
epoch:33	train_loss:0.7352083921432495	train_acc:0.8416666666666667	test_acc:0.745	test_f1:0.7390791234415782
epoch:34	train_loss:0.7225500345230103	train_acc:0.8583333333333333	test_acc:0.745	test_f1:0.7392920516036677
epoch:35	train_loss:0.7338612079620361	train_acc:0.85	test_acc:0.745	test_f1:0.7393524987105459
epoch:36	train_loss:0.6844919919967651	train_acc:0.8666666666666667	test_acc:0.746	test_f1:0.7405176210922114
epoch:37	train_loss:0.6758570075035095	train_acc:0.8833333333333333	test_acc:0.748	test_f1:0.7423165088337834
epoch:38	train_loss:0.6746095418930054	train_acc:0.8583333333333333	test_acc:0.748	test_f1:0.7420677742257901
epoch:39	train_loss:0.665236234664917	train_acc:0.8666666666666667	test_acc:0.747	test_f1:0.7411066613443579
epoch:40	train_loss:0.6342543363571167	train_acc:0.8666666666666667	test_acc:0.75	test_f1:0.7437854899714283
epoch:41	train_loss:0.6395544409751892	train_acc:0.85	test_acc:0.752	test_f1:0.7458320605113545
epoch:42	train_loss:0.6085773706436157	train_acc:0.8666666666666667	test_acc:0.752	test_f1:0.7461661637676612
epoch:43	train_loss:0.6101858019828796	train_acc:0.8916666666666667	test_acc:0.75	test_f1:0.7442756777467049
epoch:44	train_loss:0.5944861173629761	train_acc:0.8916666666666667	test_acc:0.751	test_f1:0.7450706299348805
epoch:45	train_loss:0.5442947745323181	train_acc:0.9	test_acc:0.752	test_f1:0.7465429361298659
epoch:46	train_loss:0.5372877717018127	train_acc:0.9166666666666666	test_acc:0.751	test_f1:0.7453173270469815
epoch:47	train_loss:0.5346707701683044	train_acc:0.9083333333333333	test_acc:0.751	test_f1:0.7452559609218697
epoch:48	train_loss:0.5263736248016357	train_acc:0.9	test_acc:0.752	test_f1:0.7461554612307763
epoch:49	train_loss:0.5372092723846436	train_acc:0.8916666666666667	test_acc:0.757	test_f1:0.7507297759624906
epoch:50	train_loss:0.5117762684822083	train_acc:0.9083333333333333	test_acc:0.755	test_f1:0.7485254967741013
训练并测试结束，共训练50轮，总用时35.209015130996704s
最佳正确率为:0.757,对应的macro_f1为:0.7507297759624906,对应的训练轮次为:49



2022-07-01 20:36:43.329802
epoch:1	train_loss:1.1210086345672607	train_acc:0.275	test_acc:0.18	test_f1:0.1016949152542373
epoch:2	train_loss:1.1112959384918213	train_acc:0.325	test_acc:0.18	test_f1:0.1016949152542373
epoch:3	train_loss:1.0819405317306519	train_acc:0.375	test_acc:0.193	test_f1:0.12329480370717484
epoch:4	train_loss:1.079417109489441	train_acc:0.36666666666666664	test_acc:0.404	test_f1:0.3422691938529043
epoch:5	train_loss:1.0794330835342407	train_acc:0.49166666666666664	test_acc:0.654	test_f1:0.6379681237653028
epoch:6	train_loss:1.0730022192001343	train_acc:0.5083333333333333	test_acc:0.682	test_f1:0.6652967574542764
epoch:7	train_loss:1.0588771104812622	train_acc:0.525	test_acc:0.656	test_f1:0.605887627187853
epoch:8	train_loss:1.0648270845413208	train_acc:0.55	test_acc:0.652	test_f1:0.5849931965793882
epoch:9	train_loss:1.0653210878372192	train_acc:0.5083333333333333	test_acc:0.654	test_f1:0.5946775023468992
epoch:10	train_loss:1.0570443868637085	train_acc:0.6083333333333333	test_acc:0.681	test_f1:0.6466162151336837
epoch:11	train_loss:1.0409876108169556	train_acc:0.6583333333333333	test_acc:0.709	test_f1:0.6966833176711962
epoch:12	train_loss:1.0346200466156006	train_acc:0.6416666666666667	test_acc:0.721	test_f1:0.7160156146607521
epoch:13	train_loss:1.0286431312561035	train_acc:0.7	test_acc:0.738	test_f1:0.7363079210758224
epoch:14	train_loss:1.0178428888320923	train_acc:0.7083333333333334	test_acc:0.735	test_f1:0.7325707681091803
epoch:15	train_loss:1.0147844552993774	train_acc:0.7166666666666667	test_acc:0.728	test_f1:0.7221751483836679
epoch:16	train_loss:1.007059931755066	train_acc:0.7583333333333333	test_acc:0.717	test_f1:0.7090456854576456
epoch:17	train_loss:0.9906500577926636	train_acc:0.8	test_acc:0.718	test_f1:0.7111973041474764
epoch:18	train_loss:0.9815261960029602	train_acc:0.7833333333333333	test_acc:0.715	test_f1:0.7075548412799041
epoch:19	train_loss:0.9685088992118835	train_acc:0.8083333333333333	test_acc:0.715	test_f1:0.7069606734906726
epoch:20	train_loss:0.9628735184669495	train_acc:0.725	test_acc:0.716	test_f1:0.708610461524945
epoch:21	train_loss:0.9432600736618042	train_acc:0.8	test_acc:0.719	test_f1:0.7122822125280909
epoch:22	train_loss:0.9377889633178711	train_acc:0.7916666666666666	test_acc:0.723	test_f1:0.717168545816404
epoch:23	train_loss:0.91861891746521	train_acc:0.825	test_acc:0.719	test_f1:0.7131134769309172
epoch:24	train_loss:0.9152922034263611	train_acc:0.7833333333333333	test_acc:0.72	test_f1:0.714454495291677
epoch:25	train_loss:0.9055213332176208	train_acc:0.8083333333333333	test_acc:0.725	test_f1:0.7192409479458258
epoch:26	train_loss:0.8810212016105652	train_acc:0.8416666666666667	test_acc:0.725	test_f1:0.7190297177734363
epoch:27	train_loss:0.8828781843185425	train_acc:0.85	test_acc:0.726	test_f1:0.7201158223842623
epoch:28	train_loss:0.8545254468917847	train_acc:0.825	test_acc:0.727	test_f1:0.7210765669703626
epoch:29	train_loss:0.8390865325927734	train_acc:0.8583333333333333	test_acc:0.731	test_f1:0.7249687545332822
epoch:30	train_loss:0.8255907893180847	train_acc:0.8583333333333333	test_acc:0.734	test_f1:0.7280519975489025
epoch:31	train_loss:0.8216683864593506	train_acc:0.8416666666666667	test_acc:0.734	test_f1:0.7276831066549069
epoch:32	train_loss:0.803734540939331	train_acc:0.8416666666666667	test_acc:0.738	test_f1:0.7322025453548077
epoch:33	train_loss:0.7858269810676575	train_acc:0.875	test_acc:0.738	test_f1:0.731238965953569
epoch:34	train_loss:0.787303626537323	train_acc:0.825	test_acc:0.739	test_f1:0.7321649342574581
epoch:35	train_loss:0.774823784828186	train_acc:0.8666666666666667	test_acc:0.74	test_f1:0.7333718611292538
epoch:36	train_loss:0.7672460079193115	train_acc:0.8333333333333334	test_acc:0.74	test_f1:0.7336574236208359
epoch:37	train_loss:0.7232599258422852	train_acc:0.8666666666666667	test_acc:0.743	test_f1:0.7365273592223679
epoch:38	train_loss:0.6979036927223206	train_acc:0.8583333333333333	test_acc:0.742	test_f1:0.7359149504048706
epoch:39	train_loss:0.7083308100700378	train_acc:0.9	test_acc:0.743	test_f1:0.7372516505359826
epoch:40	train_loss:0.68376225233078	train_acc:0.8666666666666667	test_acc:0.744	test_f1:0.7384760681592705
epoch:41	train_loss:0.6664202213287354	train_acc:0.8666666666666667	test_acc:0.742	test_f1:0.7356070861195311
epoch:42	train_loss:0.6673542261123657	train_acc:0.8416666666666667	test_acc:0.743	test_f1:0.736103878050355
epoch:43	train_loss:0.6351640820503235	train_acc:0.875	test_acc:0.744	test_f1:0.7370122512043461
epoch:44	train_loss:0.6085928678512573	train_acc:0.8916666666666667	test_acc:0.744	test_f1:0.7370122512043461
epoch:45	train_loss:0.6299125552177429	train_acc:0.8833333333333333	test_acc:0.746	test_f1:0.7393212514456168
epoch:46	train_loss:0.6124616265296936	train_acc:0.8916666666666667	test_acc:0.746	test_f1:0.7398108342267893
epoch:47	train_loss:0.6034491062164307	train_acc:0.9083333333333333	test_acc:0.747	test_f1:0.741203847444572
epoch:48	train_loss:0.5920074582099915	train_acc:0.8916666666666667	test_acc:0.747	test_f1:0.741203847444572
epoch:49	train_loss:0.5730029344558716	train_acc:0.9	test_acc:0.75	test_f1:0.743925540390361
epoch:50	train_loss:0.5600798726081848	train_acc:0.9	test_acc:0.751	test_f1:0.7446867681128907
训练并测试结束，共训练50轮，总用时34.869136571884155s
最佳正确率为:0.751,对应的macro_f1为:0.7446867681128907,对应的训练轮次为:50



2022-07-01 20:38:32.190305
epoch:1	train_loss:1.1256638765335083	train_acc:0.3333333333333333	test_acc:0.407	test_f1:0.19284529732290925
epoch:2	train_loss:1.122196912765503	train_acc:0.3333333333333333	test_acc:0.407	test_f1:0.19284529732290925
epoch:3	train_loss:1.1043310165405273	train_acc:0.3333333333333333	test_acc:0.407	test_f1:0.19284529732290925
epoch:4	train_loss:1.0988131761550903	train_acc:0.35555555555555557	test_acc:0.407	test_f1:0.19284529732290925
epoch:5	train_loss:1.0835503339767456	train_acc:0.3611111111111111	test_acc:0.409	test_f1:0.19633266160728322
epoch:6	train_loss:1.0749067068099976	train_acc:0.4111111111111111	test_acc:0.641	test_f1:0.5756067589185618
epoch:7	train_loss:1.0611586570739746	train_acc:0.4666666666666667	test_acc:0.698	test_f1:0.6954178543488986
epoch:8	train_loss:1.0654934644699097	train_acc:0.48333333333333334	test_acc:0.619	test_f1:0.586262377992179
epoch:9	train_loss:1.0483449697494507	train_acc:0.55	test_acc:0.548	test_f1:0.4695239384890108
epoch:10	train_loss:1.0331101417541504	train_acc:0.5666666666666667	test_acc:0.536	test_f1:0.446858393486849
epoch:11	train_loss:1.03167724609375	train_acc:0.6	test_acc:0.534	test_f1:0.444215298045105
epoch:12	train_loss:1.0389167070388794	train_acc:0.5444444444444444	test_acc:0.538	test_f1:0.4553103596593675
epoch:13	train_loss:1.0181044340133667	train_acc:0.6222222222222222	test_acc:0.551	test_f1:0.47786251963996645
epoch:14	train_loss:1.0128310918807983	train_acc:0.5944444444444444	test_acc:0.57	test_f1:0.5122531734355295
epoch:15	train_loss:1.0059620141983032	train_acc:0.6277777777777778	test_acc:0.597	test_f1:0.5543884189309555
epoch:16	train_loss:0.9882460832595825	train_acc:0.6277777777777778	test_acc:0.624	test_f1:0.5930182437513102
epoch:17	train_loss:0.9910380244255066	train_acc:0.6055555555555555	test_acc:0.656	test_f1:0.6363005548680545
epoch:18	train_loss:0.9619494676589966	train_acc:0.7222222222222222	test_acc:0.676	test_f1:0.6638785887307648
epoch:19	train_loss:0.9657223224639893	train_acc:0.6722222222222223	test_acc:0.695	test_f1:0.6865059050238381
epoch:20	train_loss:0.974429726600647	train_acc:0.6666666666666666	test_acc:0.709	test_f1:0.7037570084041743
epoch:21	train_loss:0.9403424859046936	train_acc:0.7777777777777778	test_acc:0.72	test_f1:0.716155990465781
epoch:22	train_loss:0.9209060668945312	train_acc:0.75	test_acc:0.725	test_f1:0.7221192324933309
epoch:23	train_loss:0.9249141216278076	train_acc:0.7777777777777778	test_acc:0.727	test_f1:0.7238735953127153
epoch:24	train_loss:0.9059023261070251	train_acc:0.7611111111111111	test_acc:0.728	test_f1:0.7240553253897278
epoch:25	train_loss:0.8934629559516907	train_acc:0.7944444444444444	test_acc:0.729	test_f1:0.7251375649775357
epoch:26	train_loss:0.8968337774276733	train_acc:0.7555555555555555	test_acc:0.732	test_f1:0.7276552353803805
epoch:27	train_loss:0.8799083232879639	train_acc:0.7555555555555555	test_acc:0.734	test_f1:0.7305082000271076
epoch:28	train_loss:0.86372971534729	train_acc:0.7777777777777778	test_acc:0.734	test_f1:0.730754335448976
epoch:29	train_loss:0.8509378433227539	train_acc:0.7944444444444444	test_acc:0.733	test_f1:0.7300318957730368
epoch:30	train_loss:0.8303843140602112	train_acc:0.7944444444444444	test_acc:0.734	test_f1:0.7312591517540977
epoch:31	train_loss:0.800214409828186	train_acc:0.8055555555555556	test_acc:0.736	test_f1:0.7328593205763457
epoch:32	train_loss:0.8109362125396729	train_acc:0.8055555555555556	test_acc:0.735	test_f1:0.7323740209578645
epoch:33	train_loss:0.7907631993293762	train_acc:0.7888888888888889	test_acc:0.735	test_f1:0.732290738414123
epoch:34	train_loss:0.7852227091789246	train_acc:0.7944444444444444	test_acc:0.733	test_f1:0.7294515574381822
epoch:35	train_loss:0.7675375938415527	train_acc:0.8277777777777777	test_acc:0.734	test_f1:0.7308075216508952
epoch:36	train_loss:0.7582771182060242	train_acc:0.8166666666666667	test_acc:0.73	test_f1:0.7255855506399688
epoch:37	train_loss:0.7327824831008911	train_acc:0.8333333333333334	test_acc:0.731	test_f1:0.7261525934728549
epoch:38	train_loss:0.7389371991157532	train_acc:0.7944444444444444	test_acc:0.732	test_f1:0.7273842871512596
epoch:39	train_loss:0.719662070274353	train_acc:0.8166666666666667	test_acc:0.733	test_f1:0.7287676377402281
epoch:40	train_loss:0.7078237533569336	train_acc:0.8388888888888889	test_acc:0.734	test_f1:0.7298436641478702
epoch:41	train_loss:0.6904152631759644	train_acc:0.8333333333333334	test_acc:0.737	test_f1:0.7341904984625343
epoch:42	train_loss:0.6913608312606812	train_acc:0.8277777777777777	test_acc:0.736	test_f1:0.7332405558061121
epoch:43	train_loss:0.6740842461585999	train_acc:0.8388888888888889	test_acc:0.737	test_f1:0.7337720131829141
epoch:44	train_loss:0.6589231491088867	train_acc:0.8333333333333334	test_acc:0.734	test_f1:0.7315558797870331
epoch:45	train_loss:0.6262530088424683	train_acc:0.8611111111111112	test_acc:0.736	test_f1:0.7336088803315914
epoch:46	train_loss:0.6429661512374878	train_acc:0.8388888888888889	test_acc:0.739	test_f1:0.7366470930607604
epoch:47	train_loss:0.6182768940925598	train_acc:0.8277777777777777	test_acc:0.738	test_f1:0.7352448191574217
epoch:48	train_loss:0.6213439702987671	train_acc:0.8611111111111112	test_acc:0.736	test_f1:0.7325061790097621
epoch:49	train_loss:0.6086684465408325	train_acc:0.8777777777777778	test_acc:0.737	test_f1:0.7339106569904018
epoch:50	train_loss:0.5999809503555298	train_acc:0.8444444444444444	test_acc:0.739	test_f1:0.7360257432422381
训练并测试结束，共训练50轮，总用时33.18416929244995s
最佳正确率为:0.739,对应的macro_f1为:0.7360257432422381,对应的训练轮次为:50



2022-07-01 20:40:22.526257
epoch:1	train_loss:1.1265183687210083	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:2	train_loss:1.1193772554397583	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:3	train_loss:1.1023287773132324	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:4	train_loss:1.1037241220474243	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:5	train_loss:1.0891613960266113	train_acc:0.3333333333333333	test_acc:0.18	test_f1:0.1016949152542373
epoch:6	train_loss:1.08160400390625	train_acc:0.3388888888888889	test_acc:0.18	test_f1:0.1016949152542373
epoch:7	train_loss:1.0834673643112183	train_acc:0.3333333333333333	test_acc:0.193	test_f1:0.12350185854421053
epoch:8	train_loss:1.0810022354125977	train_acc:0.38333333333333336	test_acc:0.31	test_f1:0.2767096227462669
epoch:9	train_loss:1.0696101188659668	train_acc:0.45	test_acc:0.359	test_f1:0.31817199320673145
epoch:10	train_loss:1.058353304862976	train_acc:0.5444444444444444	test_acc:0.576	test_f1:0.5699095089466315
epoch:11	train_loss:1.0529241561889648	train_acc:0.6166666666666667	test_acc:0.717	test_f1:0.7123099635231998
epoch:12	train_loss:1.0404397249221802	train_acc:0.6444444444444445	test_acc:0.705	test_f1:0.6859804431549262
epoch:13	train_loss:1.0458550453186035	train_acc:0.5722222222222222	test_acc:0.654	test_f1:0.5686169926922876
epoch:14	train_loss:1.0306950807571411	train_acc:0.6611111111111111	test_acc:0.641	test_f1:0.5281689264009823
epoch:15	train_loss:1.0334553718566895	train_acc:0.6222222222222222	test_acc:0.638	test_f1:0.5258451254712849
epoch:16	train_loss:1.0244011878967285	train_acc:0.6111111111111112	test_acc:0.651	test_f1:0.5649998920193751
epoch:17	train_loss:1.0176328420639038	train_acc:0.6111111111111112	test_acc:0.679	test_f1:0.6326597794901373
epoch:18	train_loss:1.0107076168060303	train_acc:0.6388888888888888	test_acc:0.708	test_f1:0.6958486747028241
epoch:19	train_loss:0.9873627424240112	train_acc:0.7277777777777777	test_acc:0.724	test_f1:0.7237186110130335
epoch:20	train_loss:0.990892767906189	train_acc:0.6611111111111111	test_acc:0.731	test_f1:0.7341273564408971
epoch:21	train_loss:0.9804466962814331	train_acc:0.7388888888888889	test_acc:0.732	test_f1:0.7355948742819097
epoch:22	train_loss:0.9554538130760193	train_acc:0.7833333333333333	test_acc:0.728	test_f1:0.7298834927149415
epoch:23	train_loss:0.9585860371589661	train_acc:0.7611111111111111	test_acc:0.726	test_f1:0.7268688704399745
epoch:24	train_loss:0.9352138042449951	train_acc:0.7888888888888889	test_acc:0.727	test_f1:0.7277051149675312
epoch:25	train_loss:0.9380661845207214	train_acc:0.7611111111111111	test_acc:0.724	test_f1:0.7245125640572198
epoch:26	train_loss:0.9175668358802795	train_acc:0.75	test_acc:0.728	test_f1:0.729514580443866
epoch:27	train_loss:0.8904154300689697	train_acc:0.8333333333333334	test_acc:0.728	test_f1:0.7296169725511982
epoch:28	train_loss:0.8957598209381104	train_acc:0.7944444444444444	test_acc:0.724	test_f1:0.7251957229337357
epoch:29	train_loss:0.8737257122993469	train_acc:0.8222222222222222	test_acc:0.725	test_f1:0.7268920524910948
epoch:30	train_loss:0.8558956384658813	train_acc:0.7888888888888889	test_acc:0.725	test_f1:0.7267662758756129
epoch:31	train_loss:0.8447709083557129	train_acc:0.8166666666666667	test_acc:0.728	test_f1:0.7293215250847136
epoch:32	train_loss:0.8398028016090393	train_acc:0.8	test_acc:0.728	test_f1:0.7288557078401178
epoch:33	train_loss:0.82454514503479	train_acc:0.7833333333333333	test_acc:0.727	test_f1:0.7276901722428475
epoch:34	train_loss:0.8015082478523254	train_acc:0.7888888888888889	test_acc:0.721	test_f1:0.7214588924228792
epoch:35	train_loss:0.7944474816322327	train_acc:0.7722222222222223	test_acc:0.729	test_f1:0.7281055768552509
epoch:36	train_loss:0.76997971534729	train_acc:0.8388888888888889	test_acc:0.728	test_f1:0.7265009593244592
epoch:37	train_loss:0.7550004124641418	train_acc:0.8222222222222222	test_acc:0.731	test_f1:0.7297612725178295
epoch:38	train_loss:0.7561713457107544	train_acc:0.8166666666666667	test_acc:0.731	test_f1:0.7300534710332194
epoch:39	train_loss:0.7320089340209961	train_acc:0.8388888888888889	test_acc:0.732	test_f1:0.7309960685062106
epoch:40	train_loss:0.7101825475692749	train_acc:0.85	test_acc:0.733	test_f1:0.731560264394392
epoch:41	train_loss:0.7132912278175354	train_acc:0.8222222222222222	test_acc:0.733	test_f1:0.7321282860675069
epoch:42	train_loss:0.7105751633644104	train_acc:0.8166666666666667	test_acc:0.733	test_f1:0.7328207677858541
epoch:43	train_loss:0.6788322329521179	train_acc:0.8833333333333333	test_acc:0.735	test_f1:0.7347823630079261
epoch:44	train_loss:0.6778921484947205	train_acc:0.8111111111111111	test_acc:0.743	test_f1:0.7434108513273929
epoch:45	train_loss:0.654119610786438	train_acc:0.8666666666666667	test_acc:0.74	test_f1:0.7400713162021663
epoch:46	train_loss:0.6625432372093201	train_acc:0.8222222222222222	test_acc:0.737	test_f1:0.73634195728921
epoch:47	train_loss:0.6322375535964966	train_acc:0.8722222222222222	test_acc:0.74	test_f1:0.7388253742327584
epoch:48	train_loss:0.6330013871192932	train_acc:0.8611111111111112	test_acc:0.741	test_f1:0.7396823130798199
epoch:49	train_loss:0.6397174596786499	train_acc:0.8388888888888889	test_acc:0.742	test_f1:0.7405789012609878
epoch:50	train_loss:0.6128804683685303	train_acc:0.8611111111111112	test_acc:0.745	test_f1:0.7432051953067811
训练并测试结束，共训练50轮，总用时33.75267457962036s
最佳正确率为:0.745,对应的macro_f1为:0.7432051953067811,对应的训练轮次为:50



2022-07-01 20:41:33.168597
epoch:1	train_loss:1.126771092414856	train_acc:0.32222222222222224	test_acc:0.407	test_f1:0.19284529732290925
epoch:2	train_loss:1.1133718490600586	train_acc:0.35555555555555557	test_acc:0.407	test_f1:0.19284529732290925
epoch:3	train_loss:1.1053919792175293	train_acc:0.3611111111111111	test_acc:0.407	test_f1:0.19284529732290925
epoch:4	train_loss:1.0907682180404663	train_acc:0.3611111111111111	test_acc:0.407	test_f1:0.19284529732290925
epoch:5	train_loss:1.0842593908309937	train_acc:0.40555555555555556	test_acc:0.416	test_f1:0.22580466915319797
epoch:6	train_loss:1.0735665559768677	train_acc:0.4166666666666667	test_acc:0.44	test_f1:0.299760920658076
epoch:7	train_loss:1.0658526420593262	train_acc:0.45	test_acc:0.463	test_f1:0.35649503985992
epoch:8	train_loss:1.0606098175048828	train_acc:0.4444444444444444	test_acc:0.491	test_f1:0.41321273727547636
epoch:9	train_loss:1.044285535812378	train_acc:0.5277777777777778	test_acc:0.509	test_f1:0.4412623718063477
epoch:10	train_loss:1.045000672340393	train_acc:0.5277777777777778	test_acc:0.521	test_f1:0.45545528728459655
epoch:11	train_loss:1.0265411138534546	train_acc:0.6111111111111112	test_acc:0.526	test_f1:0.45872077432069197
epoch:12	train_loss:1.0130585432052612	train_acc:0.6055555555555555	test_acc:0.526	test_f1:0.4567112380418721
epoch:13	train_loss:1.012979507446289	train_acc:0.6222222222222222	test_acc:0.536	test_f1:0.474305189425322
epoch:14	train_loss:0.9969924092292786	train_acc:0.6666666666666666	test_acc:0.572	test_f1:0.5341549265618922
epoch:15	train_loss:0.9875761270523071	train_acc:0.6666666666666666	test_acc:0.615	test_f1:0.5952888698696289
epoch:16	train_loss:0.9672549962997437	train_acc:0.75	test_acc:0.659	test_f1:0.6492710423003084
epoch:17	train_loss:0.9642874002456665	train_acc:0.7166666666666667	test_acc:0.681	test_f1:0.6766414523486154
epoch:18	train_loss:0.964146614074707	train_acc:0.7111111111111111	test_acc:0.695	test_f1:0.6913577130121543
epoch:19	train_loss:0.9583075046539307	train_acc:0.6722222222222223	test_acc:0.697	test_f1:0.6935181986391625
epoch:20	train_loss:0.937192440032959	train_acc:0.6944444444444444	test_acc:0.691	test_f1:0.6874778717173772
epoch:21	train_loss:0.9238742589950562	train_acc:0.7333333333333333	test_acc:0.684	test_f1:0.680530122515663
epoch:22	train_loss:0.898858368396759	train_acc:0.7944444444444444	test_acc:0.684	test_f1:0.6803013647151136
epoch:23	train_loss:0.8878910541534424	train_acc:0.7444444444444445	test_acc:0.684	test_f1:0.67928303905832
epoch:24	train_loss:0.8825111389160156	train_acc:0.7277777777777777	test_acc:0.682	test_f1:0.6767504904383413
epoch:25	train_loss:0.8832188844680786	train_acc:0.75	test_acc:0.681	test_f1:0.6762641677314422
epoch:26	train_loss:0.8651044964790344	train_acc:0.6944444444444444	test_acc:0.679	test_f1:0.6752940184951378
epoch:27	train_loss:0.8504793643951416	train_acc:0.7666666666666667	test_acc:0.681	test_f1:0.6775635439399799
epoch:28	train_loss:0.8329776525497437	train_acc:0.7888888888888889	test_acc:0.69	test_f1:0.6872847295634634
epoch:29	train_loss:0.8320706486701965	train_acc:0.7888888888888889	test_acc:0.702	test_f1:0.6992654275665031
epoch:30	train_loss:0.8101124167442322	train_acc:0.7888888888888889	test_acc:0.706	test_f1:0.704591953692406
epoch:31	train_loss:0.8123632669448853	train_acc:0.7777777777777778	test_acc:0.705	test_f1:0.7046046865647423
epoch:32	train_loss:0.7914948463439941	train_acc:0.7722222222222223	test_acc:0.709	test_f1:0.7086089638244447
epoch:33	train_loss:0.7925519347190857	train_acc:0.7833333333333333	test_acc:0.714	test_f1:0.7132159887707882
epoch:34	train_loss:0.7575868368148804	train_acc:0.7888888888888889	test_acc:0.722	test_f1:0.7206374095856137
epoch:35	train_loss:0.7463782429695129	train_acc:0.8055555555555556	test_acc:0.726	test_f1:0.7248183875442825
epoch:36	train_loss:0.7391182780265808	train_acc:0.8277777777777777	test_acc:0.726	test_f1:0.7249210137349174
epoch:37	train_loss:0.7280607223510742	train_acc:0.8	test_acc:0.725	test_f1:0.7259823076081818
epoch:38	train_loss:0.6976776123046875	train_acc:0.8277777777777777	test_acc:0.723	test_f1:0.7243804744245943
epoch:39	train_loss:0.7035783529281616	train_acc:0.8055555555555556	test_acc:0.723	test_f1:0.7242281422657464
epoch:40	train_loss:0.6960701942443848	train_acc:0.8111111111111111	test_acc:0.73	test_f1:0.7305088881406235
epoch:41	train_loss:0.6803534030914307	train_acc:0.8277777777777777	test_acc:0.732	test_f1:0.7326529297630201
epoch:42	train_loss:0.6772470474243164	train_acc:0.8611111111111112	test_acc:0.731	test_f1:0.7322581592558709
epoch:43	train_loss:0.6691260933876038	train_acc:0.8277777777777777	test_acc:0.736	test_f1:0.7371940287299318
epoch:44	train_loss:0.657031238079071	train_acc:0.8222222222222222	test_acc:0.737	test_f1:0.7376710579133672
epoch:45	train_loss:0.634378969669342	train_acc:0.8388888888888889	test_acc:0.742	test_f1:0.7420235875435272
epoch:46	train_loss:0.6145184636116028	train_acc:0.8611111111111112	test_acc:0.744	test_f1:0.7440671671499067
epoch:47	train_loss:0.6205683350563049	train_acc:0.8444444444444444	test_acc:0.743	test_f1:0.7431703307993086
epoch:48	train_loss:0.6149634718894958	train_acc:0.8444444444444444	test_acc:0.747	test_f1:0.7473912843376106
epoch:49	train_loss:0.6218357682228088	train_acc:0.8444444444444444	test_acc:0.75	test_f1:0.7497844690940277
epoch:50	train_loss:0.5852122902870178	train_acc:0.85	test_acc:0.749	test_f1:0.7484045084399767
训练并测试结束，共训练50轮，总用时36.33911442756653s
最佳正确率为:0.75,对应的macro_f1为:0.7497844690940277,对应的训练轮次为:49



