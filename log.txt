2022-07-01 20:45:20.101359
epoch:1	train_loss:1.9968796968460083	train_acc:0.14285714285714285	test_acc:0.109	test_f1:0.04300167020863464
epoch:2	train_loss:1.912438154220581	train_acc:0.24285714285714285	test_acc:0.146	test_f1:0.04035602459420323
epoch:3	train_loss:1.883668303489685	train_acc:0.18571428571428572	test_acc:0.144	test_f1:0.03596403596403597
epoch:4	train_loss:1.8595026731491089	train_acc:0.16428571428571428	test_acc:0.163	test_f1:0.06610892129910535
epoch:5	train_loss:1.8163129091262817	train_acc:0.2571428571428571	test_acc:0.648	test_f1:0.5300483055506214
epoch:6	train_loss:1.7748229503631592	train_acc:0.6857142857142857	test_acc:0.711	test_f1:0.6986103872703574
epoch:7	train_loss:1.7290072441101074	train_acc:0.8571428571428571	test_acc:0.638	test_f1:0.6053124012328188
epoch:8	train_loss:1.6879427433013916	train_acc:0.8785714285714286	test_acc:0.474	test_f1:0.4727991116846357
epoch:9	train_loss:1.6393587589263916	train_acc:0.8071428571428572	test_acc:0.457	test_f1:0.4726995781376814
epoch:10	train_loss:1.6033196449279785	train_acc:0.8071428571428572	test_acc:0.513	test_f1:0.5394358153931634
epoch:11	train_loss:1.5478084087371826	train_acc:0.8642857142857143	test_acc:0.62	test_f1:0.6364833864092526
epoch:12	train_loss:1.4906102418899536	train_acc:0.8857142857142857	test_acc:0.73	test_f1:0.732571408027427
epoch:13	train_loss:1.4335235357284546	train_acc:0.9571428571428572	test_acc:0.75	test_f1:0.7510632314353586
epoch:14	train_loss:1.3695697784423828	train_acc:0.9642857142857143	test_acc:0.763	test_f1:0.7585087717461579
epoch:15	train_loss:1.3064016103744507	train_acc:0.95	test_acc:0.772	test_f1:0.7648620553251053
epoch:16	train_loss:1.246506690979004	train_acc:0.9428571428571428	test_acc:0.777	test_f1:0.7656632482824456
epoch:17	train_loss:1.1753783226013184	train_acc:0.95	test_acc:0.781	test_f1:0.7694550763265946
epoch:18	train_loss:1.1079479455947876	train_acc:0.9642857142857143	test_acc:0.785	test_f1:0.7769477802857189
epoch:19	train_loss:1.0395843982696533	train_acc:0.9642857142857143	test_acc:0.78	test_f1:0.7741886882048037
epoch:20	train_loss:0.9575767517089844	train_acc:0.9785714285714285	test_acc:0.765	test_f1:0.7594620284246252
epoch:21	train_loss:0.9003491401672363	train_acc:0.9714285714285714	test_acc:0.754	test_f1:0.7483151766707579
epoch:22	train_loss:0.8362519145011902	train_acc:0.9857142857142858	test_acc:0.756	test_f1:0.7494139015092641
epoch:23	train_loss:0.7640150785446167	train_acc:0.9714285714285714	test_acc:0.766	test_f1:0.7582448210558771
epoch:24	train_loss:0.7126456499099731	train_acc:0.9714285714285714	test_acc:0.774	test_f1:0.7679145524706597
epoch:25	train_loss:0.6488834023475647	train_acc:0.9714285714285714	test_acc:0.784	test_f1:0.7772253765242852
epoch:26	train_loss:0.5877258777618408	train_acc:0.9785714285714285	test_acc:0.79	test_f1:0.7819482099907633
epoch:27	train_loss:0.5393187403678894	train_acc:0.9785714285714285	test_acc:0.79	test_f1:0.7815945032604158
epoch:28	train_loss:0.4903108775615692	train_acc:0.9714285714285714	test_acc:0.791	test_f1:0.7825651932960552
epoch:29	train_loss:0.4444839358329773	train_acc:0.9785714285714285	test_acc:0.791	test_f1:0.7825651932960552
epoch:30	train_loss:0.40381523966789246	train_acc:0.9785714285714285	test_acc:0.791	test_f1:0.7828773674905936
epoch:31	train_loss:0.36104050278663635	train_acc:0.9785714285714285	test_acc:0.79	test_f1:0.782371391687346
epoch:32	train_loss:0.3247333765029907	train_acc:0.9857142857142858	test_acc:0.788	test_f1:0.7798434568902064
epoch:33	train_loss:0.29703089594841003	train_acc:0.9785714285714285	test_acc:0.787	test_f1:0.7806360297075772
epoch:34	train_loss:0.2725699543952942	train_acc:0.9785714285714285	test_acc:0.788	test_f1:0.781574543835231
epoch:35	train_loss:0.24558570981025696	train_acc:0.9857142857142858	test_acc:0.787	test_f1:0.7796990602874986
epoch:36	train_loss:0.22380538284778595	train_acc:0.9857142857142858	test_acc:0.785	test_f1:0.7767026105522382
epoch:37	train_loss:0.19740329682826996	train_acc:0.9857142857142858	test_acc:0.787	test_f1:0.77912420766849
epoch:38	train_loss:0.181425541639328	train_acc:0.9857142857142858	test_acc:0.792	test_f1:0.7847229115134784
epoch:39	train_loss:0.1684294044971466	train_acc:0.9928571428571429	test_acc:0.79	test_f1:0.7828082698396992
epoch:40	train_loss:0.153350368142128	train_acc:0.9857142857142858	test_acc:0.788	test_f1:0.7809733079361815
epoch:41	train_loss:0.14115847647190094	train_acc:0.9857142857142858	test_acc:0.792	test_f1:0.7841325216403056
epoch:42	train_loss:0.13409999012947083	train_acc:0.9857142857142858	test_acc:0.79	test_f1:0.7816886469783901
epoch:43	train_loss:0.12207578867673874	train_acc:0.9928571428571429	test_acc:0.787	test_f1:0.7800576616136411
epoch:44	train_loss:0.10799940675497055	train_acc:1.0	test_acc:0.786	test_f1:0.7791727780634004
epoch:45	train_loss:0.10374336689710617	train_acc:1.0	test_acc:0.788	test_f1:0.782565197264033
epoch:46	train_loss:0.10130233317613602	train_acc:0.9928571428571429	test_acc:0.788	test_f1:0.7814669315141047
epoch:47	train_loss:0.08923626691102982	train_acc:1.0	test_acc:0.79	test_f1:0.7837321876797834
epoch:48	train_loss:0.08814122527837753	train_acc:1.0	test_acc:0.79	test_f1:0.7829859696450852
epoch:49	train_loss:0.08206865191459656	train_acc:1.0	test_acc:0.795	test_f1:0.7868023127018796
epoch:50	train_loss:0.07879874855279922	train_acc:1.0	test_acc:0.794	test_f1:0.7856326721488384
训练并测试结束，共训练50轮，总用时237.73161578178406s
最佳正确率为:0.795,对应的macro_f1为:0.7868023127018796,对应的训练轮次为:49



2022-07-01 20:49:35.398833
epoch:1	train_loss:1.960286021232605	train_acc:0.10714285714285714	test_acc:0.363	test_f1:0.15154728898709638
epoch:2	train_loss:1.911752700805664	train_acc:0.22857142857142856	test_acc:0.319	test_f1:0.06909996750785227
epoch:3	train_loss:1.8769738674163818	train_acc:0.18571428571428572	test_acc:0.478	test_f1:0.3923103244229354
epoch:4	train_loss:1.8394094705581665	train_acc:0.6285714285714286	test_acc:0.564	test_f1:0.574970531963408
epoch:5	train_loss:1.8046457767486572	train_acc:0.8142857142857143	test_acc:0.532	test_f1:0.5542752668558335
epoch:6	train_loss:1.7678914070129395	train_acc:0.7928571428571428	test_acc:0.54	test_f1:0.555600319597815
epoch:7	train_loss:1.7182525396347046	train_acc:0.8428571428571429	test_acc:0.578	test_f1:0.6069783991856631
epoch:8	train_loss:1.6778392791748047	train_acc:0.8785714285714286	test_acc:0.702	test_f1:0.7112438851080931
epoch:9	train_loss:1.62502121925354	train_acc:0.9285714285714286	test_acc:0.779	test_f1:0.771153246450417
epoch:10	train_loss:1.5779203176498413	train_acc:0.95	test_acc:0.791	test_f1:0.7804949598900903
epoch:11	train_loss:1.5345185995101929	train_acc:0.9357142857142857	test_acc:0.79	test_f1:0.7789226731393059
epoch:12	train_loss:1.4658182859420776	train_acc:0.9714285714285714	test_acc:0.79	test_f1:0.7801629115347908
epoch:13	train_loss:1.4049506187438965	train_acc:0.95	test_acc:0.766	test_f1:0.761575858638528
epoch:14	train_loss:1.3409886360168457	train_acc:0.95	test_acc:0.748	test_f1:0.7488206056177438
epoch:15	train_loss:1.2900997400283813	train_acc:0.95	test_acc:0.738	test_f1:0.7401988899380688
epoch:16	train_loss:1.2106062173843384	train_acc:0.9571428571428572	test_acc:0.737	test_f1:0.7406594815175149
epoch:17	train_loss:1.1464951038360596	train_acc:0.9571428571428572	test_acc:0.746	test_f1:0.747950841757468
epoch:18	train_loss:1.0805901288986206	train_acc:0.9428571428571428	test_acc:0.763	test_f1:0.7615880812753891
epoch:19	train_loss:1.0079602003097534	train_acc:0.9642857142857143	test_acc:0.776	test_f1:0.7715764080438345
epoch:20	train_loss:0.9328995943069458	train_acc:0.9714285714285714	test_acc:0.788	test_f1:0.7810169587116399
epoch:21	train_loss:0.8671828508377075	train_acc:0.9571428571428572	test_acc:0.789	test_f1:0.7798199928725976
epoch:22	train_loss:0.8000487685203552	train_acc:0.9714285714285714	test_acc:0.787	test_f1:0.7784832787019624
epoch:23	train_loss:0.734902560710907	train_acc:0.9714285714285714	test_acc:0.787	test_f1:0.7773739870739111
epoch:24	train_loss:0.6710407137870789	train_acc:0.9714285714285714	test_acc:0.785	test_f1:0.7769864688712274
epoch:25	train_loss:0.611756443977356	train_acc:0.9714285714285714	test_acc:0.786	test_f1:0.7774190369480467
epoch:26	train_loss:0.5577475428581238	train_acc:0.9785714285714285	test_acc:0.789	test_f1:0.7794374968283595
epoch:27	train_loss:0.5082725882530212	train_acc:0.9714285714285714	test_acc:0.788	test_f1:0.7778062841917082
epoch:28	train_loss:0.46624577045440674	train_acc:0.9857142857142858	test_acc:0.787	test_f1:0.7767432778552978
epoch:29	train_loss:0.4219244718551636	train_acc:0.9785714285714285	test_acc:0.789	test_f1:0.7787428628338192
epoch:30	train_loss:0.3781764805316925	train_acc:0.9785714285714285	test_acc:0.794	test_f1:0.784193398763619
epoch:31	train_loss:0.3502655625343323	train_acc:0.9785714285714285	test_acc:0.795	test_f1:0.7845428865829867
epoch:32	train_loss:0.3090551495552063	train_acc:0.9785714285714285	test_acc:0.795	test_f1:0.7856020193262039
epoch:33	train_loss:0.27847880125045776	train_acc:0.9785714285714285	test_acc:0.794	test_f1:0.7842479339991699
epoch:34	train_loss:0.2521173655986786	train_acc:0.9928571428571429	test_acc:0.793	test_f1:0.7827438963648204
epoch:35	train_loss:0.22406408190727234	train_acc:0.9857142857142858	test_acc:0.79	test_f1:0.7800449426949422
epoch:36	train_loss:0.20513927936553955	train_acc:0.9857142857142858	test_acc:0.788	test_f1:0.7804060383999707
epoch:37	train_loss:0.18956109881401062	train_acc:0.9785714285714285	test_acc:0.793	test_f1:0.7827089919501314
epoch:38	train_loss:0.1700291782617569	train_acc:0.9857142857142858	test_acc:0.792	test_f1:0.7816405510756438
epoch:39	train_loss:0.15699993073940277	train_acc:0.9928571428571429	test_acc:0.794	test_f1:0.7841083174605276
epoch:40	train_loss:0.1442927122116089	train_acc:1.0	test_acc:0.793	test_f1:0.7822079754137187
epoch:41	train_loss:0.13048242032527924	train_acc:0.9928571428571429	test_acc:0.79	test_f1:0.7800241547204436
epoch:42	train_loss:0.12241042405366898	train_acc:0.9928571428571429	test_acc:0.789	test_f1:0.7791165047840548
epoch:43	train_loss:0.11242186278104782	train_acc:0.9928571428571429	test_acc:0.787	test_f1:0.7774424582874538
epoch:44	train_loss:0.10505297780036926	train_acc:0.9928571428571429	test_acc:0.785	test_f1:0.7763916998019795
epoch:45	train_loss:0.09376227110624313	train_acc:0.9928571428571429	test_acc:0.781	test_f1:0.7719129962037804
epoch:46	train_loss:0.09126940369606018	train_acc:0.9928571428571429	test_acc:0.781	test_f1:0.7709511402412595
epoch:47	train_loss:0.08294844627380371	train_acc:1.0	test_acc:0.784	test_f1:0.7743367623951006
epoch:48	train_loss:0.07937285304069519	train_acc:1.0	test_acc:0.786	test_f1:0.776827913620374
epoch:49	train_loss:0.07331641018390656	train_acc:1.0	test_acc:0.789	test_f1:0.7811278119169006
epoch:50	train_loss:0.07035978138446808	train_acc:1.0	test_acc:0.786	test_f1:0.7776889654021895
训练并测试结束，共训练50轮，总用时254.5018196105957s
最佳正确率为:0.795,对应的macro_f1为:0.7856020193262039,对应的训练轮次为:32



2022-07-01 20:54:05.987141
epoch:1	train_loss:1.9758045673370361	train_acc:0.12857142857142856	test_acc:0.221	test_f1:0.11748364468245562
epoch:2	train_loss:1.9119720458984375	train_acc:0.2857142857142857	test_acc:0.137	test_f1:0.05073161988587748
epoch:3	train_loss:1.8946090936660767	train_acc:0.22857142857142856	test_acc:0.152	test_f1:0.08566779133486256
epoch:4	train_loss:1.859455943107605	train_acc:0.2857142857142857	test_acc:0.333	test_f1:0.285705646195685
epoch:5	train_loss:1.816773772239685	train_acc:0.5071428571428571	test_acc:0.694	test_f1:0.6389726489998423
epoch:6	train_loss:1.7692784070968628	train_acc:0.8642857142857143	test_acc:0.66	test_f1:0.6145938458039709
epoch:7	train_loss:1.7385175228118896	train_acc:0.7785714285714286	test_acc:0.544	test_f1:0.5187035433744828
epoch:8	train_loss:1.703658103942871	train_acc:0.7571428571428571	test_acc:0.566	test_f1:0.5508343721048039
epoch:9	train_loss:1.6618213653564453	train_acc:0.8	test_acc:0.648	test_f1:0.6288237945293371
epoch:10	train_loss:1.6062155961990356	train_acc:0.9071428571428571	test_acc:0.684	test_f1:0.6738915560904326
epoch:11	train_loss:1.5590605735778809	train_acc:0.9142857142857143	test_acc:0.7	test_f1:0.7022346892469146
epoch:12	train_loss:1.4997457265853882	train_acc:0.9571428571428572	test_acc:0.717	test_f1:0.7165574659539643
epoch:13	train_loss:1.4464755058288574	train_acc:0.9571428571428572	test_acc:0.738	test_f1:0.7314041867423452
epoch:14	train_loss:1.3889355659484863	train_acc:0.9642857142857143	test_acc:0.764	test_f1:0.7575861394442923
epoch:15	train_loss:1.3289393186569214	train_acc:0.95	test_acc:0.781	test_f1:0.7739835979303892
epoch:16	train_loss:1.263103723526001	train_acc:0.9642857142857143	test_acc:0.786	test_f1:0.7737258783832809
epoch:17	train_loss:1.1927098035812378	train_acc:0.9642857142857143	test_acc:0.791	test_f1:0.7778613128695406
epoch:18	train_loss:1.1268023252487183	train_acc:0.9571428571428572	test_acc:0.791	test_f1:0.7838670664845725
epoch:19	train_loss:1.0592315196990967	train_acc:0.9571428571428572	test_acc:0.786	test_f1:0.7842938706283276
epoch:20	train_loss:0.9854814410209656	train_acc:0.95	test_acc:0.777	test_f1:0.775162011546915
epoch:21	train_loss:0.9263206720352173	train_acc:0.9714285714285714	test_acc:0.777	test_f1:0.7757603413268127
epoch:22	train_loss:0.8609729409217834	train_acc:0.9571428571428572	test_acc:0.78	test_f1:0.7773074857919336
epoch:23	train_loss:0.7936432361602783	train_acc:0.9571428571428572	test_acc:0.782	test_f1:0.7775781019792961
epoch:24	train_loss:0.7268574237823486	train_acc:0.9642857142857143	test_acc:0.786	test_f1:0.7794213510093867
epoch:25	train_loss:0.6614002585411072	train_acc:0.9714285714285714	test_acc:0.791	test_f1:0.7839586648344923
epoch:26	train_loss:0.6075232028961182	train_acc:0.9642857142857143	test_acc:0.79	test_f1:0.7810718967243869
epoch:27	train_loss:0.5566092133522034	train_acc:0.9785714285714285	test_acc:0.792	test_f1:0.7827561824814289
epoch:28	train_loss:0.5029813647270203	train_acc:0.9785714285714285	test_acc:0.794	test_f1:0.7863981876254796
epoch:29	train_loss:0.4525831639766693	train_acc:0.9785714285714285	test_acc:0.791	test_f1:0.7828992323337981
epoch:30	train_loss:0.4150199592113495	train_acc:0.9857142857142858	test_acc:0.789	test_f1:0.7813790742467601
epoch:31	train_loss:0.3827083110809326	train_acc:0.9785714285714285	test_acc:0.789	test_f1:0.7804816558454809
epoch:32	train_loss:0.33390578627586365	train_acc:0.9785714285714285	test_acc:0.79	test_f1:0.7826494728216249
epoch:33	train_loss:0.3056228756904602	train_acc:0.9785714285714285	test_acc:0.79	test_f1:0.7810890786494972
epoch:34	train_loss:0.2739972174167633	train_acc:0.9785714285714285	test_acc:0.79	test_f1:0.7810232436940888
epoch:35	train_loss:0.25302600860595703	train_acc:0.9857142857142858	test_acc:0.793	test_f1:0.7832938385936588
epoch:36	train_loss:0.2374674528837204	train_acc:0.9857142857142858	test_acc:0.796	test_f1:0.7856984558438936
epoch:37	train_loss:0.20660533010959625	train_acc:0.9857142857142858	test_acc:0.795	test_f1:0.7855721054165785
epoch:38	train_loss:0.19147147238254547	train_acc:0.9857142857142858	test_acc:0.794	test_f1:0.7843778426622938
epoch:39	train_loss:0.17186027765274048	train_acc:0.9928571428571429	test_acc:0.794	test_f1:0.7839307692924169
epoch:40	train_loss:0.158077672123909	train_acc:0.9928571428571429	test_acc:0.789	test_f1:0.7773218331348752
epoch:41	train_loss:0.14930276572704315	train_acc:0.9928571428571429	test_acc:0.79	test_f1:0.77873535102325
epoch:42	train_loss:0.13365839421749115	train_acc:1.0	test_acc:0.789	test_f1:0.77887745533648
epoch:43	train_loss:0.12184669077396393	train_acc:0.9928571428571429	test_acc:0.788	test_f1:0.7775669479075366
epoch:44	train_loss:0.11231669783592224	train_acc:1.0	test_acc:0.787	test_f1:0.7783002600463205
epoch:45	train_loss:0.10336035490036011	train_acc:1.0	test_acc:0.788	test_f1:0.7793668705397654
epoch:46	train_loss:0.10105226933956146	train_acc:1.0	test_acc:0.788	test_f1:0.7788435827037208
epoch:47	train_loss:0.0954396054148674	train_acc:1.0	test_acc:0.782	test_f1:0.7728747498272776
epoch:48	train_loss:0.08493775874376297	train_acc:1.0	test_acc:0.783	test_f1:0.7732452501403148
epoch:49	train_loss:0.08361770212650299	train_acc:1.0	test_acc:0.784	test_f1:0.776307884394068
epoch:50	train_loss:0.08206610381603241	train_acc:1.0	test_acc:0.783	test_f1:0.7756384721134654
训练并测试结束，共训练50轮，总用时259.48096776008606s
最佳正确率为:0.796,对应的macro_f1为:0.7856984558438936,对应的训练轮次为:36



2022-07-01 20:58:53.780696
epoch:1	train_loss:2.0184643268585205	train_acc:0.15357142857142858	test_acc:0.194	test_f1:0.11023982355742855
epoch:2	train_loss:1.9235615730285645	train_acc:0.25357142857142856	test_acc:0.329	test_f1:0.09318398335022651
epoch:3	train_loss:1.9025578498840332	train_acc:0.25	test_acc:0.217	test_f1:0.10332673537642481
epoch:4	train_loss:1.885327935218811	train_acc:0.24642857142857144	test_acc:0.141	test_f1:0.07797967713521517
epoch:5	train_loss:1.8569872379302979	train_acc:0.22857142857142856	test_acc:0.26	test_f1:0.20830526178119763
epoch:6	train_loss:1.8181376457214355	train_acc:0.36428571428571427	test_acc:0.458	test_f1:0.4197618860111056
epoch:7	train_loss:1.7771787643432617	train_acc:0.5928571428571429	test_acc:0.667	test_f1:0.6888009289646779
epoch:8	train_loss:1.7376168966293335	train_acc:0.8214285714285714	test_acc:0.597	test_f1:0.5929972519277721
epoch:9	train_loss:1.7007315158843994	train_acc:0.8178571428571428	test_acc:0.527	test_f1:0.5000992868694404
epoch:10	train_loss:1.6635390520095825	train_acc:0.7607142857142857	test_acc:0.521	test_f1:0.5045609541091363
epoch:11	train_loss:1.6317992210388184	train_acc:0.7321428571428571	test_acc:0.58	test_f1:0.5774560889805898
epoch:12	train_loss:1.5845320224761963	train_acc:0.7964285714285714	test_acc:0.678	test_f1:0.6705169707389826
epoch:13	train_loss:1.5317004919052124	train_acc:0.8464285714285714	test_acc:0.746	test_f1:0.7347145225402295
epoch:14	train_loss:1.4821401834487915	train_acc:0.8821428571428571	test_acc:0.784	test_f1:0.7808104015756879
epoch:15	train_loss:1.4250528812408447	train_acc:0.9035714285714286	test_acc:0.782	test_f1:0.7801191529549053
epoch:16	train_loss:1.3731893301010132	train_acc:0.9035714285714286	test_acc:0.77	test_f1:0.7675867026448314
epoch:17	train_loss:1.3154387474060059	train_acc:0.8964285714285715	test_acc:0.771	test_f1:0.7702309184269532
epoch:18	train_loss:1.2572513818740845	train_acc:0.8892857142857142	test_acc:0.778	test_f1:0.7775342003937687
epoch:19	train_loss:1.2064117193222046	train_acc:0.8785714285714286	test_acc:0.779	test_f1:0.7792837842203666
epoch:20	train_loss:1.1401528120040894	train_acc:0.9071428571428571	test_acc:0.784	test_f1:0.7820003743990647
epoch:21	train_loss:1.0786662101745605	train_acc:0.9071428571428571	test_acc:0.784	test_f1:0.781278318585717
epoch:22	train_loss:1.0167317390441895	train_acc:0.9071428571428571	test_acc:0.784	test_f1:0.7797260777016606
epoch:23	train_loss:0.9507147669792175	train_acc:0.9107142857142857	test_acc:0.777	test_f1:0.7707751440100277
epoch:24	train_loss:0.8902867436408997	train_acc:0.9035714285714286	test_acc:0.777	test_f1:0.7702515264760798
epoch:25	train_loss:0.8394641876220703	train_acc:0.9	test_acc:0.78	test_f1:0.7743647809473367
epoch:26	train_loss:0.7720054984092712	train_acc:0.8964285714285715	test_acc:0.793	test_f1:0.7888550910105835
epoch:27	train_loss:0.719740629196167	train_acc:0.9107142857142857	test_acc:0.801	test_f1:0.7984898721553383
epoch:28	train_loss:0.6623134613037109	train_acc:0.925	test_acc:0.805	test_f1:0.8019916064660173
epoch:29	train_loss:0.6221132874488831	train_acc:0.9285714285714286	test_acc:0.802	test_f1:0.7957529426721687
epoch:30	train_loss:0.57523512840271	train_acc:0.925	test_acc:0.801	test_f1:0.7961495621841844
epoch:31	train_loss:0.5400471091270447	train_acc:0.925	test_acc:0.802	test_f1:0.797712598688645
epoch:32	train_loss:0.49222132563591003	train_acc:0.9321428571428572	test_acc:0.801	test_f1:0.7968107228712142
epoch:33	train_loss:0.4571833908557892	train_acc:0.9321428571428572	test_acc:0.8	test_f1:0.795762099779736
epoch:34	train_loss:0.4300576448440552	train_acc:0.925	test_acc:0.803	test_f1:0.7979317976220377
epoch:35	train_loss:0.39583224058151245	train_acc:0.9392857142857143	test_acc:0.809	test_f1:0.8021272158373998
epoch:36	train_loss:0.36624082922935486	train_acc:0.9428571428571428	test_acc:0.812	test_f1:0.8033627726848934
epoch:37	train_loss:0.33953267335891724	train_acc:0.95	test_acc:0.816	test_f1:0.8073866585696982
epoch:38	train_loss:0.3149160146713257	train_acc:0.9571428571428572	test_acc:0.822	test_f1:0.8135785725525724
epoch:39	train_loss:0.2914270758628845	train_acc:0.9535714285714286	test_acc:0.822	test_f1:0.8131422358101082
epoch:40	train_loss:0.2694844901561737	train_acc:0.9571428571428572	test_acc:0.822	test_f1:0.8133572826578401
epoch:41	train_loss:0.2540838420391083	train_acc:0.9678571428571429	test_acc:0.822	test_f1:0.8129454140564949
epoch:42	train_loss:0.2396828532218933	train_acc:0.9678571428571429	test_acc:0.824	test_f1:0.81571158716847
epoch:43	train_loss:0.22457805275917053	train_acc:0.9714285714285714	test_acc:0.823	test_f1:0.8158241472116722
epoch:44	train_loss:0.2120264321565628	train_acc:0.9714285714285714	test_acc:0.826	test_f1:0.818164470220264
epoch:45	train_loss:0.19806046783924103	train_acc:0.9785714285714285	test_acc:0.825	test_f1:0.8172769303059079
epoch:46	train_loss:0.18857145309448242	train_acc:0.975	test_acc:0.823	test_f1:0.8149070898379059
epoch:47	train_loss:0.17103074491024017	train_acc:0.9928571428571429	test_acc:0.826	test_f1:0.8198141294962349
epoch:48	train_loss:0.1636032611131668	train_acc:0.9928571428571429	test_acc:0.824	test_f1:0.8189277563268921
epoch:49	train_loss:0.15145961940288544	train_acc:0.9928571428571429	test_acc:0.824	test_f1:0.8183902142279794
epoch:50	train_loss:0.1441497653722763	train_acc:0.9928571428571429	test_acc:0.821	test_f1:0.8168627238829479
训练并测试结束，共训练50轮，总用时234.09969520568848s
最佳正确率为:0.826,对应的macro_f1为:0.8198141294962349,对应的训练轮次为:47



2022-07-01 21:03:03.198193
epoch:1	train_loss:1.9599616527557373	train_acc:0.11071428571428571	test_acc:0.149	test_f1:0.03705085167226159
epoch:2	train_loss:1.922777533531189	train_acc:0.15714285714285714	test_acc:0.235	test_f1:0.09873677724145012
epoch:3	train_loss:1.89488685131073	train_acc:0.21785714285714286	test_acc:0.601	test_f1:0.49282201362850664
epoch:4	train_loss:1.8650903701782227	train_acc:0.5071428571428571	test_acc:0.524	test_f1:0.5456034142331058
epoch:5	train_loss:1.8257123231887817	train_acc:0.6821428571428572	test_acc:0.453	test_f1:0.49117735631309284
epoch:6	train_loss:1.7997418642044067	train_acc:0.6892857142857143	test_acc:0.45	test_f1:0.5187984938685547
epoch:7	train_loss:1.7557328939437866	train_acc:0.7428571428571429	test_acc:0.557	test_f1:0.5803279817343104
epoch:8	train_loss:1.721243977546692	train_acc:0.825	test_acc:0.675	test_f1:0.6842554612822497
epoch:9	train_loss:1.680286169052124	train_acc:0.8714285714285714	test_acc:0.762	test_f1:0.7637223202470619
epoch:10	train_loss:1.6329867839813232	train_acc:0.8821428571428571	test_acc:0.802	test_f1:0.7958636619040824
epoch:11	train_loss:1.591723084449768	train_acc:0.8821428571428571	test_acc:0.813	test_f1:0.8032966079440901
epoch:12	train_loss:1.5384352207183838	train_acc:0.8892857142857142	test_acc:0.8	test_f1:0.7941826759110354
epoch:13	train_loss:1.4895704984664917	train_acc:0.8785714285714286	test_acc:0.781	test_f1:0.7808927940364733
epoch:14	train_loss:1.4380241632461548	train_acc:0.8892857142857142	test_acc:0.765	test_f1:0.7674742101763475
epoch:15	train_loss:1.3774970769882202	train_acc:0.9	test_acc:0.748	test_f1:0.7527509257674038
epoch:16	train_loss:1.3200511932373047	train_acc:0.8892857142857142	test_acc:0.744	test_f1:0.7481935887012785
epoch:17	train_loss:1.252776861190796	train_acc:0.9	test_acc:0.766	test_f1:0.7643709214614012
epoch:18	train_loss:1.2015607357025146	train_acc:0.9	test_acc:0.785	test_f1:0.7800865199363498
epoch:19	train_loss:1.13115394115448	train_acc:0.9107142857142857	test_acc:0.796	test_f1:0.7887030800177197
epoch:20	train_loss:1.0655900239944458	train_acc:0.9071428571428571	test_acc:0.802	test_f1:0.7957343981591176
epoch:21	train_loss:0.9976242780685425	train_acc:0.9107142857142857	test_acc:0.802	test_f1:0.796218707312633
epoch:22	train_loss:0.9329546093940735	train_acc:0.9214285714285714	test_acc:0.797	test_f1:0.7925114538155859
epoch:23	train_loss:0.8747749328613281	train_acc:0.9107142857142857	test_acc:0.795	test_f1:0.7901920425895835
epoch:24	train_loss:0.8118364214897156	train_acc:0.9035714285714286	test_acc:0.798	test_f1:0.7927150325831026
epoch:25	train_loss:0.7619104981422424	train_acc:0.9178571428571428	test_acc:0.797	test_f1:0.7894955581354657
epoch:26	train_loss:0.7041441798210144	train_acc:0.9321428571428572	test_acc:0.797	test_f1:0.7890754108274807
epoch:27	train_loss:0.6425642967224121	train_acc:0.9321428571428572	test_acc:0.8	test_f1:0.7911311319381038
epoch:28	train_loss:0.6040905714035034	train_acc:0.925	test_acc:0.803	test_f1:0.7950104048161503
epoch:29	train_loss:0.5567707419395447	train_acc:0.9357142857142857	test_acc:0.812	test_f1:0.8049889440114111
epoch:30	train_loss:0.513166606426239	train_acc:0.9392857142857143	test_acc:0.814	test_f1:0.8051246851276288
epoch:31	train_loss:0.47572794556617737	train_acc:0.9392857142857143	test_acc:0.816	test_f1:0.8076921181352209
epoch:32	train_loss:0.4414864778518677	train_acc:0.9535714285714286	test_acc:0.815	test_f1:0.8054753010979202
epoch:33	train_loss:0.4102689027786255	train_acc:0.9535714285714286	test_acc:0.815	test_f1:0.8060633436994534
epoch:34	train_loss:0.3755185902118683	train_acc:0.95	test_acc:0.812	test_f1:0.8030554666409851
epoch:35	train_loss:0.3455609083175659	train_acc:0.9571428571428572	test_acc:0.818	test_f1:0.8098519291874788
epoch:36	train_loss:0.3273073732852936	train_acc:0.9428571428571428	test_acc:0.815	test_f1:0.8076310774802478
epoch:37	train_loss:0.30020052194595337	train_acc:0.9571428571428572	test_acc:0.82	test_f1:0.8116689413127389
epoch:38	train_loss:0.27858150005340576	train_acc:0.9642857142857143	test_acc:0.824	test_f1:0.8149643566865192
epoch:39	train_loss:0.2621152698993683	train_acc:0.9642857142857143	test_acc:0.823	test_f1:0.8136319419377468
epoch:40	train_loss:0.240798681974411	train_acc:0.9714285714285714	test_acc:0.821	test_f1:0.8118835781646251
epoch:41	train_loss:0.2222377508878708	train_acc:0.9714285714285714	test_acc:0.825	test_f1:0.8149352856961912
epoch:42	train_loss:0.2078574299812317	train_acc:0.975	test_acc:0.827	test_f1:0.8182463359643332
epoch:43	train_loss:0.197477325797081	train_acc:0.9892857142857143	test_acc:0.83	test_f1:0.820778686345999
epoch:44	train_loss:0.17943570017814636	train_acc:0.9857142857142858	test_acc:0.828	test_f1:0.8184379621069872
epoch:45	train_loss:0.1669265627861023	train_acc:0.9892857142857143	test_acc:0.826	test_f1:0.8178193975265178
epoch:46	train_loss:0.16072411835193634	train_acc:1.0	test_acc:0.824	test_f1:0.8152218451554815
epoch:47	train_loss:0.15230770409107208	train_acc:0.9964285714285714	test_acc:0.823	test_f1:0.8136519825136118
epoch:48	train_loss:0.14148563146591187	train_acc:1.0	test_acc:0.823	test_f1:0.8144196827369745
epoch:49	train_loss:0.1376766860485077	train_acc:1.0	test_acc:0.827	test_f1:0.818011824056019
epoch:50	train_loss:0.12952955067157745	train_acc:1.0	test_acc:0.828	test_f1:0.8190491279747711
训练并测试结束，共训练50轮，总用时229.97916293144226s
最佳正确率为:0.83,对应的macro_f1为:0.820778686345999,对应的训练轮次为:43



2022-07-01 21:07:17.902845
epoch:1	train_loss:2.081911087036133	train_acc:0.14285714285714285	test_acc:0.104	test_f1:0.07752155980502438
epoch:2	train_loss:1.950100302696228	train_acc:0.21071428571428572	test_acc:0.327	test_f1:0.24676051293427817
epoch:3	train_loss:1.8917150497436523	train_acc:0.3464285714285714	test_acc:0.148	test_f1:0.07590480154247323
epoch:4	train_loss:1.882905125617981	train_acc:0.18214285714285713	test_acc:0.208	test_f1:0.1309669596481809
epoch:5	train_loss:1.8684077262878418	train_acc:0.2357142857142857	test_acc:0.177	test_f1:0.11538972655251725
epoch:6	train_loss:1.8328871726989746	train_acc:0.26071428571428573	test_acc:0.181	test_f1:0.14792566408644578
epoch:7	train_loss:1.7849535942077637	train_acc:0.3107142857142857	test_acc:0.547	test_f1:0.4752871336379179
epoch:8	train_loss:1.746512770652771	train_acc:0.6178571428571429	test_acc:0.709	test_f1:0.6837915796871509
epoch:9	train_loss:1.7055613994598389	train_acc:0.7821428571428571	test_acc:0.722	test_f1:0.6582397574279206
epoch:10	train_loss:1.6660348176956177	train_acc:0.8142857142857143	test_acc:0.698	test_f1:0.6076244521665395
epoch:11	train_loss:1.6302322149276733	train_acc:0.7714285714285715	test_acc:0.642	test_f1:0.5584008126122144
epoch:12	train_loss:1.5922698974609375	train_acc:0.7464285714285714	test_acc:0.621	test_f1:0.5613487844693431
epoch:13	train_loss:1.5478097200393677	train_acc:0.75	test_acc:0.662	test_f1:0.63066027889763
epoch:14	train_loss:1.4985946416854858	train_acc:0.8428571428571429	test_acc:0.724	test_f1:0.7091069946970094
epoch:15	train_loss:1.452510952949524	train_acc:0.8785714285714286	test_acc:0.754	test_f1:0.7494215726682757
epoch:16	train_loss:1.3924355506896973	train_acc:0.9071428571428571	test_acc:0.786	test_f1:0.7898778535481018
epoch:17	train_loss:1.3388622999191284	train_acc:0.9142857142857143	test_acc:0.781	test_f1:0.779690828503826
epoch:18	train_loss:1.2820931673049927	train_acc:0.9107142857142857	test_acc:0.776	test_f1:0.7687943695758485
epoch:19	train_loss:1.2303376197814941	train_acc:0.9	test_acc:0.785	test_f1:0.7748789884258483
epoch:20	train_loss:1.174928069114685	train_acc:0.8821428571428571	test_acc:0.803	test_f1:0.7923423238452336
epoch:21	train_loss:1.1137241125106812	train_acc:0.9107142857142857	test_acc:0.812	test_f1:0.8037819128525001
epoch:22	train_loss:1.044634222984314	train_acc:0.9	test_acc:0.817	test_f1:0.8103390091016662
epoch:23	train_loss:0.9858587384223938	train_acc:0.9214285714285714	test_acc:0.81	test_f1:0.8056964087296926
epoch:24	train_loss:0.9233971834182739	train_acc:0.9178571428571428	test_acc:0.801	test_f1:0.7949563203839549
epoch:25	train_loss:0.8684661388397217	train_acc:0.9285714285714286	test_acc:0.795	test_f1:0.7863315171569528
epoch:26	train_loss:0.8072386980056763	train_acc:0.9214285714285714	test_acc:0.793	test_f1:0.783889039554498
epoch:27	train_loss:0.7526974678039551	train_acc:0.925	test_acc:0.798	test_f1:0.7910282153756134
epoch:28	train_loss:0.701026976108551	train_acc:0.925	test_acc:0.807	test_f1:0.8018286846478301
epoch:29	train_loss:0.6548023819923401	train_acc:0.9285714285714286	test_acc:0.812	test_f1:0.8060904613656553
epoch:30	train_loss:0.604271411895752	train_acc:0.9321428571428572	test_acc:0.814	test_f1:0.8086145317627483
epoch:31	train_loss:0.5574585199356079	train_acc:0.9428571428571428	test_acc:0.824	test_f1:0.8175132181034329
epoch:32	train_loss:0.5195965766906738	train_acc:0.9357142857142857	test_acc:0.822	test_f1:0.8139085077453608
epoch:33	train_loss:0.479922890663147	train_acc:0.9357142857142857	test_acc:0.826	test_f1:0.8200623131338037
epoch:34	train_loss:0.44071125984191895	train_acc:0.9535714285714286	test_acc:0.82	test_f1:0.8144969869278255
epoch:35	train_loss:0.4103555977344513	train_acc:0.9464285714285714	test_acc:0.817	test_f1:0.8107416704282214
epoch:36	train_loss:0.3785630762577057	train_acc:0.95	test_acc:0.813	test_f1:0.8074741076831177
epoch:37	train_loss:0.35268083214759827	train_acc:0.9464285714285714	test_acc:0.821	test_f1:0.8158691415033018
epoch:38	train_loss:0.32609814405441284	train_acc:0.9428571428571428	test_acc:0.82	test_f1:0.8137937853558033
epoch:39	train_loss:0.3060618042945862	train_acc:0.95	test_acc:0.826	test_f1:0.8201019091264289
epoch:40	train_loss:0.28500378131866455	train_acc:0.9607142857142857	test_acc:0.827	test_f1:0.8204405553806849
epoch:41	train_loss:0.2635834217071533	train_acc:0.9714285714285714	test_acc:0.829	test_f1:0.8237033956789502
epoch:42	train_loss:0.24195612967014313	train_acc:0.9714285714285714	test_acc:0.827	test_f1:0.8206055807985926
epoch:43	train_loss:0.22851213812828064	train_acc:0.9678571428571429	test_acc:0.824	test_f1:0.8169042969574535
epoch:44	train_loss:0.214117169380188	train_acc:0.9857142857142858	test_acc:0.824	test_f1:0.8161554647422893
epoch:45	train_loss:0.2010229229927063	train_acc:0.9857142857142858	test_acc:0.825	test_f1:0.8170793342876854
epoch:46	train_loss:0.19119131565093994	train_acc:0.9821428571428571	test_acc:0.826	test_f1:0.8191474020509365
epoch:47	train_loss:0.1814575344324112	train_acc:0.9928571428571429	test_acc:0.827	test_f1:0.8199561223928267
epoch:48	train_loss:0.1668509542942047	train_acc:0.9928571428571429	test_acc:0.83	test_f1:0.8227095581881344
epoch:49	train_loss:0.1591125726699829	train_acc:0.9928571428571429	test_acc:0.83	test_f1:0.8229454439622509
epoch:50	train_loss:0.14836148917675018	train_acc:1.0	test_acc:0.828	test_f1:0.8217895342029845
训练并测试结束，共训练50轮，总用时228.8395595550537s
最佳正确率为:0.83,对应的macro_f1为:0.8229454439622509,对应的训练轮次为:49



2022-07-01 21:12:04.049589
epoch:1	train_loss:1.9975444078445435	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:2	train_loss:1.9277559518814087	train_acc:0.14761904761904762	test_acc:0.161	test_f1:0.16512129281626034
epoch:3	train_loss:1.9002593755722046	train_acc:0.30238095238095236	test_acc:0.064	test_f1:0.017185821697099892
epoch:4	train_loss:1.881119728088379	train_acc:0.14285714285714285	test_acc:0.066	test_f1:0.02154719103871646
epoch:5	train_loss:1.8537715673446655	train_acc:0.15	test_acc:0.246	test_f1:0.32567039530572334
epoch:6	train_loss:1.8168587684631348	train_acc:0.44761904761904764	test_acc:0.493	test_f1:0.5167564257955388
epoch:7	train_loss:1.7795464992523193	train_acc:0.669047619047619	test_acc:0.716	test_f1:0.7154170269975311
epoch:8	train_loss:1.7416824102401733	train_acc:0.830952380952381	test_acc:0.813	test_f1:0.7834346734873155
epoch:9	train_loss:1.7050724029541016	train_acc:0.8238095238095238	test_acc:0.749	test_f1:0.7093830759076276
epoch:10	train_loss:1.67588472366333	train_acc:0.7452380952380953	test_acc:0.714	test_f1:0.6756971423435351
epoch:11	train_loss:1.6380985975265503	train_acc:0.7404761904761905	test_acc:0.736	test_f1:0.7084737085496647
epoch:12	train_loss:1.593267798423767	train_acc:0.7785714285714286	test_acc:0.776	test_f1:0.7601110463601907
epoch:13	train_loss:1.5450694561004639	train_acc:0.8380952380952381	test_acc:0.808	test_f1:0.7959425001003482
epoch:14	train_loss:1.4956355094909668	train_acc:0.8857142857142857	test_acc:0.794	test_f1:0.7816368523863055
epoch:15	train_loss:1.4426076412200928	train_acc:0.8833333333333333	test_acc:0.783	test_f1:0.7719344951259778
epoch:16	train_loss:1.3935935497283936	train_acc:0.888095238095238	test_acc:0.763	test_f1:0.7577692533033611
epoch:17	train_loss:1.3417938947677612	train_acc:0.8809523809523809	test_acc:0.763	test_f1:0.7621568670584817
epoch:18	train_loss:1.2835184335708618	train_acc:0.888095238095238	test_acc:0.769	test_f1:0.7680230450429557
epoch:19	train_loss:1.2250713109970093	train_acc:0.8976190476190476	test_acc:0.779	test_f1:0.7761410068671232
epoch:20	train_loss:1.1640734672546387	train_acc:0.9071428571428571	test_acc:0.796	test_f1:0.7885981835126058
epoch:21	train_loss:1.099307894706726	train_acc:0.9023809523809524	test_acc:0.807	test_f1:0.7972925571382864
epoch:22	train_loss:1.0424917936325073	train_acc:0.9119047619047619	test_acc:0.809	test_f1:0.7988939224509595
epoch:23	train_loss:0.9834062457084656	train_acc:0.888095238095238	test_acc:0.809	test_f1:0.798924198335711
epoch:24	train_loss:0.9263240694999695	train_acc:0.8976190476190476	test_acc:0.812	test_f1:0.8008436942782121
epoch:25	train_loss:0.8636865615844727	train_acc:0.9119047619047619	test_acc:0.813	test_f1:0.8028651695837106
epoch:26	train_loss:0.8029956221580505	train_acc:0.9142857142857143	test_acc:0.818	test_f1:0.8074427897873472
epoch:27	train_loss:0.7509638071060181	train_acc:0.9166666666666666	test_acc:0.816	test_f1:0.8078553483768521
epoch:28	train_loss:0.6992745399475098	train_acc:0.9119047619047619	test_acc:0.811	test_f1:0.8036598161619557
epoch:29	train_loss:0.6534849405288696	train_acc:0.9142857142857143	test_acc:0.808	test_f1:0.8009127482461481
epoch:30	train_loss:0.6064919233322144	train_acc:0.9142857142857143	test_acc:0.807	test_f1:0.7996789100835123
epoch:31	train_loss:0.5659914016723633	train_acc:0.9214285714285714	test_acc:0.815	test_f1:0.8083715824465434
epoch:32	train_loss:0.526802659034729	train_acc:0.9238095238095239	test_acc:0.822	test_f1:0.8150226768146337
epoch:33	train_loss:0.4953802824020386	train_acc:0.9238095238095239	test_acc:0.82	test_f1:0.8124114947794885
epoch:34	train_loss:0.46333128213882446	train_acc:0.9285714285714286	test_acc:0.822	test_f1:0.8138415064705784
epoch:35	train_loss:0.42967620491981506	train_acc:0.930952380952381	test_acc:0.822	test_f1:0.8132193553308815
epoch:36	train_loss:0.40362703800201416	train_acc:0.9380952380952381	test_acc:0.82	test_f1:0.8114281947758741
epoch:37	train_loss:0.37909257411956787	train_acc:0.9357142857142857	test_acc:0.82	test_f1:0.8120716779379943
epoch:38	train_loss:0.35751184821128845	train_acc:0.9476190476190476	test_acc:0.82	test_f1:0.8130220406482938
epoch:39	train_loss:0.33228424191474915	train_acc:0.9476190476190476	test_acc:0.819	test_f1:0.8120963112898675
epoch:40	train_loss:0.31583890318870544	train_acc:0.95	test_acc:0.822	test_f1:0.8142650343424315
epoch:41	train_loss:0.29272642731666565	train_acc:0.9523809523809523	test_acc:0.823	test_f1:0.8154504734069338
epoch:42	train_loss:0.27863609790802	train_acc:0.9523809523809523	test_acc:0.825	test_f1:0.8160841061693855
epoch:43	train_loss:0.2585403025150299	train_acc:0.9571428571428572	test_acc:0.823	test_f1:0.8146160352856667
epoch:44	train_loss:0.2510778605937958	train_acc:0.9595238095238096	test_acc:0.824	test_f1:0.8156987153333145
epoch:45	train_loss:0.23285576701164246	train_acc:0.9666666666666667	test_acc:0.828	test_f1:0.8198225450312757
epoch:46	train_loss:0.22283343970775604	train_acc:0.9642857142857143	test_acc:0.831	test_f1:0.822728234712354
epoch:47	train_loss:0.20956939458847046	train_acc:0.9738095238095238	test_acc:0.831	test_f1:0.822385649992966
epoch:48	train_loss:0.20417003333568573	train_acc:0.9714285714285714	test_acc:0.833	test_f1:0.8239416257357987
epoch:49	train_loss:0.19159992039203644	train_acc:0.9714285714285714	test_acc:0.833	test_f1:0.823928914777154
epoch:50	train_loss:0.18596144020557404	train_acc:0.9714285714285714	test_acc:0.835	test_f1:0.8254348207311822
训练并测试结束，共训练50轮，总用时226.95100855827332s
最佳正确率为:0.835,对应的macro_f1为:0.8254348207311822,对应的训练轮次为:50



2022-07-01 21:16:52.737390
epoch:1	train_loss:1.9838212728500366	train_acc:0.13095238095238096	test_acc:0.451	test_f1:0.2660127858405471
epoch:2	train_loss:1.9230395555496216	train_acc:0.2761904761904762	test_acc:0.091	test_f1:0.02383134738771769
epoch:3	train_loss:1.9005484580993652	train_acc:0.15714285714285714	test_acc:0.091	test_f1:0.02383134738771769
epoch:4	train_loss:1.8785687685012817	train_acc:0.14523809523809525	test_acc:0.123	test_f1:0.09146207437188988
epoch:5	train_loss:1.8463658094406128	train_acc:0.24761904761904763	test_acc:0.58	test_f1:0.6001802670269775
epoch:6	train_loss:1.8105274438858032	train_acc:0.7333333333333333	test_acc:0.689	test_f1:0.6422123160656555
epoch:7	train_loss:1.7852507829666138	train_acc:0.7380952380952381	test_acc:0.682	test_f1:0.571836800830069
epoch:8	train_loss:1.7586694955825806	train_acc:0.680952380952381	test_acc:0.687	test_f1:0.5879475699003718
epoch:9	train_loss:1.723026990890503	train_acc:0.7214285714285714	test_acc:0.726	test_f1:0.6615874151184971
epoch:10	train_loss:1.686923861503601	train_acc:0.7619047619047619	test_acc:0.802	test_f1:0.7813771811616255
epoch:11	train_loss:1.6426414251327515	train_acc:0.861904761904762	test_acc:0.819	test_f1:0.8104952986230902
epoch:12	train_loss:1.605299472808838	train_acc:0.8952380952380953	test_acc:0.763	test_f1:0.7634167070185953
epoch:13	train_loss:1.5600652694702148	train_acc:0.8809523809523809	test_acc:0.696	test_f1:0.7077044886857908
epoch:14	train_loss:1.5148533582687378	train_acc:0.8714285714285714	test_acc:0.684	test_f1:0.6983714248503682
epoch:15	train_loss:1.46677827835083	train_acc:0.85	test_acc:0.709	test_f1:0.7146969110664122
epoch:16	train_loss:1.4170187711715698	train_acc:0.8785714285714286	test_acc:0.753	test_f1:0.751661664753917
epoch:17	train_loss:1.3579059839248657	train_acc:0.888095238095238	test_acc:0.786	test_f1:0.7831090059046666
epoch:18	train_loss:1.3030498027801514	train_acc:0.8976190476190476	test_acc:0.804	test_f1:0.7988701215804547
epoch:19	train_loss:1.2431410551071167	train_acc:0.8952380952380953	test_acc:0.817	test_f1:0.808004151237965
epoch:20	train_loss:1.1868033409118652	train_acc:0.8976190476190476	test_acc:0.826	test_f1:0.8163935375704295
epoch:21	train_loss:1.1315232515335083	train_acc:0.9023809523809524	test_acc:0.831	test_f1:0.82064208492629
epoch:22	train_loss:1.0673611164093018	train_acc:0.9071428571428571	test_acc:0.817	test_f1:0.8077891605601212
epoch:23	train_loss:1.0053526163101196	train_acc:0.8976190476190476	test_acc:0.802	test_f1:0.7952001540908779
epoch:24	train_loss:0.941030740737915	train_acc:0.9095238095238095	test_acc:0.794	test_f1:0.7881094300321915
epoch:25	train_loss:0.8871076107025146	train_acc:0.9047619047619048	test_acc:0.793	test_f1:0.7881777979614929
epoch:26	train_loss:0.833321750164032	train_acc:0.8976190476190476	test_acc:0.797	test_f1:0.7931627387730626
epoch:27	train_loss:0.7804303765296936	train_acc:0.9119047619047619	test_acc:0.806	test_f1:0.8015122479526087
epoch:28	train_loss:0.7249454259872437	train_acc:0.9166666666666666	test_acc:0.822	test_f1:0.8144564615629194
epoch:29	train_loss:0.6800239682197571	train_acc:0.9119047619047619	test_acc:0.83	test_f1:0.8210359839975248
epoch:30	train_loss:0.6358026266098022	train_acc:0.9095238095238095	test_acc:0.833	test_f1:0.823645443337961
epoch:31	train_loss:0.5884987115859985	train_acc:0.9095238095238095	test_acc:0.826	test_f1:0.816715121341254
epoch:32	train_loss:0.5532345771789551	train_acc:0.9214285714285714	test_acc:0.824	test_f1:0.8159866710373915
epoch:33	train_loss:0.515440821647644	train_acc:0.919047619047619	test_acc:0.824	test_f1:0.8162826293413649
epoch:34	train_loss:0.47846290469169617	train_acc:0.9214285714285714	test_acc:0.821	test_f1:0.8127802523778472
epoch:35	train_loss:0.44439876079559326	train_acc:0.930952380952381	test_acc:0.822	test_f1:0.8154008464551951
epoch:36	train_loss:0.41692784428596497	train_acc:0.9333333333333333	test_acc:0.822	test_f1:0.8150102988546362
epoch:37	train_loss:0.3903639614582062	train_acc:0.9404761904761905	test_acc:0.825	test_f1:0.8175727269602534
epoch:38	train_loss:0.36849501729011536	train_acc:0.930952380952381	test_acc:0.827	test_f1:0.8199101118306352
epoch:39	train_loss:0.3425581455230713	train_acc:0.9404761904761905	test_acc:0.827	test_f1:0.8199101118306352
epoch:40	train_loss:0.3221924304962158	train_acc:0.9428571428571428	test_acc:0.828	test_f1:0.8204777555213231
epoch:41	train_loss:0.30349186062812805	train_acc:0.9452380952380952	test_acc:0.827	test_f1:0.820202874624827
epoch:42	train_loss:0.2918444871902466	train_acc:0.9452380952380952	test_acc:0.827	test_f1:0.8196382725208611
epoch:43	train_loss:0.26560160517692566	train_acc:0.9523809523809523	test_acc:0.827	test_f1:0.8192995424108578
epoch:44	train_loss:0.25397059321403503	train_acc:0.9595238095238096	test_acc:0.827	test_f1:0.8192617812340844
epoch:45	train_loss:0.24476654827594757	train_acc:0.9619047619047619	test_acc:0.829	test_f1:0.82138430124052
epoch:46	train_loss:0.22792157530784607	train_acc:0.9666666666666667	test_acc:0.833	test_f1:0.8247353314724178
epoch:47	train_loss:0.21502315998077393	train_acc:0.9714285714285714	test_acc:0.834	test_f1:0.824567546063762
epoch:48	train_loss:0.2092968076467514	train_acc:0.969047619047619	test_acc:0.835	test_f1:0.8274572686627629
epoch:49	train_loss:0.1961333453655243	train_acc:0.9714285714285714	test_acc:0.835	test_f1:0.827635695788997
epoch:50	train_loss:0.19081591069698334	train_acc:0.9761904761904762	test_acc:0.838	test_f1:0.8299177392463665
训练并测试结束，共训练50轮，总用时228.60849261283875s
最佳正确率为:0.838,对应的macro_f1为:0.8299177392463665,对应的训练轮次为:50



2022-07-01 21:20:59.024761
epoch:1	train_loss:1.9790319204330444	train_acc:0.14285714285714285	test_acc:0.166	test_f1:0.09555905980639788
epoch:2	train_loss:1.9241926670074463	train_acc:0.16666666666666666	test_acc:0.363	test_f1:0.16489333563337358
epoch:3	train_loss:1.896602749824524	train_acc:0.30714285714285716	test_acc:0.425	test_f1:0.21407596140449783
epoch:4	train_loss:1.8789219856262207	train_acc:0.3333333333333333	test_acc:0.27	test_f1:0.1972228883822633
epoch:5	train_loss:1.8460662364959717	train_acc:0.30714285714285716	test_acc:0.435	test_f1:0.41037041739132246
epoch:6	train_loss:1.8043919801712036	train_acc:0.5238095238095238	test_acc:0.598	test_f1:0.5269336064723944
epoch:7	train_loss:1.7757221460342407	train_acc:0.6880952380952381	test_acc:0.598	test_f1:0.6012706931652287
epoch:8	train_loss:1.739404559135437	train_acc:0.7761904761904762	test_acc:0.631	test_f1:0.6491766805922927
epoch:9	train_loss:1.700361967086792	train_acc:0.7785714285714286	test_acc:0.675	test_f1:0.6847607744142163
epoch:10	train_loss:1.664244294166565	train_acc:0.7761904761904762	test_acc:0.683	test_f1:0.6869445067653247
epoch:11	train_loss:1.620808720588684	train_acc:0.7952380952380952	test_acc:0.695	test_f1:0.7021955093113819
epoch:12	train_loss:1.582261562347412	train_acc:0.8142857142857143	test_acc:0.737	test_f1:0.7423150395017609
epoch:13	train_loss:1.5312334299087524	train_acc:0.8404761904761905	test_acc:0.785	test_f1:0.7823649943335153
epoch:14	train_loss:1.479830265045166	train_acc:0.8857142857142857	test_acc:0.795	test_f1:0.7874830172669156
epoch:15	train_loss:1.4330213069915771	train_acc:0.8833333333333333	test_acc:0.781	test_f1:0.7633485786753565
epoch:16	train_loss:1.3740211725234985	train_acc:0.8785714285714286	test_acc:0.779	test_f1:0.7602806110433873
epoch:17	train_loss:1.3229470252990723	train_acc:0.8785714285714286	test_acc:0.784	test_f1:0.7640135943566494
epoch:18	train_loss:1.264075756072998	train_acc:0.8785714285714286	test_acc:0.791	test_f1:0.7724952795508461
epoch:19	train_loss:1.2023522853851318	train_acc:0.8714285714285714	test_acc:0.794	test_f1:0.7778637310359023
epoch:20	train_loss:1.1382585763931274	train_acc:0.8833333333333333	test_acc:0.798	test_f1:0.7836652770230187
epoch:21	train_loss:1.0810637474060059	train_acc:0.8928571428571429	test_acc:0.803	test_f1:0.7971817530341899
epoch:22	train_loss:1.0233442783355713	train_acc:0.8976190476190476	test_acc:0.803	test_f1:0.7975997767650371
epoch:23	train_loss:0.9589197635650635	train_acc:0.8904761904761904	test_acc:0.798	test_f1:0.7937493444011585
epoch:24	train_loss:0.9023816585540771	train_acc:0.9	test_acc:0.797	test_f1:0.7928598836881214
epoch:25	train_loss:0.841417133808136	train_acc:0.8952380952380953	test_acc:0.798	test_f1:0.7941052764658963
epoch:26	train_loss:0.7905949354171753	train_acc:0.9023809523809524	test_acc:0.805	test_f1:0.7992674487010343
epoch:27	train_loss:0.7349824905395508	train_acc:0.8976190476190476	test_acc:0.803	test_f1:0.7953489820484372
epoch:28	train_loss:0.6878330111503601	train_acc:0.9023809523809524	test_acc:0.811	test_f1:0.8009535679896899
epoch:29	train_loss:0.6384174227714539	train_acc:0.9095238095238095	test_acc:0.815	test_f1:0.8059292190252894
epoch:30	train_loss:0.5980290770530701	train_acc:0.9095238095238095	test_acc:0.817	test_f1:0.8095086137625274
epoch:31	train_loss:0.5595913529396057	train_acc:0.9214285714285714	test_acc:0.821	test_f1:0.8140974435888113
epoch:32	train_loss:0.5208884477615356	train_acc:0.9261904761904762	test_acc:0.815	test_f1:0.8083044902482313
epoch:33	train_loss:0.4845900535583496	train_acc:0.919047619047619	test_acc:0.813	test_f1:0.8071485848355069
epoch:34	train_loss:0.4550389349460602	train_acc:0.9214285714285714	test_acc:0.818	test_f1:0.8129492439662268
epoch:35	train_loss:0.4262363314628601	train_acc:0.9214285714285714	test_acc:0.82	test_f1:0.8153939169569245
epoch:36	train_loss:0.39495736360549927	train_acc:0.9285714285714286	test_acc:0.823	test_f1:0.8191697444849926
epoch:37	train_loss:0.3712475895881653	train_acc:0.9404761904761905	test_acc:0.825	test_f1:0.8200619225894722
epoch:38	train_loss:0.3527131974697113	train_acc:0.9380952380952381	test_acc:0.824	test_f1:0.8175647262470764
epoch:39	train_loss:0.32305780053138733	train_acc:0.9452380952380952	test_acc:0.83	test_f1:0.8225372351894947
epoch:40	train_loss:0.3087707459926605	train_acc:0.9476190476190476	test_acc:0.83	test_f1:0.8222604598923152
epoch:41	train_loss:0.28826794028282166	train_acc:0.9547619047619048	test_acc:0.829	test_f1:0.8209799327417517
epoch:42	train_loss:0.27411025762557983	train_acc:0.9452380952380952	test_acc:0.833	test_f1:0.8253046043953532
epoch:43	train_loss:0.2528231739997864	train_acc:0.9571428571428572	test_acc:0.832	test_f1:0.8246487534740982
epoch:44	train_loss:0.2468489706516266	train_acc:0.9523809523809523	test_acc:0.834	test_f1:0.8261668845232404
epoch:45	train_loss:0.22601480782032013	train_acc:0.9642857142857143	test_acc:0.833	test_f1:0.8247879345103752
epoch:46	train_loss:0.2195037603378296	train_acc:0.9595238095238096	test_acc:0.833	test_f1:0.8253568237991392
epoch:47	train_loss:0.21049542725086212	train_acc:0.969047619047619	test_acc:0.831	test_f1:0.8237630081337831
epoch:48	train_loss:0.19766657054424286	train_acc:0.969047619047619	test_acc:0.833	test_f1:0.8251978088998354
epoch:49	train_loss:0.18684183061122894	train_acc:0.9785714285714285	test_acc:0.834	test_f1:0.8265222424967061
epoch:50	train_loss:0.17909979820251465	train_acc:0.9785714285714285	test_acc:0.835	test_f1:0.8273326953333949
训练并测试结束，共训练50轮，总用时228.8734793663025s
最佳正确率为:0.835,对应的macro_f1为:0.8273326953333949,对应的训练轮次为:50



2022-07-01 21:25:33.843761
epoch:1	train_loss:1.834807276725769	train_acc:0.16666666666666666	test_acc:0.171	test_f1:0.051561697710321513
epoch:2	train_loss:1.7752649784088135	train_acc:0.19166666666666668	test_acc:0.16	test_f1:0.04597701149425288
epoch:3	train_loss:1.764195203781128	train_acc:0.16666666666666666	test_acc:0.16	test_f1:0.04597701149425288
epoch:4	train_loss:1.740102767944336	train_acc:0.16666666666666666	test_acc:0.176	test_f1:0.09033284280809033
epoch:5	train_loss:1.713438868522644	train_acc:0.3333333333333333	test_acc:0.266	test_f1:0.23910095413996593
epoch:6	train_loss:1.6714824438095093	train_acc:0.65	test_acc:0.259	test_f1:0.1892292032136911
epoch:7	train_loss:1.6636674404144287	train_acc:0.6583333333333333	test_acc:0.19	test_f1:0.0694734586611754
epoch:8	train_loss:1.6424075365066528	train_acc:0.4083333333333333	test_acc:0.204	test_f1:0.096188988730061
epoch:9	train_loss:1.60627019405365	train_acc:0.55	test_acc:0.352	test_f1:0.28852994088673084
epoch:10	train_loss:1.5779316425323486	train_acc:0.7	test_acc:0.66	test_f1:0.5999948805932747
epoch:11	train_loss:1.5393239259719849	train_acc:0.9	test_acc:0.683	test_f1:0.6315683645637654
epoch:12	train_loss:1.4991540908813477	train_acc:0.95	test_acc:0.579	test_f1:0.5519990375524806
epoch:13	train_loss:1.4711261987686157	train_acc:0.925	test_acc:0.503	test_f1:0.4810975841950842
epoch:14	train_loss:1.4279260635375977	train_acc:0.9333333333333333	test_acc:0.515	test_f1:0.49149810224005747
epoch:15	train_loss:1.3979222774505615	train_acc:0.925	test_acc:0.595	test_f1:0.5677581716075545
epoch:16	train_loss:1.3460533618927002	train_acc:0.9416666666666667	test_acc:0.66	test_f1:0.6286932620012536
epoch:17	train_loss:1.297616958618164	train_acc:0.95	test_acc:0.686	test_f1:0.6518608817802182
epoch:18	train_loss:1.2439258098602295	train_acc:0.9416666666666667	test_acc:0.687	test_f1:0.6493631685005417
epoch:19	train_loss:1.192365050315857	train_acc:0.9583333333333334	test_acc:0.687	test_f1:0.6440805683906433
epoch:20	train_loss:1.150162696838379	train_acc:0.95	test_acc:0.69	test_f1:0.6457460486302192
epoch:21	train_loss:1.096086859703064	train_acc:0.9416666666666667	test_acc:0.707	test_f1:0.6612079796274003
epoch:22	train_loss:1.0285402536392212	train_acc:0.95	test_acc:0.706	test_f1:0.6654915039528687
epoch:23	train_loss:0.9678367972373962	train_acc:0.9666666666666667	test_acc:0.702	test_f1:0.6629427360994243
epoch:24	train_loss:0.916918933391571	train_acc:0.95	test_acc:0.694	test_f1:0.6579709920258024
epoch:25	train_loss:0.8681241273880005	train_acc:0.95	test_acc:0.684	test_f1:0.6512826589227765
epoch:26	train_loss:0.8076298832893372	train_acc:0.9583333333333334	test_acc:0.688	test_f1:0.6571638457502421
epoch:27	train_loss:0.749835729598999	train_acc:0.9666666666666667	test_acc:0.69	test_f1:0.6559333672634409
epoch:28	train_loss:0.6944756507873535	train_acc:0.95	test_acc:0.693	test_f1:0.6557756945609645
epoch:29	train_loss:0.6410230398178101	train_acc:0.9416666666666667	test_acc:0.697	test_f1:0.6563466298414223
epoch:30	train_loss:0.5908430218696594	train_acc:0.95	test_acc:0.703	test_f1:0.6622359734483337
epoch:31	train_loss:0.5467589497566223	train_acc:0.95	test_acc:0.696	test_f1:0.6571102400434657
epoch:32	train_loss:0.5107874274253845	train_acc:0.9583333333333334	test_acc:0.698	test_f1:0.6610925351458795
epoch:33	train_loss:0.4571349024772644	train_acc:0.9666666666666667	test_acc:0.697	test_f1:0.6632915701158528
epoch:34	train_loss:0.4284610152244568	train_acc:0.975	test_acc:0.696	test_f1:0.6647506116915467
epoch:35	train_loss:0.3895096480846405	train_acc:0.9833333333333333	test_acc:0.692	test_f1:0.6597664104671052
epoch:36	train_loss:0.35462698340415955	train_acc:0.975	test_acc:0.694	test_f1:0.6610561186651632
epoch:37	train_loss:0.32466766238212585	train_acc:0.9666666666666667	test_acc:0.699	test_f1:0.6672968908097809
epoch:38	train_loss:0.3028826415538788	train_acc:0.9833333333333333	test_acc:0.695	test_f1:0.6662852870944781
epoch:39	train_loss:0.27001914381980896	train_acc:0.9833333333333333	test_acc:0.69	test_f1:0.6611028280578674
epoch:40	train_loss:0.2510806620121002	train_acc:0.9833333333333333	test_acc:0.688	test_f1:0.6571845831077187
epoch:41	train_loss:0.22757574915885925	train_acc:0.9833333333333333	test_acc:0.685	test_f1:0.6521481693157768
epoch:42	train_loss:0.21498188376426697	train_acc:0.9916666666666667	test_acc:0.689	test_f1:0.65533033660327
epoch:43	train_loss:0.19532576203346252	train_acc:0.9916666666666667	test_acc:0.69	test_f1:0.6569287877203396
epoch:44	train_loss:0.1850283145904541	train_acc:0.9916666666666667	test_acc:0.694	test_f1:0.662076113263077
epoch:45	train_loss:0.17262764275074005	train_acc:0.9916666666666667	test_acc:0.694	test_f1:0.6643506988619712
epoch:46	train_loss:0.16207976639270782	train_acc:1.0	test_acc:0.682	test_f1:0.6556750364385284
epoch:47	train_loss:0.1508413702249527	train_acc:0.9916666666666667	test_acc:0.674	test_f1:0.649322197801512
epoch:48	train_loss:0.14570219814777374	train_acc:1.0	test_acc:0.675	test_f1:0.6504685169058865
epoch:49	train_loss:0.13537609577178955	train_acc:1.0	test_acc:0.679	test_f1:0.6531419874695069
epoch:50	train_loss:0.13238182663917542	train_acc:1.0	test_acc:0.685	test_f1:0.6562461215455188
训练并测试结束，共训练50轮，总用时402.772629737854s
最佳正确率为:0.707,对应的macro_f1为:0.6612079796274003,对应的训练轮次为:21



2022-07-01 21:32:54.387041
epoch:1	train_loss:1.875751256942749	train_acc:0.16666666666666666	test_acc:0.233	test_f1:0.07080307184198291
epoch:2	train_loss:1.778887391090393	train_acc:0.20833333333333334	test_acc:0.181	test_f1:0.05108664973186564
epoch:3	train_loss:1.7729707956314087	train_acc:0.225	test_acc:0.39	test_f1:0.2773826875994059
epoch:4	train_loss:1.770495057106018	train_acc:0.425	test_acc:0.321	test_f1:0.23746458875249954
epoch:5	train_loss:1.748840093612671	train_acc:0.4166666666666667	test_acc:0.416	test_f1:0.2900968992678364
epoch:6	train_loss:1.7072066068649292	train_acc:0.49166666666666664	test_acc:0.415	test_f1:0.30854051092915524
epoch:7	train_loss:1.6742939949035645	train_acc:0.5666666666666667	test_acc:0.57	test_f1:0.4794928679567088
epoch:8	train_loss:1.6399288177490234	train_acc:0.7833333333333333	test_acc:0.286	test_f1:0.2439466152410347
epoch:9	train_loss:1.62676203250885	train_acc:0.7166666666666667	test_acc:0.13	test_f1:0.09296216525914025
epoch:10	train_loss:1.5979681015014648	train_acc:0.49166666666666664	test_acc:0.115	test_f1:0.07495603887048045
epoch:11	train_loss:1.5760254859924316	train_acc:0.4	test_acc:0.148	test_f1:0.12149996332319486
epoch:12	train_loss:1.5458991527557373	train_acc:0.5833333333333334	test_acc:0.356	test_f1:0.34629853512434217
epoch:13	train_loss:1.5032566785812378	train_acc:0.775	test_acc:0.562	test_f1:0.5274697773297751
epoch:14	train_loss:1.469802975654602	train_acc:0.9	test_acc:0.648	test_f1:0.6076333058582339
epoch:15	train_loss:1.4313991069793701	train_acc:0.95	test_acc:0.675	test_f1:0.6237990172161557
epoch:16	train_loss:1.3923252820968628	train_acc:0.9333333333333333	test_acc:0.684	test_f1:0.6204228939716524
epoch:17	train_loss:1.353879690170288	train_acc:0.9333333333333333	test_acc:0.669	test_f1:0.5988704319259966
epoch:18	train_loss:1.2966468334197998	train_acc:0.9083333333333333	test_acc:0.675	test_f1:0.6139303861018738
epoch:19	train_loss:1.2585994005203247	train_acc:0.9166666666666666	test_acc:0.677	test_f1:0.628832597675331
epoch:20	train_loss:1.2062705755233765	train_acc:0.9416666666666667	test_acc:0.698	test_f1:0.6465638097125004
epoch:21	train_loss:1.156499981880188	train_acc:0.9416666666666667	test_acc:0.708	test_f1:0.6662012074760998
epoch:22	train_loss:1.100372552871704	train_acc:0.9583333333333334	test_acc:0.682	test_f1:0.6499009332307453
epoch:23	train_loss:1.0521855354309082	train_acc:0.9416666666666667	test_acc:0.66	test_f1:0.636429845915565
epoch:24	train_loss:0.9969712495803833	train_acc:0.95	test_acc:0.65	test_f1:0.6289963020942858
epoch:25	train_loss:0.9446523189544678	train_acc:0.9583333333333334	test_acc:0.647	test_f1:0.6235784179984442
epoch:26	train_loss:0.8795502185821533	train_acc:0.9583333333333334	test_acc:0.66	test_f1:0.6332318410808869
epoch:27	train_loss:0.8293076753616333	train_acc:0.9583333333333334	test_acc:0.674	test_f1:0.6425717851791858
epoch:28	train_loss:0.7684012055397034	train_acc:0.9583333333333334	test_acc:0.693	test_f1:0.6592354437323928
epoch:29	train_loss:0.723127007484436	train_acc:0.9583333333333334	test_acc:0.703	test_f1:0.661600848016549
epoch:30	train_loss:0.6813969612121582	train_acc:0.9583333333333334	test_acc:0.707	test_f1:0.6631646353827242
epoch:31	train_loss:0.6196674704551697	train_acc:0.9416666666666667	test_acc:0.704	test_f1:0.6609669143945622
epoch:32	train_loss:0.5835533738136292	train_acc:0.95	test_acc:0.703	test_f1:0.6624727958490626
epoch:33	train_loss:0.5311166048049927	train_acc:0.9583333333333334	test_acc:0.704	test_f1:0.6675696653524591
epoch:34	train_loss:0.4989885091781616	train_acc:0.9583333333333334	test_acc:0.695	test_f1:0.6630172273559248
epoch:35	train_loss:0.45715418457984924	train_acc:0.9666666666666667	test_acc:0.687	test_f1:0.6581446236464296
epoch:36	train_loss:0.41690000891685486	train_acc:0.9583333333333334	test_acc:0.675	test_f1:0.6476648776288002
epoch:37	train_loss:0.38123512268066406	train_acc:0.9666666666666667	test_acc:0.678	test_f1:0.6512124312285755
epoch:38	train_loss:0.3530922830104828	train_acc:0.975	test_acc:0.68	test_f1:0.6529885162273485
epoch:39	train_loss:0.3191273808479309	train_acc:0.9833333333333333	test_acc:0.681	test_f1:0.6543596986351304
epoch:40	train_loss:0.29853612184524536	train_acc:0.975	test_acc:0.685	test_f1:0.6567842146201336
epoch:41	train_loss:0.2735806703567505	train_acc:0.975	test_acc:0.69	test_f1:0.6611911691614094
epoch:42	train_loss:0.2558918595314026	train_acc:0.9833333333333333	test_acc:0.697	test_f1:0.6655694531248872
epoch:43	train_loss:0.2317713052034378	train_acc:0.9916666666666667	test_acc:0.693	test_f1:0.662177174919251
epoch:44	train_loss:0.21778282523155212	train_acc:0.9833333333333333	test_acc:0.688	test_f1:0.6597479068914825
epoch:45	train_loss:0.20740270614624023	train_acc:0.975	test_acc:0.681	test_f1:0.653569454229057
epoch:46	train_loss:0.1879342645406723	train_acc:0.9916666666666667	test_acc:0.68	test_f1:0.65294511982076
epoch:47	train_loss:0.17549706995487213	train_acc:0.9916666666666667	test_acc:0.677	test_f1:0.6511999041948379
epoch:48	train_loss:0.16447298228740692	train_acc:0.9916666666666667	test_acc:0.675	test_f1:0.6490626292364537
epoch:49	train_loss:0.16012908518314362	train_acc:0.9916666666666667	test_acc:0.678	test_f1:0.6515034877215743
epoch:50	train_loss:0.15269169211387634	train_acc:1.0	test_acc:0.682	test_f1:0.6547110340881553
训练并测试结束，共训练50轮，总用时404.2077624797821s
最佳正确率为:0.708,对应的macro_f1为:0.6662012074760998,对应的训练轮次为:21



2022-07-01 21:39:56.140437
epoch:1	train_loss:1.8116928339004517	train_acc:0.175	test_acc:0.169	test_f1:0.04818933561448532
epoch:2	train_loss:1.777665376663208	train_acc:0.25	test_acc:0.169	test_f1:0.04818933561448532
epoch:3	train_loss:1.7565135955810547	train_acc:0.21666666666666667	test_acc:0.353	test_f1:0.17941979959881046
epoch:4	train_loss:1.7323496341705322	train_acc:0.35	test_acc:0.292	test_f1:0.16011552903644924
epoch:5	train_loss:1.7036539316177368	train_acc:0.5083333333333333	test_acc:0.227	test_f1:0.13799244034795274
epoch:6	train_loss:1.6906514167785645	train_acc:0.475	test_acc:0.271	test_f1:0.18019763810781667
epoch:7	train_loss:1.6614962816238403	train_acc:0.4583333333333333	test_acc:0.248	test_f1:0.1850131349555868
epoch:8	train_loss:1.6420456171035767	train_acc:0.5583333333333333	test_acc:0.44	test_f1:0.39845744963975843
epoch:9	train_loss:1.6200546026229858	train_acc:0.8083333333333333	test_acc:0.473	test_f1:0.4364464710034703
epoch:10	train_loss:1.5818469524383545	train_acc:0.85	test_acc:0.578	test_f1:0.504005242804246
epoch:11	train_loss:1.5544565916061401	train_acc:0.8583333333333333	test_acc:0.606	test_f1:0.519675371264026
epoch:12	train_loss:1.5189989805221558	train_acc:0.8083333333333333	test_acc:0.579	test_f1:0.49989838397516184
epoch:13	train_loss:1.4768238067626953	train_acc:0.85	test_acc:0.596	test_f1:0.5274410323039418
epoch:14	train_loss:1.4402544498443604	train_acc:0.8916666666666667	test_acc:0.659	test_f1:0.6077707357435925
epoch:15	train_loss:1.3970845937728882	train_acc:0.8833333333333333	test_acc:0.702	test_f1:0.6621196016873053
epoch:16	train_loss:1.3563185930252075	train_acc:0.9416666666666667	test_acc:0.691	test_f1:0.661000911667831
epoch:17	train_loss:1.3069795370101929	train_acc:0.9583333333333334	test_acc:0.646	test_f1:0.6201025797623065
epoch:18	train_loss:1.2698756456375122	train_acc:0.9416666666666667	test_acc:0.636	test_f1:0.6090468458570092
epoch:19	train_loss:1.2131091356277466	train_acc:0.9416666666666667	test_acc:0.672	test_f1:0.6334619494581877
epoch:20	train_loss:1.1681534051895142	train_acc:0.9333333333333333	test_acc:0.695	test_f1:0.6499162054800084
epoch:21	train_loss:1.1022148132324219	train_acc:0.9416666666666667	test_acc:0.709	test_f1:0.662440039105992
epoch:22	train_loss:1.0547724962234497	train_acc:0.9416666666666667	test_acc:0.703	test_f1:0.6558216787843418
epoch:23	train_loss:0.9995579123497009	train_acc:0.9416666666666667	test_acc:0.705	test_f1:0.661782989130182
epoch:24	train_loss:0.9475298523902893	train_acc:0.9333333333333333	test_acc:0.709	test_f1:0.6691716303922605
epoch:25	train_loss:0.8886763453483582	train_acc:0.95	test_acc:0.705	test_f1:0.673962006128802
epoch:26	train_loss:0.8280208110809326	train_acc:0.9666666666666667	test_acc:0.696	test_f1:0.6670792258009488
epoch:27	train_loss:0.7723470330238342	train_acc:0.9416666666666667	test_acc:0.689	test_f1:0.6595086263555654
epoch:28	train_loss:0.7195306420326233	train_acc:0.9583333333333334	test_acc:0.69	test_f1:0.6582849039864729
epoch:29	train_loss:0.6730753183364868	train_acc:0.9416666666666667	test_acc:0.693	test_f1:0.659944516597052
epoch:30	train_loss:0.6221012473106384	train_acc:0.95	test_acc:0.698	test_f1:0.6651925917876277
epoch:31	train_loss:0.5778659582138062	train_acc:0.9583333333333334	test_acc:0.702	test_f1:0.6703269965547983
epoch:32	train_loss:0.5303929448127747	train_acc:0.95	test_acc:0.701	test_f1:0.673684151733913
epoch:33	train_loss:0.4865517020225525	train_acc:0.975	test_acc:0.696	test_f1:0.6683651832110136
epoch:34	train_loss:0.4391237795352936	train_acc:0.975	test_acc:0.696	test_f1:0.666798734582846
epoch:35	train_loss:0.40560054779052734	train_acc:0.9583333333333334	test_acc:0.695	test_f1:0.6637379221650321
epoch:36	train_loss:0.37991422414779663	train_acc:0.975	test_acc:0.692	test_f1:0.6605756088516718
epoch:37	train_loss:0.339542418718338	train_acc:0.975	test_acc:0.691	test_f1:0.6616154468548958
epoch:38	train_loss:0.32071641087532043	train_acc:0.975	test_acc:0.693	test_f1:0.6678662256341973
epoch:39	train_loss:0.29316219687461853	train_acc:0.9833333333333333	test_acc:0.689	test_f1:0.6644210483313849
epoch:40	train_loss:0.27031227946281433	train_acc:0.9916666666666667	test_acc:0.681	test_f1:0.6575800115044301
epoch:41	train_loss:0.2534453272819519	train_acc:0.9916666666666667	test_acc:0.684	test_f1:0.6597893003643825
epoch:42	train_loss:0.22968260943889618	train_acc:0.9833333333333333	test_acc:0.695	test_f1:0.668026751706182
epoch:43	train_loss:0.21514521539211273	train_acc:0.9916666666666667	test_acc:0.694	test_f1:0.6654810878592061
epoch:44	train_loss:0.19774052500724792	train_acc:0.9916666666666667	test_acc:0.688	test_f1:0.6565689997100796
epoch:45	train_loss:0.18375277519226074	train_acc:0.9916666666666667	test_acc:0.687	test_f1:0.6559919368524995
epoch:46	train_loss:0.1656000018119812	train_acc:0.9916666666666667	test_acc:0.688	test_f1:0.6585667178138533
epoch:47	train_loss:0.1637469083070755	train_acc:1.0	test_acc:0.689	test_f1:0.662060881494044
epoch:48	train_loss:0.15094150602817535	train_acc:0.9916666666666667	test_acc:0.684	test_f1:0.6584675444636835
epoch:49	train_loss:0.14347030222415924	train_acc:0.9916666666666667	test_acc:0.687	test_f1:0.6600823384650978
epoch:50	train_loss:0.1321297585964203	train_acc:1.0	test_acc:0.693	test_f1:0.664935563340232
训练并测试结束，共训练50轮，总用时398.8653676509857s
最佳正确率为:0.709,对应的macro_f1为:0.6691716303922605,对应的训练轮次为:24



2022-07-01 21:47:02.257975
epoch:1	train_loss:1.8426926136016846	train_acc:0.16666666666666666	test_acc:0.207	test_f1:0.10367348039048445
epoch:2	train_loss:1.7851086854934692	train_acc:0.225	test_acc:0.181	test_f1:0.05108664973186564
epoch:3	train_loss:1.7742271423339844	train_acc:0.22083333333333333	test_acc:0.181	test_f1:0.05108664973186564
epoch:4	train_loss:1.7703685760498047	train_acc:0.16666666666666666	test_acc:0.181	test_f1:0.05108664973186564
epoch:5	train_loss:1.7368810176849365	train_acc:0.16666666666666666	test_acc:0.302	test_f1:0.18838224888233265
epoch:6	train_loss:1.713362693786621	train_acc:0.36666666666666664	test_acc:0.538	test_f1:0.5079000828779068
epoch:7	train_loss:1.6906541585922241	train_acc:0.6708333333333333	test_acc:0.265	test_f1:0.2862513124092185
epoch:8	train_loss:1.672019600868225	train_acc:0.5333333333333333	test_acc:0.154	test_f1:0.14725107658580913
epoch:9	train_loss:1.6594643592834473	train_acc:0.4041666666666667	test_acc:0.235	test_f1:0.24364023330875847
epoch:10	train_loss:1.6360762119293213	train_acc:0.5791666666666667	test_acc:0.373	test_f1:0.35547828923840474
epoch:11	train_loss:1.6110990047454834	train_acc:0.6291666666666667	test_acc:0.555	test_f1:0.49895403674842287
epoch:12	train_loss:1.5814480781555176	train_acc:0.8125	test_acc:0.717	test_f1:0.6687597545667656
epoch:13	train_loss:1.5532655715942383	train_acc:0.8833333333333333	test_acc:0.72	test_f1:0.6649948236553367
epoch:14	train_loss:1.5230154991149902	train_acc:0.8625	test_acc:0.606	test_f1:0.5469315786473282
epoch:15	train_loss:1.4945577383041382	train_acc:0.8041666666666667	test_acc:0.568	test_f1:0.5020472801294731
epoch:16	train_loss:1.4594589471817017	train_acc:0.7875	test_acc:0.615	test_f1:0.553022657289596
epoch:17	train_loss:1.420447587966919	train_acc:0.825	test_acc:0.69	test_f1:0.6293184809150049
epoch:18	train_loss:1.3882038593292236	train_acc:0.8666666666666667	test_acc:0.719	test_f1:0.6710868398869261
epoch:19	train_loss:1.3396456241607666	train_acc:0.9	test_acc:0.721	test_f1:0.6805730633049828
epoch:20	train_loss:1.2962044477462769	train_acc:0.9	test_acc:0.71	test_f1:0.6779053244846578
epoch:21	train_loss:1.2590006589889526	train_acc:0.9	test_acc:0.697	test_f1:0.6671169562250557
epoch:22	train_loss:1.2123323678970337	train_acc:0.9166666666666666	test_acc:0.705	test_f1:0.6712633904653931
epoch:23	train_loss:1.1614575386047363	train_acc:0.9041666666666667	test_acc:0.714	test_f1:0.6770885152327742
epoch:24	train_loss:1.1169606447219849	train_acc:0.9083333333333333	test_acc:0.718	test_f1:0.6795392744957708
epoch:25	train_loss:1.0568288564682007	train_acc:0.9125	test_acc:0.73	test_f1:0.687982392039561
epoch:26	train_loss:1.0120364427566528	train_acc:0.9166666666666666	test_acc:0.733	test_f1:0.688798090050739
epoch:27	train_loss:0.9622005224227905	train_acc:0.9083333333333333	test_acc:0.73	test_f1:0.6859795815943827
epoch:28	train_loss:0.9178500771522522	train_acc:0.9166666666666666	test_acc:0.732	test_f1:0.6879360972314484
epoch:29	train_loss:0.8587141633033752	train_acc:0.9125	test_acc:0.729	test_f1:0.686613163621777
epoch:30	train_loss:0.8143484592437744	train_acc:0.9208333333333333	test_acc:0.718	test_f1:0.6780658913190859
epoch:31	train_loss:0.7631373405456543	train_acc:0.9166666666666666	test_acc:0.72	test_f1:0.6824894132560494
epoch:32	train_loss:0.7201805114746094	train_acc:0.925	test_acc:0.718	test_f1:0.6809318651041361
epoch:33	train_loss:0.6676568984985352	train_acc:0.9208333333333333	test_acc:0.719	test_f1:0.6829590007306957
epoch:34	train_loss:0.6264890432357788	train_acc:0.9166666666666666	test_acc:0.72	test_f1:0.6830050936700504
epoch:35	train_loss:0.5896114706993103	train_acc:0.925	test_acc:0.722	test_f1:0.685069500415672
epoch:36	train_loss:0.548095703125	train_acc:0.9208333333333333	test_acc:0.713	test_f1:0.6728180774272757
epoch:37	train_loss:0.5096216797828674	train_acc:0.9291666666666667	test_acc:0.715	test_f1:0.6748261609280459
epoch:38	train_loss:0.47980067133903503	train_acc:0.925	test_acc:0.716	test_f1:0.6772047636917834
epoch:39	train_loss:0.4556971490383148	train_acc:0.9333333333333333	test_acc:0.716	test_f1:0.6806564060427349
epoch:40	train_loss:0.4247897267341614	train_acc:0.9333333333333333	test_acc:0.717	test_f1:0.6846322342103862
epoch:41	train_loss:0.39517566561698914	train_acc:0.9375	test_acc:0.719	test_f1:0.6890275614064056
epoch:42	train_loss:0.3734586834907532	train_acc:0.9333333333333333	test_acc:0.718	test_f1:0.6881776554040986
epoch:43	train_loss:0.3557903468608856	train_acc:0.9375	test_acc:0.721	test_f1:0.6913638177011175
epoch:44	train_loss:0.32663872838020325	train_acc:0.9458333333333333	test_acc:0.719	test_f1:0.6880131248796563
epoch:45	train_loss:0.3144707977771759	train_acc:0.95	test_acc:0.715	test_f1:0.6817043657001741
epoch:46	train_loss:0.2962629199028015	train_acc:0.9416666666666667	test_acc:0.716	test_f1:0.6826413920910938
epoch:47	train_loss:0.28283873200416565	train_acc:0.95	test_acc:0.718	test_f1:0.6850514843075222
epoch:48	train_loss:0.27010878920555115	train_acc:0.9458333333333333	test_acc:0.723	test_f1:0.6926811368988899
epoch:49	train_loss:0.25996801257133484	train_acc:0.9458333333333333	test_acc:0.722	test_f1:0.692651590018901
epoch:50	train_loss:0.2474028468132019	train_acc:0.9458333333333333	test_acc:0.716	test_f1:0.6830699446444353
训练并测试结束，共训练50轮，总用时401.42521834373474s
最佳正确率为:0.733,对应的macro_f1为:0.688798090050739,对应的训练轮次为:26



2022-07-01 21:53:59.450352
epoch:1	train_loss:1.9418559074401855	train_acc:0.17083333333333334	test_acc:0.181	test_f1:0.05108664973186564
epoch:2	train_loss:1.8010958433151245	train_acc:0.2125	test_acc:0.077	test_f1:0.023831631073970908
epoch:3	train_loss:1.7718302011489868	train_acc:0.2	test_acc:0.162	test_f1:0.05449523767881478
epoch:4	train_loss:1.7848756313323975	train_acc:0.21666666666666667	test_acc:0.16	test_f1:0.04597701149425288
epoch:5	train_loss:1.7739017009735107	train_acc:0.17083333333333334	test_acc:0.162	test_f1:0.05449523767881478
epoch:6	train_loss:1.7372081279754639	train_acc:0.1875	test_acc:0.166	test_f1:0.06757815018021553
epoch:7	train_loss:1.6976968050003052	train_acc:0.275	test_acc:0.404	test_f1:0.34112037163577164
epoch:8	train_loss:1.678301453590393	train_acc:0.5958333333333333	test_acc:0.376	test_f1:0.3077262257008584
epoch:9	train_loss:1.6604984998703003	train_acc:0.5125	test_acc:0.479	test_f1:0.3490342357724166
epoch:10	train_loss:1.6435054540634155	train_acc:0.55	test_acc:0.443	test_f1:0.3352164354879072
epoch:11	train_loss:1.6313377618789673	train_acc:0.525	test_acc:0.44	test_f1:0.3339628907581109
epoch:12	train_loss:1.605552077293396	train_acc:0.5833333333333334	test_acc:0.489	test_f1:0.38580061864066667
epoch:13	train_loss:1.575096845626831	train_acc:0.6458333333333334	test_acc:0.638	test_f1:0.5751827563467378
epoch:14	train_loss:1.5412676334381104	train_acc:0.8041666666666667	test_acc:0.674	test_f1:0.6308100896534679
epoch:15	train_loss:1.5118364095687866	train_acc:0.8791666666666667	test_acc:0.603	test_f1:0.5654777081593841
epoch:16	train_loss:1.4780954122543335	train_acc:0.8333333333333334	test_acc:0.494	test_f1:0.4574481835617215
epoch:17	train_loss:1.451444387435913	train_acc:0.8	test_acc:0.464	test_f1:0.4308568065180654
epoch:18	train_loss:1.422013521194458	train_acc:0.8041666666666667	test_acc:0.508	test_f1:0.47540857490410665
epoch:19	train_loss:1.3872781991958618	train_acc:0.8333333333333334	test_acc:0.621	test_f1:0.5916588819195364
epoch:20	train_loss:1.3499559164047241	train_acc:0.875	test_acc:0.707	test_f1:0.6685657683705385
epoch:21	train_loss:1.2970470190048218	train_acc:0.9083333333333333	test_acc:0.736	test_f1:0.6820004578935032
epoch:22	train_loss:1.2628086805343628	train_acc:0.9125	test_acc:0.735	test_f1:0.6821606648778039
epoch:23	train_loss:1.2199628353118896	train_acc:0.9041666666666667	test_acc:0.738	test_f1:0.6841568575310711
epoch:24	train_loss:1.1836341619491577	train_acc:0.9125	test_acc:0.741	test_f1:0.6875709576774147
epoch:25	train_loss:1.131430745124817	train_acc:0.9041666666666667	test_acc:0.733	test_f1:0.6869530610238209
epoch:26	train_loss:1.0811002254486084	train_acc:0.9041666666666667	test_acc:0.721	test_f1:0.6837699500564564
epoch:27	train_loss:1.0389950275421143	train_acc:0.9041666666666667	test_acc:0.707	test_f1:0.6717774764655585
epoch:28	train_loss:0.9863409399986267	train_acc:0.9125	test_acc:0.699	test_f1:0.6655911654593495
epoch:29	train_loss:0.9365531802177429	train_acc:0.9166666666666666	test_acc:0.7	test_f1:0.6692234362541395
epoch:30	train_loss:0.886173665523529	train_acc:0.9125	test_acc:0.707	test_f1:0.6754134924478884
epoch:31	train_loss:0.8414604067802429	train_acc:0.9166666666666666	test_acc:0.719	test_f1:0.6860226694531248
epoch:32	train_loss:0.7927671670913696	train_acc:0.9208333333333333	test_acc:0.719	test_f1:0.6799387654416109
epoch:33	train_loss:0.7505232095718384	train_acc:0.9166666666666666	test_acc:0.729	test_f1:0.688583140144928
epoch:34	train_loss:0.70438152551651	train_acc:0.9291666666666667	test_acc:0.727	test_f1:0.6855273785673104
epoch:35	train_loss:0.6592445373535156	train_acc:0.925	test_acc:0.728	test_f1:0.6881989402389603
epoch:36	train_loss:0.6183487772941589	train_acc:0.925	test_acc:0.724	test_f1:0.6852682061525245
epoch:37	train_loss:0.5825926661491394	train_acc:0.9208333333333333	test_acc:0.723	test_f1:0.6883215092908127
epoch:38	train_loss:0.5426430106163025	train_acc:0.9291666666666667	test_acc:0.713	test_f1:0.6785888121605855
epoch:39	train_loss:0.5121300220489502	train_acc:0.925	test_acc:0.712	test_f1:0.6813670412388434
epoch:40	train_loss:0.4844193458557129	train_acc:0.9208333333333333	test_acc:0.717	test_f1:0.6852703730301944
epoch:41	train_loss:0.45261144638061523	train_acc:0.9333333333333333	test_acc:0.719	test_f1:0.6876712964101775
epoch:42	train_loss:0.4252576529979706	train_acc:0.9291666666666667	test_acc:0.721	test_f1:0.6859003339627815
epoch:43	train_loss:0.3966429531574249	train_acc:0.9333333333333333	test_acc:0.722	test_f1:0.6844289179539559
epoch:44	train_loss:0.3726983070373535	train_acc:0.9375	test_acc:0.722	test_f1:0.6859307361899895
epoch:45	train_loss:0.35137659311294556	train_acc:0.9375	test_acc:0.717	test_f1:0.6820588712101582
epoch:46	train_loss:0.33224302530288696	train_acc:0.9541666666666667	test_acc:0.721	test_f1:0.6914253930874755
epoch:47	train_loss:0.31561043858528137	train_acc:0.9458333333333333	test_acc:0.716	test_f1:0.6862841306552537
epoch:48	train_loss:0.2974241077899933	train_acc:0.9375	test_acc:0.712	test_f1:0.6848809850176597
epoch:49	train_loss:0.2812371551990509	train_acc:0.9458333333333333	test_acc:0.713	test_f1:0.6853202382736518
epoch:50	train_loss:0.2671550512313843	train_acc:0.95	test_acc:0.713	test_f1:0.6839853963678274
训练并测试结束，共训练50轮，总用时396.3245372772217s
最佳正确率为:0.741,对应的macro_f1为:0.6875709576774147,对应的训练轮次为:24



2022-07-01 22:01:03.736769
epoch:1	train_loss:1.8420041799545288	train_acc:0.16666666666666666	test_acc:0.077	test_f1:0.023831631073970908
epoch:2	train_loss:1.779356837272644	train_acc:0.20416666666666666	test_acc:0.294	test_f1:0.22369243396283242
epoch:3	train_loss:1.770564317703247	train_acc:0.2833333333333333	test_acc:0.309	test_f1:0.15251477940505723
epoch:4	train_loss:1.7662456035614014	train_acc:0.2791666666666667	test_acc:0.259	test_f1:0.14138015768450551
epoch:5	train_loss:1.7436515092849731	train_acc:0.29583333333333334	test_acc:0.345	test_f1:0.21703915569742185
epoch:6	train_loss:1.7143449783325195	train_acc:0.4125	test_acc:0.624	test_f1:0.5952429177400023
epoch:7	train_loss:1.6884489059448242	train_acc:0.7375	test_acc:0.435	test_f1:0.3081814726494253
epoch:8	train_loss:1.6785696744918823	train_acc:0.5625	test_acc:0.365	test_f1:0.24242415256080252
epoch:9	train_loss:1.655573844909668	train_acc:0.4708333333333333	test_acc:0.309	test_f1:0.1997274992604626
epoch:10	train_loss:1.6334885358810425	train_acc:0.4791666666666667	test_acc:0.353	test_f1:0.2791519758154966
epoch:11	train_loss:1.6085379123687744	train_acc:0.5916666666666667	test_acc:0.541	test_f1:0.4905085739137444
epoch:12	train_loss:1.5756555795669556	train_acc:0.7375	test_acc:0.672	test_f1:0.6189377642217807
epoch:13	train_loss:1.5444716215133667	train_acc:0.8791666666666667	test_acc:0.675	test_f1:0.6365273044857659
epoch:14	train_loss:1.5170241594314575	train_acc:0.8875	test_acc:0.61	test_f1:0.5706344874086993
epoch:15	train_loss:1.4919226169586182	train_acc:0.8625	test_acc:0.581	test_f1:0.5449448238752007
epoch:16	train_loss:1.4518722295761108	train_acc:0.8916666666666667	test_acc:0.599	test_f1:0.568621249910468
epoch:17	train_loss:1.4224215745925903	train_acc:0.8583333333333333	test_acc:0.657	test_f1:0.6234572300303948
epoch:18	train_loss:1.3786455392837524	train_acc:0.9041666666666667	test_acc:0.705	test_f1:0.6654832063886094
epoch:19	train_loss:1.3331223726272583	train_acc:0.925	test_acc:0.723	test_f1:0.6812378026813178
epoch:20	train_loss:1.2945128679275513	train_acc:0.9041666666666667	test_acc:0.711	test_f1:0.6685848630582023
epoch:21	train_loss:1.251889705657959	train_acc:0.9	test_acc:0.701	test_f1:0.6581176081349677
epoch:22	train_loss:1.2062642574310303	train_acc:0.9166666666666666	test_acc:0.703	test_f1:0.6626272091759766
epoch:23	train_loss:1.1563785076141357	train_acc:0.9083333333333333	test_acc:0.709	test_f1:0.6730326740912845
epoch:24	train_loss:1.1122839450836182	train_acc:0.9125	test_acc:0.709	test_f1:0.675486889507979
epoch:25	train_loss:1.064031958580017	train_acc:0.9208333333333333	test_acc:0.713	test_f1:0.6774408793608641
epoch:26	train_loss:1.0074243545532227	train_acc:0.9208333333333333	test_acc:0.717	test_f1:0.6789633048902276
epoch:27	train_loss:0.9571516513824463	train_acc:0.9291666666666667	test_acc:0.716	test_f1:0.6760877996241622
epoch:28	train_loss:0.9069383144378662	train_acc:0.9333333333333333	test_acc:0.717	test_f1:0.6747356945394815
epoch:29	train_loss:0.858127236366272	train_acc:0.9125	test_acc:0.719	test_f1:0.6752459850147022
epoch:30	train_loss:0.8045695424079895	train_acc:0.9166666666666666	test_acc:0.721	test_f1:0.6793433216600571
epoch:31	train_loss:0.7615529894828796	train_acc:0.9166666666666666	test_acc:0.717	test_f1:0.6774935906569929
epoch:32	train_loss:0.708756148815155	train_acc:0.9166666666666666	test_acc:0.715	test_f1:0.6805907543171706
epoch:33	train_loss:0.6654177308082581	train_acc:0.9333333333333333	test_acc:0.715	test_f1:0.6814070938771333
epoch:34	train_loss:0.6232734322547913	train_acc:0.9291666666666667	test_acc:0.716	test_f1:0.6808656640664154
epoch:35	train_loss:0.5906907320022583	train_acc:0.9166666666666666	test_acc:0.718	test_f1:0.6820096590135597
epoch:36	train_loss:0.5444381833076477	train_acc:0.9166666666666666	test_acc:0.718	test_f1:0.6805748482273102
epoch:37	train_loss:0.5114421248435974	train_acc:0.9375	test_acc:0.718	test_f1:0.6810591677072552
epoch:38	train_loss:0.47719115018844604	train_acc:0.925	test_acc:0.718	test_f1:0.6811263410037162
epoch:39	train_loss:0.44715186953544617	train_acc:0.9291666666666667	test_acc:0.719	test_f1:0.6841969697699906
epoch:40	train_loss:0.4207516014575958	train_acc:0.9208333333333333	test_acc:0.713	test_f1:0.6789515783636801
epoch:41	train_loss:0.3967352509498596	train_acc:0.9333333333333333	test_acc:0.715	test_f1:0.6804377209303715
epoch:42	train_loss:0.36717361211776733	train_acc:0.9458333333333333	test_acc:0.717	test_f1:0.6829395401099246
epoch:43	train_loss:0.3442974090576172	train_acc:0.9333333333333333	test_acc:0.717	test_f1:0.681799623473189
epoch:44	train_loss:0.32571443915367126	train_acc:0.9375	test_acc:0.718	test_f1:0.6827727292935343
epoch:45	train_loss:0.3088824450969696	train_acc:0.9458333333333333	test_acc:0.718	test_f1:0.68407940557824
epoch:46	train_loss:0.29606887698173523	train_acc:0.9375	test_acc:0.716	test_f1:0.6833181181830073
epoch:47	train_loss:0.28157147765159607	train_acc:0.95	test_acc:0.719	test_f1:0.6873369317351212
epoch:48	train_loss:0.2644648551940918	train_acc:0.9541666666666667	test_acc:0.717	test_f1:0.6857344253905429
epoch:49	train_loss:0.24647288024425507	train_acc:0.9625	test_acc:0.717	test_f1:0.6845834399180868
epoch:50	train_loss:0.24007852375507355	train_acc:0.9583333333333334	test_acc:0.715	test_f1:0.6829021308812583
训练并测试结束，共训练50轮，总用时391.81691098213196s
最佳正确率为:0.723,对应的macro_f1为:0.6812378026813178,对应的训练轮次为:19



2022-07-01 22:08:33.238681
epoch:1	train_loss:1.8285702466964722	train_acc:0.16666666666666666	test_acc:0.169	test_f1:0.04818933561448532
epoch:2	train_loss:1.781250238418579	train_acc:0.21944444444444444	test_acc:0.337	test_f1:0.16416040100250626
epoch:3	train_loss:1.787235140800476	train_acc:0.22777777777777777	test_acc:0.372	test_f1:0.20136064635624665
epoch:4	train_loss:1.76569664478302	train_acc:0.30277777777777776	test_acc:0.592	test_f1:0.46319926360695346
epoch:5	train_loss:1.7335971593856812	train_acc:0.4638888888888889	test_acc:0.545	test_f1:0.45663819290921087
epoch:6	train_loss:1.7180346250534058	train_acc:0.55	test_acc:0.108	test_f1:0.07632312441855152
epoch:7	train_loss:1.7065297365188599	train_acc:0.3388888888888889	test_acc:0.077	test_f1:0.023831631073970908
epoch:8	train_loss:1.6909422874450684	train_acc:0.21666666666666667	test_acc:0.08	test_f1:0.029867228728177552
epoch:9	train_loss:1.669791579246521	train_acc:0.2611111111111111	test_acc:0.23	test_f1:0.2495729367206192
epoch:10	train_loss:1.6433062553405762	train_acc:0.5055555555555555	test_acc:0.66	test_f1:0.6282411475313042
epoch:11	train_loss:1.6190264225006104	train_acc:0.7944444444444444	test_acc:0.711	test_f1:0.6409207282924386
epoch:12	train_loss:1.5941447019577026	train_acc:0.7972222222222223	test_acc:0.726	test_f1:0.6377085120330273
epoch:13	train_loss:1.572009563446045	train_acc:0.7527777777777778	test_acc:0.741	test_f1:0.6439181155903388
epoch:14	train_loss:1.5445111989974976	train_acc:0.7611111111111111	test_acc:0.743	test_f1:0.6505033002346451
epoch:15	train_loss:1.514175534248352	train_acc:0.7777777777777778	test_acc:0.736	test_f1:0.6486091885469839
epoch:16	train_loss:1.4805378913879395	train_acc:0.8083333333333333	test_acc:0.746	test_f1:0.6840835963769578
epoch:17	train_loss:1.4415154457092285	train_acc:0.8583333333333333	test_acc:0.74	test_f1:0.7050585677395023
epoch:18	train_loss:1.4058103561401367	train_acc:0.8916666666666667	test_acc:0.711	test_f1:0.6895799392261903
epoch:19	train_loss:1.368675947189331	train_acc:0.9055555555555556	test_acc:0.684	test_f1:0.6648673972021469
epoch:20	train_loss:1.3320385217666626	train_acc:0.8944444444444445	test_acc:0.694	test_f1:0.6688773242138609
epoch:21	train_loss:1.2916624546051025	train_acc:0.8916666666666667	test_acc:0.724	test_f1:0.6949627127622048
epoch:22	train_loss:1.2515636682510376	train_acc:0.8833333333333333	test_acc:0.741	test_f1:0.7059709331650167
epoch:23	train_loss:1.1943514347076416	train_acc:0.8861111111111111	test_acc:0.746	test_f1:0.6994634174854609
epoch:24	train_loss:1.153659462928772	train_acc:0.8777777777777778	test_acc:0.749	test_f1:0.6938227294563152
epoch:25	train_loss:1.1031690835952759	train_acc:0.8861111111111111	test_acc:0.749	test_f1:0.690397292702584
epoch:26	train_loss:1.0511448383331299	train_acc:0.8833333333333333	test_acc:0.747	test_f1:0.6886471793910548
epoch:27	train_loss:1.004732608795166	train_acc:0.8944444444444445	test_acc:0.749	test_f1:0.7018248525044571
epoch:28	train_loss:0.9560571908950806	train_acc:0.9	test_acc:0.745	test_f1:0.7050074591783022
epoch:29	train_loss:0.9115214347839355	train_acc:0.9055555555555556	test_acc:0.732	test_f1:0.7035315217582943
epoch:30	train_loss:0.8522735238075256	train_acc:0.9111111111111111	test_acc:0.727	test_f1:0.7010490017029755
epoch:31	train_loss:0.8194087147712708	train_acc:0.9111111111111111	test_acc:0.728	test_f1:0.7027848418445686
epoch:32	train_loss:0.7702929973602295	train_acc:0.9166666666666666	test_acc:0.726	test_f1:0.6985307984340886
epoch:33	train_loss:0.7245234251022339	train_acc:0.9166666666666666	test_acc:0.728	test_f1:0.6997800744743583
epoch:34	train_loss:0.6818340420722961	train_acc:0.9166666666666666	test_acc:0.73	test_f1:0.7004103963428946
epoch:35	train_loss:0.64631187915802	train_acc:0.9166666666666666	test_acc:0.728	test_f1:0.6974258322804833
epoch:36	train_loss:0.6089169383049011	train_acc:0.9166666666666666	test_acc:0.729	test_f1:0.6999886945026912
epoch:37	train_loss:0.5778899192810059	train_acc:0.9166666666666666	test_acc:0.724	test_f1:0.6952481603383864
epoch:38	train_loss:0.5448614358901978	train_acc:0.9222222222222223	test_acc:0.724	test_f1:0.6957370936932059
epoch:39	train_loss:0.5180845856666565	train_acc:0.9166666666666666	test_acc:0.719	test_f1:0.6948799682859543
epoch:40	train_loss:0.48945748805999756	train_acc:0.9222222222222223	test_acc:0.716	test_f1:0.6922714310121224
epoch:41	train_loss:0.46001705527305603	train_acc:0.9305555555555556	test_acc:0.716	test_f1:0.692927397079942
epoch:42	train_loss:0.439225435256958	train_acc:0.9277777777777778	test_acc:0.714	test_f1:0.6898399434055723
epoch:43	train_loss:0.41459840536117554	train_acc:0.9388888888888889	test_acc:0.717	test_f1:0.6901200987365909
epoch:44	train_loss:0.4007994532585144	train_acc:0.9305555555555556	test_acc:0.721	test_f1:0.6932627895313349
epoch:45	train_loss:0.3790033757686615	train_acc:0.9305555555555556	test_acc:0.722	test_f1:0.6949984467365988
epoch:46	train_loss:0.36069443821907043	train_acc:0.9277777777777778	test_acc:0.715	test_f1:0.6903342658048808
epoch:47	train_loss:0.33762526512145996	train_acc:0.9416666666666667	test_acc:0.715	test_f1:0.6915111432950868
epoch:48	train_loss:0.3286694884300232	train_acc:0.9333333333333333	test_acc:0.715	test_f1:0.6911714035917725
epoch:49	train_loss:0.31556999683380127	train_acc:0.9416666666666667	test_acc:0.714	test_f1:0.690606605798395
epoch:50	train_loss:0.2980651259422302	train_acc:0.95	test_acc:0.719	test_f1:0.6931228130705538
训练并测试结束，共训练50轮，总用时368.670147895813s
最佳正确率为:0.749,对应的macro_f1为:0.7018248525044571,对应的训练轮次为:27



2022-07-01 22:14:41.910828
epoch:1	train_loss:0.2881670594215393	train_acc:0.9416666666666667	test_acc:0.726	test_f1:0.7005301985631638
epoch:2	train_loss:0.2807667553424835	train_acc:0.9444444444444444	test_acc:0.722	test_f1:0.6956737308784747
epoch:3	train_loss:0.2668565511703491	train_acc:0.9444444444444444	test_acc:0.723	test_f1:0.6968626071542605
epoch:4	train_loss:0.2571887671947479	train_acc:0.9555555555555556	test_acc:0.717	test_f1:0.6910290352665914
epoch:5	train_loss:0.2500258684158325	train_acc:0.9583333333333334	test_acc:0.722	test_f1:0.6959844944715486
epoch:6	train_loss:0.24602331221103668	train_acc:0.9638888888888889	test_acc:0.724	test_f1:0.6977448311129238
epoch:7	train_loss:0.2375411093235016	train_acc:0.9583333333333334	test_acc:0.724	test_f1:0.697761750476416
epoch:8	train_loss:0.23251259326934814	train_acc:0.9583333333333334	test_acc:0.726	test_f1:0.6996001541930825
epoch:9	train_loss:0.22444245219230652	train_acc:0.9611111111111111	test_acc:0.726	test_f1:0.6996001541930825
epoch:10	train_loss:0.22152139246463776	train_acc:0.9638888888888889	test_acc:0.726	test_f1:0.6995818324542364
epoch:11	train_loss:0.2162236124277115	train_acc:0.9694444444444444	test_acc:0.72	test_f1:0.694022702001396
epoch:12	train_loss:0.21223768591880798	train_acc:0.9638888888888889	test_acc:0.726	test_f1:0.6995988765923152
epoch:13	train_loss:0.20621976256370544	train_acc:0.9694444444444444	test_acc:0.726	test_f1:0.6988597309821974
epoch:14	train_loss:0.1985534131526947	train_acc:0.975	test_acc:0.732	test_f1:0.7036134830985802
epoch:15	train_loss:0.19514283537864685	train_acc:0.975	test_acc:0.734	test_f1:0.704661045043054
epoch:16	train_loss:0.19990624487400055	train_acc:0.9722222222222222	test_acc:0.732	test_f1:0.7028836647314768
epoch:17	train_loss:0.18875153362751007	train_acc:0.9777777777777777	test_acc:0.73	test_f1:0.7011426355549016
epoch:18	train_loss:0.1895456612110138	train_acc:0.975	test_acc:0.727	test_f1:0.6992448236311954
epoch:19	train_loss:0.1864244043827057	train_acc:0.9861111111111112	test_acc:0.723	test_f1:0.6953371075922323
epoch:20	train_loss:0.17841027677059174	train_acc:0.9833333333333333	test_acc:0.734	test_f1:0.704668396434994
epoch:21	train_loss:0.1797671616077423	train_acc:0.9833333333333333	test_acc:0.737	test_f1:0.7075286335609086
epoch:22	train_loss:0.17896966636180878	train_acc:0.975	test_acc:0.738	test_f1:0.7086451852638206
epoch:23	train_loss:0.17484746873378754	train_acc:0.975	test_acc:0.735	test_f1:0.7058539357860724
epoch:24	train_loss:0.16975142061710358	train_acc:0.9861111111111112	test_acc:0.729	test_f1:0.7002112805250417
epoch:25	train_loss:0.16701500117778778	train_acc:0.9861111111111112	test_acc:0.733	test_f1:0.7039688849429494
epoch:26	train_loss:0.16805510222911835	train_acc:0.9861111111111112	test_acc:0.739	test_f1:0.7088163878307001
epoch:27	train_loss:0.1626635044813156	train_acc:0.9805555555555555	test_acc:0.739	test_f1:0.708841445661215
epoch:28	train_loss:0.16306695342063904	train_acc:0.9833333333333333	test_acc:0.736	test_f1:0.7058882967528105
epoch:29	train_loss:0.16286905109882355	train_acc:0.9805555555555555	test_acc:0.729	test_f1:0.7011311529298698
epoch:30	train_loss:0.16125556826591492	train_acc:0.9861111111111112	test_acc:0.73	test_f1:0.7019566471305513
epoch:31	train_loss:0.15907803177833557	train_acc:0.9888888888888889	test_acc:0.736	test_f1:0.7058666220317792
epoch:32	train_loss:0.1537209302186966	train_acc:0.9916666666666667	test_acc:0.737	test_f1:0.7068618483502284
epoch:33	train_loss:0.15432976186275482	train_acc:0.9916666666666667	test_acc:0.736	test_f1:0.7048271918191459
epoch:34	train_loss:0.1517842411994934	train_acc:0.9916666666666667	test_acc:0.733	test_f1:0.7031572077101987
epoch:35	train_loss:0.1511135995388031	train_acc:0.9944444444444445	test_acc:0.729	test_f1:0.6995593568071938
epoch:36	train_loss:0.1512007862329483	train_acc:0.9833333333333333	test_acc:0.731	test_f1:0.7015971162442322
epoch:37	train_loss:0.14569959044456482	train_acc:0.9888888888888889	test_acc:0.736	test_f1:0.7064538196132396
epoch:38	train_loss:0.14565303921699524	train_acc:0.9861111111111112	test_acc:0.736	test_f1:0.7060322517562322
epoch:39	train_loss:0.14803121984004974	train_acc:0.9944444444444445	test_acc:0.731	test_f1:0.700959237802588
epoch:40	train_loss:0.142107754945755	train_acc:0.9861111111111112	test_acc:0.726	test_f1:0.6963583023322855
epoch:41	train_loss:0.141524538397789	train_acc:0.9861111111111112	test_acc:0.729	test_f1:0.6997066438674514
epoch:42	train_loss:0.14020833373069763	train_acc:0.9861111111111112	test_acc:0.733	test_f1:0.7040349327646664
epoch:43	train_loss:0.140573650598526	train_acc:0.9861111111111112	test_acc:0.733	test_f1:0.7038488475597843
epoch:44	train_loss:0.132667675614357	train_acc:0.9861111111111112	test_acc:0.732	test_f1:0.7011762846658715
epoch:45	train_loss:0.1321471482515335	train_acc:0.9916666666666667	test_acc:0.728	test_f1:0.6977410707776889
epoch:46	train_loss:0.13308590650558472	train_acc:0.9888888888888889	test_acc:0.729	test_f1:0.6998198394485856
epoch:47	train_loss:0.13396404683589935	train_acc:0.9944444444444445	test_acc:0.73	test_f1:0.7005757885306042
epoch:48	train_loss:0.1302250623703003	train_acc:0.9944444444444445	test_acc:0.731	test_f1:0.7019226824503786
epoch:49	train_loss:0.12727046012878418	train_acc:0.9972222222222222	test_acc:0.733	test_f1:0.7040732263589996
epoch:50	train_loss:0.12613308429718018	train_acc:0.9944444444444445	test_acc:0.731	test_f1:0.7017161194271214
训练并测试结束，共训练50轮，总用时371.4014096260071s
最佳正确率为:0.739,对应的macro_f1为:0.708841445661215,对应的训练轮次为:27



2022-07-01 22:20:53.321321
epoch:1	train_loss:0.12584714591503143	train_acc:0.9944444444444445	test_acc:0.728	test_f1:0.6974111494507792
epoch:2	train_loss:0.12402369827032089	train_acc:0.9888888888888889	test_acc:0.733	test_f1:0.7017842818313754
epoch:3	train_loss:0.12181919068098068	train_acc:0.9916666666666667	test_acc:0.731	test_f1:0.7002002882951857
epoch:4	train_loss:0.11796975135803223	train_acc:0.9888888888888889	test_acc:0.735	test_f1:0.7043459519714529
epoch:5	train_loss:0.12168416380882263	train_acc:0.9944444444444445	test_acc:0.735	test_f1:0.7048127641818089
epoch:6	train_loss:0.12064563482999802	train_acc:0.9916666666666667	test_acc:0.732	test_f1:0.7027215895501989
epoch:7	train_loss:0.1161682978272438	train_acc:0.9916666666666667	test_acc:0.731	test_f1:0.7021130107405629
epoch:8	train_loss:0.11938213557004929	train_acc:0.9944444444444445	test_acc:0.73	test_f1:0.7010725215859623
epoch:9	train_loss:0.11969102919101715	train_acc:0.9916666666666667	test_acc:0.732	test_f1:0.7013775889786058
epoch:10	train_loss:0.11612968891859055	train_acc:0.9916666666666667	test_acc:0.737	test_f1:0.706410764443827
epoch:11	train_loss:0.11572935432195663	train_acc:0.9888888888888889	test_acc:0.735	test_f1:0.704504423313661
epoch:12	train_loss:0.11536871641874313	train_acc:0.9916666666666667	test_acc:0.73	test_f1:0.69925438682198
epoch:13	train_loss:0.11421483755111694	train_acc:0.9916666666666667	test_acc:0.726	test_f1:0.6964712313361209
epoch:14	train_loss:0.11622801423072815	train_acc:0.9861111111111112	test_acc:0.726	test_f1:0.6960191495984357
epoch:15	train_loss:0.11245713382959366	train_acc:0.9944444444444445	test_acc:0.737	test_f1:0.7069036095911557
epoch:16	train_loss:0.11087013781070709	train_acc:0.9916666666666667	test_acc:0.736	test_f1:0.7058992504111274
epoch:17	train_loss:0.11292076855897903	train_acc:0.9861111111111112	test_acc:0.732	test_f1:0.7026309868816485
epoch:18	train_loss:0.11087634414434433	train_acc:0.9916666666666667	test_acc:0.724	test_f1:0.6948313279631684
epoch:19	train_loss:0.11013862490653992	train_acc:0.9944444444444445	test_acc:0.72	test_f1:0.691006932428501
epoch:20	train_loss:0.10872623324394226	train_acc:0.9916666666666667	test_acc:0.727	test_f1:0.6966186230850338
epoch:21	train_loss:0.10699903964996338	train_acc:0.9944444444444445	test_acc:0.735	test_f1:0.7053755040093145
epoch:22	train_loss:0.1082841157913208	train_acc:0.9916666666666667	test_acc:0.736	test_f1:0.706318693331478
epoch:23	train_loss:0.10781224071979523	train_acc:0.9888888888888889	test_acc:0.729	test_f1:0.6992201134706181
epoch:24	train_loss:0.11170084029436111	train_acc:0.9916666666666667	test_acc:0.725	test_f1:0.6946876563846603
epoch:25	train_loss:0.10454771667718887	train_acc:0.9972222222222222	test_acc:0.724	test_f1:0.6936849350081619
epoch:26	train_loss:0.10835904628038406	train_acc:0.9944444444444445	test_acc:0.732	test_f1:0.7012367736135219
epoch:27	train_loss:0.1056567057967186	train_acc:0.9944444444444445	test_acc:0.735	test_f1:0.7048278537497511
epoch:28	train_loss:0.10241900384426117	train_acc:0.9916666666666667	test_acc:0.73	test_f1:0.7004025143457068
epoch:29	train_loss:0.10244299471378326	train_acc:0.9916666666666667	test_acc:0.729	test_f1:0.7001455482190355
epoch:30	train_loss:0.10226893424987793	train_acc:0.9944444444444445	test_acc:0.723	test_f1:0.6941188876404712
epoch:31	train_loss:0.10105068981647491	train_acc:0.9944444444444445	test_acc:0.725	test_f1:0.6946588470862088
epoch:32	train_loss:0.10093003511428833	train_acc:0.9972222222222222	test_acc:0.735	test_f1:0.7041767961953763
epoch:33	train_loss:0.0999496579170227	train_acc:0.9944444444444445	test_acc:0.736	test_f1:0.7054501455644475
epoch:34	train_loss:0.10085366666316986	train_acc:0.9944444444444445	test_acc:0.732	test_f1:0.701396064804081
epoch:35	train_loss:0.09905552119016647	train_acc:0.9944444444444445	test_acc:0.731	test_f1:0.7017215623564853
epoch:36	train_loss:0.10030770301818848	train_acc:0.9888888888888889	test_acc:0.727	test_f1:0.6978587674427094
epoch:37	train_loss:0.09965617954730988	train_acc:0.9944444444444445	test_acc:0.724	test_f1:0.6938096433889799
epoch:38	train_loss:0.09687525033950806	train_acc:0.9916666666666667	test_acc:0.731	test_f1:0.7003408287770404
epoch:39	train_loss:0.0965484231710434	train_acc:0.9944444444444445	test_acc:0.735	test_f1:0.7041692087581076
epoch:40	train_loss:0.0967232882976532	train_acc:0.9944444444444445	test_acc:0.734	test_f1:0.7032462736256865
epoch:41	train_loss:0.09336244314908981	train_acc:0.9972222222222222	test_acc:0.733	test_f1:0.7023668472360055
epoch:42	train_loss:0.09625022858381271	train_acc:0.9916666666666667	test_acc:0.727	test_f1:0.6970263420031921
epoch:43	train_loss:0.09431964159011841	train_acc:0.9944444444444445	test_acc:0.727	test_f1:0.6970120854258203
epoch:44	train_loss:0.09391522407531738	train_acc:0.9972222222222222	test_acc:0.727	test_f1:0.6969366565893678
epoch:45	train_loss:0.09576345980167389	train_acc:0.9888888888888889	test_acc:0.732	test_f1:0.7015296079018937
epoch:46	train_loss:0.09453777968883514	train_acc:0.9916666666666667	test_acc:0.737	test_f1:0.7062350894233909
epoch:47	train_loss:0.09377902001142502	train_acc:0.9972222222222222	test_acc:0.735	test_f1:0.7044934716963684
epoch:48	train_loss:0.09344756603240967	train_acc:0.9916666666666667	test_acc:0.729	test_f1:0.6986303980055771
epoch:49	train_loss:0.09078403562307358	train_acc:0.9944444444444445	test_acc:0.725	test_f1:0.6952187811573269
epoch:50	train_loss:0.08932821452617645	train_acc:0.9972222222222222	test_acc:0.728	test_f1:0.6981584280959469
训练并测试结束，共训练50轮，总用时369.88522243499756s
最佳正确率为:0.737,对应的macro_f1为:0.7062350894233909,对应的训练轮次为:46



2022-07-01 22:42:04.255467
2022-07-01 23:21:37.485942
epoch:1	train_loss:1.8865642547607422	train_acc:0.15833333333333333	test_acc:0.16	test_f1:0.04597701149425288
epoch:2	train_loss:2.2118866443634033	train_acc:0.16666666666666666	test_acc:0.184	test_f1:0.055311064856113916
epoch:3	train_loss:1.9095869064331055	train_acc:0.19444444444444445	test_acc:0.312	test_f1:0.2520319666128989
epoch:4	train_loss:1.6878105401992798	train_acc:0.475	test_acc:0.253	test_f1:0.17900196435252247
epoch:5	train_loss:1.6640973091125488	train_acc:0.3611111111111111	test_acc:0.239	test_f1:0.09371440405923165
epoch:6	train_loss:1.6392958164215088	train_acc:0.2361111111111111	test_acc:0.244	test_f1:0.10609105345947452
epoch:7	train_loss:1.5152204036712646	train_acc:0.28055555555555556	test_acc:0.644	test_f1:0.6191716640631083
epoch:8	train_loss:1.354039192199707	train_acc:0.8611111111111112	test_acc:0.606	test_f1:0.5587904334697972
epoch:9	train_loss:1.246475100517273	train_acc:0.8	test_acc:0.555	test_f1:0.488869028133023
epoch:10	train_loss:1.145159363746643	train_acc:0.7361111111111112	test_acc:0.653	test_f1:0.6111678380735761
epoch:11	train_loss:0.986035168170929	train_acc:0.8555555555555555	test_acc:0.717	test_f1:0.6840635373566024
epoch:12	train_loss:0.8481498956680298	train_acc:0.9027777777777778	test_acc:0.707	test_f1:0.6779429025032989
epoch:13	train_loss:0.7144142389297485	train_acc:0.9055555555555556	test_acc:0.71	test_f1:0.6872534410663627
epoch:14	train_loss:0.6075478196144104	train_acc:0.9111111111111111	test_acc:0.713	test_f1:0.6861649896429921
epoch:15	train_loss:0.5004990696907043	train_acc:0.9138888888888889	test_acc:0.72	test_f1:0.6905504494069264
epoch:16	train_loss:0.421670138835907	train_acc:0.925	test_acc:0.721	test_f1:0.6868926907721319
epoch:17	train_loss:0.36565956473350525	train_acc:0.925	test_acc:0.725	test_f1:0.6932886710502589
epoch:18	train_loss:0.3234327733516693	train_acc:0.9305555555555556	test_acc:0.72	test_f1:0.6917297371445085
epoch:19	train_loss:0.2827567160129547	train_acc:0.9305555555555556	test_acc:0.716	test_f1:0.6898739995466103
epoch:20	train_loss:0.2502046823501587	train_acc:0.9361111111111111	test_acc:0.713	test_f1:0.6870305788028267
epoch:21	train_loss:0.2277960628271103	train_acc:0.95	test_acc:0.714	test_f1:0.6891163577150633
epoch:22	train_loss:0.20386788249015808	train_acc:0.9527777777777777	test_acc:0.707	test_f1:0.6797810019331343
epoch:23	train_loss:0.19081030786037445	train_acc:0.9694444444444444	test_acc:0.711	test_f1:0.6842529170168042
epoch:24	train_loss:0.17545689642429352	train_acc:0.975	test_acc:0.71	test_f1:0.6823275891389676
epoch:25	train_loss:0.16287894546985626	train_acc:0.9722222222222222	test_acc:0.71	test_f1:0.6834159158158447
epoch:26	train_loss:0.15059995651245117	train_acc:0.975	test_acc:0.719	test_f1:0.6906847862417163
epoch:27	train_loss:0.14800630509853363	train_acc:0.9833333333333333	test_acc:0.73	test_f1:0.6993346056527541
epoch:28	train_loss:0.14309613406658173	train_acc:0.9805555555555555	test_acc:0.718	test_f1:0.689133599937613
epoch:29	train_loss:0.14010468125343323	train_acc:0.9861111111111112	test_acc:0.714	test_f1:0.6846739270489103
epoch:30	train_loss:0.1379130780696869	train_acc:0.9833333333333333	test_acc:0.718	test_f1:0.6877501221682292
epoch:31	train_loss:0.1380404829978943	train_acc:0.9805555555555555	test_acc:0.719	test_f1:0.6905028447051421
epoch:32	train_loss:0.13550245761871338	train_acc:0.9805555555555555	test_acc:0.711	test_f1:0.6838588807390651
epoch:33	train_loss:0.13455840945243835	train_acc:0.9805555555555555	test_acc:0.733	test_f1:0.7016215021795883
epoch:34	train_loss:0.12807048857212067	train_acc:0.9861111111111112	test_acc:0.734	test_f1:0.7025943767210929
epoch:35	train_loss:0.1255912035703659	train_acc:0.9888888888888889	test_acc:0.712	test_f1:0.6831272201985867
epoch:36	train_loss:0.12678053975105286	train_acc:0.9888888888888889	test_acc:0.721	test_f1:0.6918399722100737
epoch:37	train_loss:0.11852685362100601	train_acc:0.9861111111111112	test_acc:0.716	test_f1:0.6885452053356486
epoch:38	train_loss:0.12381148338317871	train_acc:0.9916666666666667	test_acc:0.722	test_f1:0.6940441028589156
epoch:39	train_loss:0.11139732599258423	train_acc:0.9972222222222222	test_acc:0.717	test_f1:0.6877396445031234
epoch:40	train_loss:0.10876842588186264	train_acc:0.9888888888888889	test_acc:0.726	test_f1:0.6956922721276538
epoch:41	train_loss:0.10588541626930237	train_acc:0.9916666666666667	test_acc:0.725	test_f1:0.6947988979014763
epoch:42	train_loss:0.10364588350057602	train_acc:0.9888888888888889	test_acc:0.717	test_f1:0.6877742222752224
epoch:43	train_loss:0.10245029628276825	train_acc:0.9888888888888889	test_acc:0.724	test_f1:0.6937762890753683
epoch:44	train_loss:0.09845513850450516	train_acc:0.9916666666666667	test_acc:0.725	test_f1:0.6937293908912467
epoch:45	train_loss:0.09625149518251419	train_acc:0.9861111111111112	test_acc:0.723	test_f1:0.6928126980559618
epoch:46	train_loss:0.08737237006425858	train_acc:0.9916666666666667	test_acc:0.71	test_f1:0.6830347314210146
epoch:47	train_loss:0.09400851279497147	train_acc:0.9916666666666667	test_acc:0.72	test_f1:0.6907898670756291
epoch:48	train_loss:0.09090328216552734	train_acc:0.9888888888888889	test_acc:0.732	test_f1:0.7012314929278113
epoch:49	train_loss:0.09845320880413055	train_acc:0.9861111111111112	test_acc:0.716	test_f1:0.6863971074242424
epoch:50	train_loss:0.09189814329147339	train_acc:0.9888888888888889	test_acc:0.707	test_f1:0.680974017604445
训练并测试结束，共训练50轮，总用时483.6262135505676s
最佳正确率为:0.734,对应的macro_f1为:0.7025943767210929,对应的训练轮次为:34



2022-07-01 23:30:17.018661
epoch:1	train_loss:1.86814284324646	train_acc:0.16666666666666666	test_acc:0.077	test_f1:0.023831631073970908
epoch:2	train_loss:2.328014373779297	train_acc:0.16666666666666666	test_acc:0.236	test_f1:0.07289673837147162
epoch:3	train_loss:2.00290584564209	train_acc:0.24722222222222223	test_acc:0.341	test_f1:0.23142220054982346
epoch:4	train_loss:1.763491153717041	train_acc:0.45	test_acc:0.232	test_f1:0.12925627652252764
epoch:5	train_loss:1.6958835124969482	train_acc:0.30277777777777776	test_acc:0.182	test_f1:0.05295143712759717
epoch:6	train_loss:1.658323049545288	train_acc:0.17777777777777778	test_acc:0.222	test_f1:0.12903766358119265
epoch:7	train_loss:1.5291900634765625	train_acc:0.35555555555555557	test_acc:0.296	test_f1:0.33410991877287016
epoch:8	train_loss:1.4332149028778076	train_acc:0.6055555555555555	test_acc:0.342	test_f1:0.3580027053521071
epoch:9	train_loss:1.3221290111541748	train_acc:0.6555555555555556	test_acc:0.612	test_f1:0.5396775016955694
epoch:10	train_loss:1.1707478761672974	train_acc:0.8027777777777778	test_acc:0.601	test_f1:0.5128247630210329
epoch:11	train_loss:1.0579067468643188	train_acc:0.725	test_acc:0.72	test_f1:0.6441236122715025
epoch:12	train_loss:0.9343017339706421	train_acc:0.8277777777777777	test_acc:0.74	test_f1:0.6895628610640473
epoch:13	train_loss:0.7921103239059448	train_acc:0.8888888888888888	test_acc:0.702	test_f1:0.6714460097991433
epoch:14	train_loss:0.6784618496894836	train_acc:0.9083333333333333	test_acc:0.68	test_f1:0.6650926216874665
epoch:15	train_loss:0.5902811884880066	train_acc:0.9194444444444444	test_acc:0.674	test_f1:0.6627409778138177
epoch:16	train_loss:0.50760817527771	train_acc:0.9333333333333333	test_acc:0.717	test_f1:0.6936692305631866
epoch:17	train_loss:0.43281418085098267	train_acc:0.9305555555555556	test_acc:0.735	test_f1:0.6949241826838225
epoch:18	train_loss:0.3818911910057068	train_acc:0.925	test_acc:0.749	test_f1:0.7087503868370405
epoch:19	train_loss:0.3416101038455963	train_acc:0.9305555555555556	test_acc:0.738	test_f1:0.7022141957954552
epoch:20	train_loss:0.29375848174095154	train_acc:0.9361111111111111	test_acc:0.724	test_f1:0.6957951622490479
epoch:21	train_loss:0.26299378275871277	train_acc:0.9472222222222222	test_acc:0.699	test_f1:0.6817715088117041
epoch:22	train_loss:0.2428276240825653	train_acc:0.9527777777777777	test_acc:0.702	test_f1:0.6806137206198543
epoch:23	train_loss:0.22654464840888977	train_acc:0.95	test_acc:0.723	test_f1:0.693179521694475
epoch:24	train_loss:0.19560012221336365	train_acc:0.9583333333333334	test_acc:0.74	test_f1:0.7071570345649909
epoch:25	train_loss:0.18795403838157654	train_acc:0.9583333333333334	test_acc:0.741	test_f1:0.7074354416369989
epoch:26	train_loss:0.181862011551857	train_acc:0.9638888888888889	test_acc:0.731	test_f1:0.7009727245019773
epoch:27	train_loss:0.1656336486339569	train_acc:0.9805555555555555	test_acc:0.725	test_f1:0.6979931161760621
epoch:28	train_loss:0.157704159617424	train_acc:0.9833333333333333	test_acc:0.714	test_f1:0.68463729329159
epoch:29	train_loss:0.15359725058078766	train_acc:0.9722222222222222	test_acc:0.718	test_f1:0.6881878602628047
epoch:30	train_loss:0.15629489719867706	train_acc:0.975	test_acc:0.721	test_f1:0.6919284880652866
epoch:31	train_loss:0.14864322543144226	train_acc:0.9805555555555555	test_acc:0.725	test_f1:0.6946516578854722
epoch:32	train_loss:0.14331141114234924	train_acc:0.9888888888888889	test_acc:0.728	test_f1:0.6977274231974272
epoch:33	train_loss:0.1527237743139267	train_acc:0.9805555555555555	test_acc:0.727	test_f1:0.6968725826499979
epoch:34	train_loss:0.14884352684020996	train_acc:0.9805555555555555	test_acc:0.729	test_f1:0.6992333370236367
epoch:35	train_loss:0.14559215307235718	train_acc:0.9861111111111112	test_acc:0.721	test_f1:0.6929335766725035
epoch:36	train_loss:0.1402633786201477	train_acc:0.9888888888888889	test_acc:0.725	test_f1:0.6963642204196091
epoch:37	train_loss:0.1347312480211258	train_acc:0.9888888888888889	test_acc:0.733	test_f1:0.7033512238960752
epoch:38	train_loss:0.12535937130451202	train_acc:0.9916666666666667	test_acc:0.731	test_f1:0.699031845675156
epoch:39	train_loss:0.13085365295410156	train_acc:0.9888888888888889	test_acc:0.741	test_f1:0.7099189419423514
epoch:40	train_loss:0.11997859925031662	train_acc:0.9944444444444445	test_acc:0.733	test_f1:0.7022526761183968
epoch:41	train_loss:0.1102544367313385	train_acc:0.9916666666666667	test_acc:0.722	test_f1:0.6941711199181612
epoch:42	train_loss:0.11290287971496582	train_acc:0.9972222222222222	test_acc:0.723	test_f1:0.6947455989141108
epoch:43	train_loss:0.10896077752113342	train_acc:0.9888888888888889	test_acc:0.731	test_f1:0.7001348116800271
epoch:44	train_loss:0.10898888856172562	train_acc:0.9833333333333333	test_acc:0.732	test_f1:0.7020840917671519
epoch:45	train_loss:0.10424881428480148	train_acc:0.9888888888888889	test_acc:0.735	test_f1:0.7042918699293437
epoch:46	train_loss:0.10306459665298462	train_acc:0.9861111111111112	test_acc:0.733	test_f1:0.7031152870900327
epoch:47	train_loss:0.09773191064596176	train_acc:0.9916666666666667	test_acc:0.733	test_f1:0.7024930441827125
epoch:48	train_loss:0.09992280602455139	train_acc:0.9861111111111112	test_acc:0.729	test_f1:0.6990771081579558
epoch:49	train_loss:0.09827578067779541	train_acc:0.9888888888888889	test_acc:0.731	test_f1:0.7011916053962151
epoch:50	train_loss:0.093337781727314	train_acc:0.9916666666666667	test_acc:0.729	test_f1:0.6991386005997278
训练并测试结束，共训练50轮，总用时482.74837946891785s
最佳正确率为:0.749,对应的macro_f1为:0.7087503868370405,对应的训练轮次为:18



2022-07-02 00:43:02.569880
epoch:1	train_loss:2.004322052001953	train_acc:0.14285714285714285	test_acc:0.387	test_f1:0.17649294010455724
epoch:2	train_loss:2.177659511566162	train_acc:0.2571428571428571	test_acc:0.143	test_f1:0.13584684852339107
epoch:3	train_loss:1.934998631477356	train_acc:0.24642857142857144	test_acc:0.36	test_f1:0.3414174538346412
epoch:4	train_loss:1.6715452671051025	train_acc:0.5142857142857142	test_acc:0.594	test_f1:0.6209638265261349
epoch:5	train_loss:1.4896368980407715	train_acc:0.7892857142857143	test_acc:0.33	test_f1:0.3666614463169398
epoch:6	train_loss:1.3655433654785156	train_acc:0.5178571428571429	test_acc:0.471	test_f1:0.5201601670324829
epoch:7	train_loss:1.173885464668274	train_acc:0.7035714285714286	test_acc:0.775	test_f1:0.757447174192378
epoch:8	train_loss:0.9562905430793762	train_acc:0.9071428571428571	test_acc:0.759	test_f1:0.7392036036890179
epoch:9	train_loss:0.7889323830604553	train_acc:0.8857142857142857	test_acc:0.748	test_f1:0.7382683584404631
epoch:10	train_loss:0.6386836767196655	train_acc:0.875	test_acc:0.778	test_f1:0.7753567339835206
epoch:11	train_loss:0.5008751749992371	train_acc:0.9071428571428571	test_acc:0.808	test_f1:0.8060843045048246
epoch:12	train_loss:0.38159966468811035	train_acc:0.9357142857142857	test_acc:0.765	test_f1:0.775528432730542
epoch:13	train_loss:0.31719088554382324	train_acc:0.95	test_acc:0.785	test_f1:0.7855098595014313
epoch:14	train_loss:0.2474163919687271	train_acc:0.9571428571428572	test_acc:0.832	test_f1:0.8231922408795158
epoch:15	train_loss:0.19346444308757782	train_acc:0.9571428571428572	test_acc:0.837	test_f1:0.827300135472471
epoch:16	train_loss:0.15685971081256866	train_acc:0.9607142857142857	test_acc:0.831	test_f1:0.8247587156410783
epoch:17	train_loss:0.1281459629535675	train_acc:0.9714285714285714	test_acc:0.825	test_f1:0.8214178744262906
epoch:18	train_loss:0.10187400877475739	train_acc:0.9857142857142858	test_acc:0.82	test_f1:0.8163833145052772
epoch:19	train_loss:0.08197572827339172	train_acc:0.9928571428571429	test_acc:0.822	test_f1:0.8144232811847366
epoch:20	train_loss:0.06803523004055023	train_acc:1.0	test_acc:0.827	test_f1:0.819512941699443
epoch:21	train_loss:0.05617441609501839	train_acc:1.0	test_acc:0.831	test_f1:0.8203569934417112
epoch:22	train_loss:0.05155251547694206	train_acc:1.0	test_acc:0.832	test_f1:0.8234656523893031
epoch:23	train_loss:0.04447481408715248	train_acc:1.0	test_acc:0.825	test_f1:0.8173478795244697
epoch:24	train_loss:0.03632953763008118	train_acc:1.0	test_acc:0.827	test_f1:0.8213793937855943
epoch:25	train_loss:0.0361427366733551	train_acc:1.0	test_acc:0.826	test_f1:0.8195996413644286
epoch:26	train_loss:0.033520083874464035	train_acc:1.0	test_acc:0.829	test_f1:0.8211252549002662
epoch:27	train_loss:0.03337337076663971	train_acc:1.0	test_acc:0.835	test_f1:0.828000304724684
epoch:28	train_loss:0.03426395729184151	train_acc:1.0	test_acc:0.839	test_f1:0.8287953522166172
epoch:29	train_loss:0.033644597977399826	train_acc:1.0	test_acc:0.825	test_f1:0.8138080031737164
epoch:30	train_loss:0.03530329093337059	train_acc:1.0	test_acc:0.818	test_f1:0.8096583016367009
epoch:31	train_loss:0.03821922466158867	train_acc:1.0	test_acc:0.822	test_f1:0.8135310248669799
epoch:32	train_loss:0.04349038749933243	train_acc:1.0	test_acc:0.827	test_f1:0.8166906355044498
epoch:33	train_loss:0.04305678606033325	train_acc:1.0	test_acc:0.834	test_f1:0.8244839011930397
epoch:34	train_loss:0.046814147382974625	train_acc:1.0	test_acc:0.83	test_f1:0.8185994242136628
epoch:35	train_loss:0.05067348852753639	train_acc:1.0	test_acc:0.819	test_f1:0.808630544774571
epoch:36	train_loss:0.05407346040010452	train_acc:1.0	test_acc:0.821	test_f1:0.8103053278201079
epoch:37	train_loss:0.05285139009356499	train_acc:1.0	test_acc:0.832	test_f1:0.8229253328420755
epoch:38	train_loss:0.05518627166748047	train_acc:1.0	test_acc:0.834	test_f1:0.8239264227061219
epoch:39	train_loss:0.0579117089509964	train_acc:1.0	test_acc:0.826	test_f1:0.8143669306004097
epoch:40	train_loss:0.05728887766599655	train_acc:1.0	test_acc:0.826	test_f1:0.8173072979290835
epoch:41	train_loss:0.05686264857649803	train_acc:1.0	test_acc:0.832	test_f1:0.8224053665931923
epoch:42	train_loss:0.05323725938796997	train_acc:1.0	test_acc:0.827	test_f1:0.8187681971863717
epoch:43	train_loss:0.052412085235118866	train_acc:1.0	test_acc:0.822	test_f1:0.8108017388769484
epoch:44	train_loss:0.049063462764024734	train_acc:1.0	test_acc:0.826	test_f1:0.8155381171083663
epoch:45	train_loss:0.046026721596717834	train_acc:1.0	test_acc:0.83	test_f1:0.8216602828699776
epoch:46	train_loss:0.047354213893413544	train_acc:1.0	test_acc:0.836	test_f1:0.8266655457072748
epoch:47	train_loss:0.045226164162158966	train_acc:1.0	test_acc:0.831	test_f1:0.8195193329279473
epoch:48	train_loss:0.04350278526544571	train_acc:1.0	test_acc:0.828	test_f1:0.8175236320297695
epoch:49	train_loss:0.04326453432440758	train_acc:1.0	test_acc:0.834	test_f1:0.8276119733048007
epoch:50	train_loss:0.04340850189328194	train_acc:1.0	test_acc:0.828	test_f1:0.8196311317704233
训练并测试结束，共训练50轮，总用时54.320948123931885s
最佳正确率为:0.839,对应的macro_f1为:0.8287953522166172,对应的训练轮次为:28



2022-07-02 00:44:54.242873
epoch:1	train_loss:1.968721866607666	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:2	train_loss:2.2230734825134277	train_acc:0.14285714285714285	test_acc:0.332	test_f1:0.30637835851583445
epoch:3	train_loss:1.8689643144607544	train_acc:0.4607142857142857	test_acc:0.474	test_f1:0.5159648841897251
epoch:4	train_loss:1.6529139280319214	train_acc:0.6714285714285714	test_acc:0.228	test_f1:0.20120224170056958
epoch:5	train_loss:1.5739686489105225	train_acc:0.35714285714285715	test_acc:0.332	test_f1:0.3303156843447166
epoch:6	train_loss:1.403389811515808	train_acc:0.5071428571428571	test_acc:0.56	test_f1:0.6139626742731863
epoch:7	train_loss:1.17503821849823	train_acc:0.8035714285714286	test_acc:0.792	test_f1:0.7861142529687225
epoch:8	train_loss:0.9822225570678711	train_acc:0.8928571428571429	test_acc:0.748	test_f1:0.7413145431079788
epoch:9	train_loss:0.8174720406532288	train_acc:0.9	test_acc:0.769	test_f1:0.7592444089502354
epoch:10	train_loss:0.6477224230766296	train_acc:0.9107142857142857	test_acc:0.809	test_f1:0.8018462319117213
epoch:11	train_loss:0.49294301867485046	train_acc:0.9285714285714286	test_acc:0.799	test_f1:0.7886379800532304
epoch:12	train_loss:0.3888970911502838	train_acc:0.9464285714285714	test_acc:0.779	test_f1:0.7678461098533734
epoch:13	train_loss:0.3164122402667999	train_acc:0.9357142857142857	test_acc:0.801	test_f1:0.7943277308440112
epoch:14	train_loss:0.24555814266204834	train_acc:0.9392857142857143	test_acc:0.816	test_f1:0.8108762201868016
epoch:15	train_loss:0.18511900305747986	train_acc:0.9678571428571429	test_acc:0.826	test_f1:0.8215526950241243
epoch:16	train_loss:0.14384181797504425	train_acc:0.9821428571428571	test_acc:0.831	test_f1:0.8228237550062578
epoch:17	train_loss:0.11313939094543457	train_acc:0.9928571428571429	test_acc:0.834	test_f1:0.8255703178949625
epoch:18	train_loss:0.09109411388635635	train_acc:0.9928571428571429	test_acc:0.838	test_f1:0.8298956813517587
epoch:19	train_loss:0.07464952021837234	train_acc:0.9964285714285714	test_acc:0.829	test_f1:0.8231360094866323
epoch:20	train_loss:0.05330171063542366	train_acc:1.0	test_acc:0.816	test_f1:0.8112795351551736
epoch:21	train_loss:0.04622725769877434	train_acc:1.0	test_acc:0.81	test_f1:0.8064573398217104
epoch:22	train_loss:0.03664657473564148	train_acc:1.0	test_acc:0.819	test_f1:0.8121902634578417
epoch:23	train_loss:0.0325404554605484	train_acc:1.0	test_acc:0.823	test_f1:0.8140968766385138
epoch:24	train_loss:0.03057125210762024	train_acc:1.0	test_acc:0.827	test_f1:0.8171457102574256
epoch:25	train_loss:0.028056256473064423	train_acc:1.0	test_acc:0.827	test_f1:0.8181006400822314
epoch:26	train_loss:0.03158216178417206	train_acc:1.0	test_acc:0.825	test_f1:0.8156128380635941
epoch:27	train_loss:0.029805302619934082	train_acc:1.0	test_acc:0.82	test_f1:0.8102521584898159
epoch:28	train_loss:0.03164352476596832	train_acc:1.0	test_acc:0.823	test_f1:0.8146243467664344
epoch:29	train_loss:0.03308767080307007	train_acc:1.0	test_acc:0.811	test_f1:0.8033402688465227
epoch:30	train_loss:0.035198599100112915	train_acc:1.0	test_acc:0.811	test_f1:0.8026441022920218
epoch:31	train_loss:0.037089645862579346	train_acc:1.0	test_acc:0.817	test_f1:0.8096095800721056
epoch:32	train_loss:0.03556056320667267	train_acc:1.0	test_acc:0.827	test_f1:0.8192172325827514
epoch:33	train_loss:0.04093077778816223	train_acc:1.0	test_acc:0.824	test_f1:0.8146330063815889
epoch:34	train_loss:0.043845612555742264	train_acc:1.0	test_acc:0.813	test_f1:0.8037601421700057
epoch:35	train_loss:0.04800676181912422	train_acc:1.0	test_acc:0.816	test_f1:0.8074604122609349
epoch:36	train_loss:0.050998229533433914	train_acc:1.0	test_acc:0.816	test_f1:0.8057395999580947
epoch:37	train_loss:0.05448179692029953	train_acc:1.0	test_acc:0.814	test_f1:0.8064958192988849
epoch:38	train_loss:0.053305450826883316	train_acc:1.0	test_acc:0.818	test_f1:0.8118692420020811
epoch:39	train_loss:0.05532929673790932	train_acc:1.0	test_acc:0.826	test_f1:0.8180611304209767
epoch:40	train_loss:0.06167849898338318	train_acc:1.0	test_acc:0.817	test_f1:0.8084876136551439
epoch:41	train_loss:0.05398136377334595	train_acc:1.0	test_acc:0.818	test_f1:0.8106230402265366
epoch:42	train_loss:0.055972158908843994	train_acc:1.0	test_acc:0.826	test_f1:0.8178709501889878
epoch:43	train_loss:0.05601377785205841	train_acc:1.0	test_acc:0.813	test_f1:0.8035610638430686
epoch:44	train_loss:0.04933462291955948	train_acc:1.0	test_acc:0.81	test_f1:0.800660663913393
epoch:45	train_loss:0.0542905256152153	train_acc:1.0	test_acc:0.816	test_f1:0.806725003362754
epoch:46	train_loss:0.04864828288555145	train_acc:1.0	test_acc:0.829	test_f1:0.817558508602948
epoch:47	train_loss:0.05004984885454178	train_acc:1.0	test_acc:0.813	test_f1:0.8040106478738751
epoch:48	train_loss:0.04205373674631119	train_acc:1.0	test_acc:0.81	test_f1:0.8034827548806929
epoch:49	train_loss:0.04480394721031189	train_acc:1.0	test_acc:0.818	test_f1:0.8101834331363584
epoch:50	train_loss:0.04239346832036972	train_acc:1.0	test_acc:0.827	test_f1:0.8179331235603697
训练并测试结束，共训练50轮，总用时53.68077206611633s
最佳正确率为:0.838,对应的macro_f1为:0.8298956813517587,对应的训练轮次为:18



2022-07-02 00:46:40.584463
epoch:1	train_loss:1.9981576204299927	train_acc:0.14285714285714285	test_acc:0.13	test_f1:0.03286978508217447
epoch:2	train_loss:2.3734400272369385	train_acc:0.14285714285714285	test_acc:0.419	test_f1:0.2568158569956249
epoch:3	train_loss:1.954495906829834	train_acc:0.3464285714285714	test_acc:0.201	test_f1:0.25918448904113817
epoch:4	train_loss:1.7922886610031128	train_acc:0.4035714285714286	test_acc:0.435	test_f1:0.4456569707580545
epoch:5	train_loss:1.6637508869171143	train_acc:0.6392857142857142	test_acc:0.355	test_f1:0.37308512672383803
epoch:6	train_loss:1.5595682859420776	train_acc:0.5357142857142857	test_acc:0.381	test_f1:0.41317807792857286
epoch:7	train_loss:1.414520502090454	train_acc:0.5642857142857143	test_acc:0.577	test_f1:0.6265472897616763
epoch:8	train_loss:1.214142918586731	train_acc:0.8464285714285714	test_acc:0.761	test_f1:0.7590115804525709
epoch:9	train_loss:1.0290662050247192	train_acc:0.8928571428571429	test_acc:0.762	test_f1:0.7384741421544296
epoch:10	train_loss:0.8722681403160095	train_acc:0.8892857142857142	test_acc:0.791	test_f1:0.7721744560734827
epoch:11	train_loss:0.7099388241767883	train_acc:0.9071428571428571	test_acc:0.82	test_f1:0.8041364033123971
epoch:12	train_loss:0.5520970225334167	train_acc:0.9178571428571428	test_acc:0.795	test_f1:0.795804223611918
epoch:13	train_loss:0.43241754174232483	train_acc:0.9428571428571428	test_acc:0.779	test_f1:0.7874808452206306
epoch:14	train_loss:0.35724279284477234	train_acc:0.925	test_acc:0.804	test_f1:0.7992268620090387
epoch:15	train_loss:0.2798915505409241	train_acc:0.9428571428571428	test_acc:0.822	test_f1:0.8120562215625181
epoch:16	train_loss:0.22278304398059845	train_acc:0.9642857142857143	test_acc:0.824	test_f1:0.812632873500046
epoch:17	train_loss:0.1816094070672989	train_acc:0.9607142857142857	test_acc:0.821	test_f1:0.8092005649610297
epoch:18	train_loss:0.14967021346092224	train_acc:0.9642857142857143	test_acc:0.828	test_f1:0.8185857219931905
epoch:19	train_loss:0.1141095757484436	train_acc:0.9857142857142858	test_acc:0.828	test_f1:0.8207661000259782
epoch:20	train_loss:0.09144559502601624	train_acc:0.9892857142857143	test_acc:0.819	test_f1:0.8117011591480431
epoch:21	train_loss:0.07446251809597015	train_acc:0.9964285714285714	test_acc:0.812	test_f1:0.8047650683652423
epoch:22	train_loss:0.0659177154302597	train_acc:0.9964285714285714	test_acc:0.814	test_f1:0.8099994597342342
epoch:23	train_loss:0.053873784840106964	train_acc:1.0	test_acc:0.819	test_f1:0.8130722694301565
epoch:24	train_loss:0.04102492332458496	train_acc:1.0	test_acc:0.824	test_f1:0.8191734198680536
epoch:25	train_loss:0.04111718013882637	train_acc:1.0	test_acc:0.821	test_f1:0.8141973428871442
epoch:26	train_loss:0.03815475478768349	train_acc:1.0	test_acc:0.826	test_f1:0.8190622328190587
epoch:27	train_loss:0.03665585443377495	train_acc:1.0	test_acc:0.825	test_f1:0.8174500090039307
epoch:28	train_loss:0.033493008464574814	train_acc:1.0	test_acc:0.822	test_f1:0.8160921566169872
epoch:29	train_loss:0.0322483591735363	train_acc:1.0	test_acc:0.811	test_f1:0.8087118773586978
epoch:30	train_loss:0.03467287868261337	train_acc:1.0	test_acc:0.812	test_f1:0.809423230359216
epoch:31	train_loss:0.034828681498765945	train_acc:1.0	test_acc:0.818	test_f1:0.8103937291151296
epoch:32	train_loss:0.03958020731806755	train_acc:1.0	test_acc:0.82	test_f1:0.8107179408370968
epoch:33	train_loss:0.03832854703068733	train_acc:1.0	test_acc:0.814	test_f1:0.8038006632831014
epoch:34	train_loss:0.04143277928233147	train_acc:1.0	test_acc:0.814	test_f1:0.8053948922169389
epoch:35	train_loss:0.04583849757909775	train_acc:1.0	test_acc:0.83	test_f1:0.8228565314585045
epoch:36	train_loss:0.04588812589645386	train_acc:1.0	test_acc:0.827	test_f1:0.8169784179255057
epoch:37	train_loss:0.04673762992024422	train_acc:1.0	test_acc:0.826	test_f1:0.817341061258635
epoch:38	train_loss:0.04970600828528404	train_acc:1.0	test_acc:0.809	test_f1:0.8038507556838571
epoch:39	train_loss:0.05368587002158165	train_acc:1.0	test_acc:0.813	test_f1:0.807503219944436
epoch:40	train_loss:0.05345997214317322	train_acc:1.0	test_acc:0.823	test_f1:0.8124728359883241
epoch:41	train_loss:0.055229585617780685	train_acc:1.0	test_acc:0.831	test_f1:0.8197446281581966
epoch:42	train_loss:0.05743677169084549	train_acc:1.0	test_acc:0.819	test_f1:0.8099950917732475
epoch:43	train_loss:0.056792035698890686	train_acc:1.0	test_acc:0.808	test_f1:0.8031271276868394
epoch:44	train_loss:0.05618483945727348	train_acc:1.0	test_acc:0.813	test_f1:0.8038607962218564
epoch:45	train_loss:0.05385676771402359	train_acc:1.0	test_acc:0.816	test_f1:0.8053987753869392
epoch:46	train_loss:0.057380493730306625	train_acc:1.0	test_acc:0.829	test_f1:0.8236712005745196
epoch:47	train_loss:0.05026852339506149	train_acc:1.0	test_acc:0.826	test_f1:0.8220210866237941
epoch:48	train_loss:0.04988020658493042	train_acc:1.0	test_acc:0.826	test_f1:0.8179827485327708
epoch:49	train_loss:0.049223609268665314	train_acc:1.0	test_acc:0.82	test_f1:0.809677207670888
epoch:50	train_loss:0.04812754690647125	train_acc:1.0	test_acc:0.814	test_f1:0.8041701744824852
训练并测试结束，共训练50轮，总用时54.32469940185547s
最佳正确率为:0.814,对应的macro_f1为:0.8041701744824852,对应的训练轮次为:50



2022-07-02 00:48:05.577275
epoch:1	train_loss:1.9640334844589233	train_acc:0.14642857142857144	test_acc:0.319	test_f1:0.06909996750785227
epoch:2	train_loss:2.340195655822754	train_acc:0.14285714285714285	test_acc:0.372	test_f1:0.32191122600547406
epoch:3	train_loss:1.8343652486801147	train_acc:0.4857142857142857	test_acc:0.197	test_f1:0.12948923185854092
epoch:4	train_loss:1.7139110565185547	train_acc:0.2392857142857143	test_acc:0.245	test_f1:0.2291798631119817
epoch:5	train_loss:1.626802682876587	train_acc:0.39285714285714285	test_acc:0.207	test_f1:0.2646153880157591
epoch:6	train_loss:1.47129225730896	train_acc:0.425	test_acc:0.512	test_f1:0.5497403984622914
epoch:7	train_loss:1.2683759927749634	train_acc:0.7821428571428571	test_acc:0.596	test_f1:0.6341398912907603
epoch:8	train_loss:1.0813132524490356	train_acc:0.8285714285714286	test_acc:0.762	test_f1:0.7572846990318542
epoch:9	train_loss:0.8923984169960022	train_acc:0.8928571428571429	test_acc:0.777	test_f1:0.7615106289687162
epoch:10	train_loss:0.7388607859611511	train_acc:0.8857142857142857	test_acc:0.798	test_f1:0.791584071848167
epoch:11	train_loss:0.5757827758789062	train_acc:0.9142857142857143	test_acc:0.798	test_f1:0.7929636868488746
epoch:12	train_loss:0.4468180239200592	train_acc:0.9357142857142857	test_acc:0.772	test_f1:0.771436467942845
epoch:13	train_loss:0.3606180250644684	train_acc:0.9321428571428572	test_acc:0.776	test_f1:0.7690657894168432
epoch:14	train_loss:0.287442684173584	train_acc:0.9357142857142857	test_acc:0.808	test_f1:0.7996285697547537
epoch:15	train_loss:0.22335128486156464	train_acc:0.9571428571428572	test_acc:0.83	test_f1:0.8233778581554299
epoch:16	train_loss:0.17075692117214203	train_acc:0.9785714285714285	test_acc:0.827	test_f1:0.8185108543265052
epoch:17	train_loss:0.1398807168006897	train_acc:0.9892857142857143	test_acc:0.821	test_f1:0.8146200349831355
epoch:18	train_loss:0.1147792711853981	train_acc:0.9892857142857143	test_acc:0.821	test_f1:0.8129275733547058
epoch:19	train_loss:0.08552445471286774	train_acc:0.9964285714285714	test_acc:0.826	test_f1:0.8171827053121425
epoch:20	train_loss:0.06558112800121307	train_acc:1.0	test_acc:0.826	test_f1:0.8162243160302379
epoch:21	train_loss:0.056208234280347824	train_acc:1.0	test_acc:0.823	test_f1:0.8112492368263852
epoch:22	train_loss:0.04699261486530304	train_acc:1.0	test_acc:0.824	test_f1:0.8158378678170563
epoch:23	train_loss:0.04000011086463928	train_acc:1.0	test_acc:0.823	test_f1:0.8179027564960804
epoch:24	train_loss:0.03779488801956177	train_acc:1.0	test_acc:0.825	test_f1:0.8195586043499341
epoch:25	train_loss:0.03252408653497696	train_acc:1.0	test_acc:0.829	test_f1:0.8204854045662013
epoch:26	train_loss:0.031826820224523544	train_acc:1.0	test_acc:0.83	test_f1:0.8189550452564894
epoch:27	train_loss:0.03273019939661026	train_acc:1.0	test_acc:0.832	test_f1:0.8202703307773006
epoch:28	train_loss:0.03231329843401909	train_acc:1.0	test_acc:0.829	test_f1:0.8184998143633821
epoch:29	train_loss:0.03273671865463257	train_acc:1.0	test_acc:0.833	test_f1:0.8261376066170075
epoch:30	train_loss:0.03207724168896675	train_acc:1.0	test_acc:0.824	test_f1:0.8178947891485142
epoch:31	train_loss:0.03623604401946068	train_acc:1.0	test_acc:0.827	test_f1:0.8174763398117969
epoch:32	train_loss:0.038170043379068375	train_acc:1.0	test_acc:0.832	test_f1:0.8206510880271701
epoch:33	train_loss:0.04147221893072128	train_acc:1.0	test_acc:0.83	test_f1:0.8173695782385092
epoch:34	train_loss:0.0438278503715992	train_acc:1.0	test_acc:0.824	test_f1:0.8126086900780969
epoch:35	train_loss:0.04639118164777756	train_acc:1.0	test_acc:0.826	test_f1:0.8188101644701443
epoch:36	train_loss:0.046888574957847595	train_acc:1.0	test_acc:0.827	test_f1:0.8195510767891868
epoch:37	train_loss:0.05174702778458595	train_acc:1.0	test_acc:0.825	test_f1:0.8151614506845443
epoch:38	train_loss:0.051095377653837204	train_acc:1.0	test_acc:0.829	test_f1:0.8165766615778141
epoch:39	train_loss:0.05803095921874046	train_acc:1.0	test_acc:0.831	test_f1:0.8221763522147348
epoch:40	train_loss:0.05633734166622162	train_acc:1.0	test_acc:0.83	test_f1:0.8215865185926399
epoch:41	train_loss:0.05613415688276291	train_acc:1.0	test_acc:0.829	test_f1:0.8166577605194599
epoch:42	train_loss:0.05589872598648071	train_acc:1.0	test_acc:0.825	test_f1:0.8141690009491357
epoch:43	train_loss:0.05315421521663666	train_acc:1.0	test_acc:0.825	test_f1:0.8177977365234531
epoch:44	train_loss:0.05367666855454445	train_acc:1.0	test_acc:0.827	test_f1:0.8184303661017244
epoch:45	train_loss:0.050663188099861145	train_acc:1.0	test_acc:0.827	test_f1:0.8157227929769897
epoch:46	train_loss:0.05021236464381218	train_acc:1.0	test_acc:0.829	test_f1:0.8184824879085515
epoch:47	train_loss:0.05043352395296097	train_acc:1.0	test_acc:0.836	test_f1:0.8304295221722869
epoch:48	train_loss:0.047755833715200424	train_acc:1.0	test_acc:0.831	test_f1:0.8257420906410516
epoch:49	train_loss:0.047904182225465775	train_acc:1.0	test_acc:0.828	test_f1:0.8158015242553409
epoch:50	train_loss:0.045519452542066574	train_acc:1.0	test_acc:0.824	test_f1:0.8132247175315513
训练并测试结束，共训练50轮，总用时54.773357629776s
最佳正确率为:0.836,对应的macro_f1为:0.8304295221722869,对应的训练轮次为:47



2022-07-02 00:51:15.134847
epoch:1	train_loss:1.974625825881958	train_acc:0.13214285714285715	test_acc:0.091	test_f1:0.02383134738771769
epoch:2	train_loss:2.443385601043701	train_acc:0.14285714285714285	test_acc:0.383	test_f1:0.2266328983571316
epoch:3	train_loss:1.8241509199142456	train_acc:0.3464285714285714	test_acc:0.478	test_f1:0.46694819463144815
epoch:4	train_loss:1.694888949394226	train_acc:0.6214285714285714	test_acc:0.301	test_f1:0.27974352771579397
epoch:5	train_loss:1.6922497749328613	train_acc:0.42142857142857143	test_acc:0.406	test_f1:0.41966922977599663
epoch:6	train_loss:1.5291224718093872	train_acc:0.5607142857142857	test_acc:0.603	test_f1:0.5488732890464914
epoch:7	train_loss:1.3239108324050903	train_acc:0.7642857142857142	test_acc:0.691	test_f1:0.589797866371974
epoch:8	train_loss:1.149198055267334	train_acc:0.7571428571428571	test_acc:0.764	test_f1:0.7272100537908205
epoch:9	train_loss:0.956913948059082	train_acc:0.8571428571428571	test_acc:0.802	test_f1:0.7857567399532419
epoch:10	train_loss:0.7744248509407043	train_acc:0.9178571428571428	test_acc:0.745	test_f1:0.7449100865776704
epoch:11	train_loss:0.6262500286102295	train_acc:0.9071428571428571	test_acc:0.762	test_f1:0.7626216284358689
epoch:12	train_loss:0.49895593523979187	train_acc:0.9	test_acc:0.816	test_f1:0.8091643048919087
epoch:13	train_loss:0.3843430280685425	train_acc:0.9357142857142857	test_acc:0.82	test_f1:0.8103182229073438
epoch:14	train_loss:0.3208022713661194	train_acc:0.9464285714285714	test_acc:0.814	test_f1:0.805133116962484
epoch:15	train_loss:0.2554289400577545	train_acc:0.9571428571428572	test_acc:0.811	test_f1:0.8041131251352531
epoch:16	train_loss:0.20868700742721558	train_acc:0.9642857142857143	test_acc:0.803	test_f1:0.7946706605147218
epoch:17	train_loss:0.17917859554290771	train_acc:0.9642857142857143	test_acc:0.808	test_f1:0.7989956882497795
epoch:18	train_loss:0.15820790827274323	train_acc:0.9607142857142857	test_acc:0.83	test_f1:0.8183163265440638
epoch:19	train_loss:0.12940797209739685	train_acc:0.9928571428571429	test_acc:0.83	test_f1:0.8176600935273148
epoch:20	train_loss:0.11764349043369293	train_acc:0.9928571428571429	test_acc:0.828	test_f1:0.8208216361530422
epoch:21	train_loss:0.10185185074806213	train_acc:1.0	test_acc:0.823	test_f1:0.8178087181963278
epoch:22	train_loss:0.09475077688694	train_acc:1.0	test_acc:0.819	test_f1:0.8162891557755894
epoch:23	train_loss:0.08454957604408264	train_acc:1.0	test_acc:0.821	test_f1:0.8173805762199988
epoch:24	train_loss:0.07708371430635452	train_acc:1.0	test_acc:0.824	test_f1:0.8180912434109643
epoch:25	train_loss:0.06819464266300201	train_acc:1.0	test_acc:0.821	test_f1:0.8104676134983869
epoch:26	train_loss:0.06354525685310364	train_acc:1.0	test_acc:0.829	test_f1:0.8171724577319203
epoch:27	train_loss:0.06577564775943756	train_acc:1.0	test_acc:0.826	test_f1:0.8129991375115019
epoch:28	train_loss:0.05729196220636368	train_acc:1.0	test_acc:0.833	test_f1:0.8233547772255986
epoch:29	train_loss:0.05768953263759613	train_acc:1.0	test_acc:0.825	test_f1:0.8184452557551813
epoch:30	train_loss:0.061704084277153015	train_acc:1.0	test_acc:0.828	test_f1:0.8221989197529977
epoch:31	train_loss:0.06287287920713425	train_acc:1.0	test_acc:0.823	test_f1:0.8135656980261755
epoch:32	train_loss:0.06323587894439697	train_acc:1.0	test_acc:0.827	test_f1:0.8157301166527905
epoch:33	train_loss:0.06688778847455978	train_acc:1.0	test_acc:0.822	test_f1:0.8139597945007665
epoch:34	train_loss:0.06724637001752853	train_acc:1.0	test_acc:0.823	test_f1:0.8158051768078127
epoch:35	train_loss:0.06990750879049301	train_acc:1.0	test_acc:0.835	test_f1:0.8274930466461681
epoch:36	train_loss:0.07053197175264359	train_acc:1.0	test_acc:0.832	test_f1:0.8230860165040179
epoch:37	train_loss:0.07032664865255356	train_acc:1.0	test_acc:0.823	test_f1:0.8135235170889766
epoch:38	train_loss:0.06762563437223434	train_acc:1.0	test_acc:0.815	test_f1:0.8052280647329343
epoch:39	train_loss:0.07673467695713043	train_acc:1.0	test_acc:0.83	test_f1:0.8222219833941317
epoch:40	train_loss:0.0719701275229454	train_acc:1.0	test_acc:0.832	test_f1:0.8238772673282663
epoch:41	train_loss:0.07104372978210449	train_acc:1.0	test_acc:0.831	test_f1:0.8229912258260941
epoch:42	train_loss:0.06555486470460892	train_acc:1.0	test_acc:0.828	test_f1:0.8197444338315322
epoch:43	train_loss:0.06235043704509735	train_acc:1.0	test_acc:0.822	test_f1:0.8133596117526414
epoch:44	train_loss:0.06585599482059479	train_acc:1.0	test_acc:0.831	test_f1:0.8223223739968807
epoch:45	train_loss:0.055120646953582764	train_acc:1.0	test_acc:0.842	test_f1:0.8313330367638733
epoch:46	train_loss:0.05766429752111435	train_acc:1.0	test_acc:0.836	test_f1:0.8267005187706395
epoch:47	train_loss:0.058260299265384674	train_acc:1.0	test_acc:0.826	test_f1:0.8199219166828365
epoch:48	train_loss:0.051620010286569595	train_acc:1.0	test_acc:0.832	test_f1:0.8235348308210902
epoch:49	train_loss:0.05214743688702583	train_acc:1.0	test_acc:0.84	test_f1:0.8297990148318055
epoch:50	train_loss:0.049755219370126724	train_acc:1.0	test_acc:0.84	test_f1:0.8306440421382428
训练并测试结束，共训练50轮，总用时201.20737171173096s
最佳正确率为:0.842,对应的macro_f1为:0.8313330367638733,对应的训练轮次为:45



2022-07-02 01:02:52.172098
epoch:1	train_loss:2.0068838596343994	train_acc:0.1357142857142857	test_acc:0.171	test_f1:0.1208417568628726
epoch:2	train_loss:2.245756149291992	train_acc:0.2642857142857143	test_acc:0.328	test_f1:0.30924660400629966
epoch:3	train_loss:1.8370414972305298	train_acc:0.525	test_acc:0.556	test_f1:0.5151355121018085
epoch:4	train_loss:1.6363455057144165	train_acc:0.7428571428571429	test_acc:0.47	test_f1:0.2849089938026394
epoch:5	train_loss:1.5718724727630615	train_acc:0.4035714285714286	test_acc:0.558	test_f1:0.4645466785410397
epoch:6	train_loss:1.4111685752868652	train_acc:0.5821428571428572	test_acc:0.749	test_f1:0.7215505819772672
epoch:7	train_loss:1.1851686239242554	train_acc:0.85	test_acc:0.702	test_f1:0.7080582126248121
epoch:8	train_loss:0.9786483645439148	train_acc:0.8928571428571429	test_acc:0.684	test_f1:0.6784510943662143
epoch:9	train_loss:0.8046471476554871	train_acc:0.8821428571428571	test_acc:0.752	test_f1:0.7412207542259434
epoch:10	train_loss:0.6351586580276489	train_acc:0.9178571428571428	test_acc:0.812	test_f1:0.8018231442048588
epoch:11	train_loss:0.48325660824775696	train_acc:0.925	test_acc:0.817	test_f1:0.8071489038618899
epoch:12	train_loss:0.37737545371055603	train_acc:0.9178571428571428	test_acc:0.822	test_f1:0.809038137314111
epoch:13	train_loss:0.30427902936935425	train_acc:0.9428571428571428	test_acc:0.824	test_f1:0.81196604970767
epoch:14	train_loss:0.24198438227176666	train_acc:0.9464285714285714	test_acc:0.823	test_f1:0.8114217037791313
epoch:15	train_loss:0.18049538135528564	train_acc:0.9642857142857143	test_acc:0.828	test_f1:0.8188270502698185
epoch:16	train_loss:0.1442803591489792	train_acc:0.9642857142857143	test_acc:0.827	test_f1:0.817398145485109
epoch:17	train_loss:0.11204499751329422	train_acc:0.9821428571428571	test_acc:0.828	test_f1:0.818301753494186
epoch:18	train_loss:0.08730913698673248	train_acc:0.9928571428571429	test_acc:0.825	test_f1:0.8174614670649504
epoch:19	train_loss:0.07158543914556503	train_acc:0.9928571428571429	test_acc:0.826	test_f1:0.8200047053258371
epoch:20	train_loss:0.056268345564603806	train_acc:1.0	test_acc:0.821	test_f1:0.8150620712699244
epoch:21	train_loss:0.04828312247991562	train_acc:1.0	test_acc:0.831	test_f1:0.8224894142829512
epoch:22	train_loss:0.03778007999062538	train_acc:1.0	test_acc:0.84	test_f1:0.8309454356881388
epoch:23	train_loss:0.036920901387929916	train_acc:1.0	test_acc:0.841	test_f1:0.8306782287666115
epoch:24	train_loss:0.03238173574209213	train_acc:1.0	test_acc:0.834	test_f1:0.8251905072477979
epoch:25	train_loss:0.030477527529001236	train_acc:1.0	test_acc:0.83	test_f1:0.8222662000961902
epoch:26	train_loss:0.030758384615182877	train_acc:1.0	test_acc:0.823	test_f1:0.8173684482001299
epoch:27	train_loss:0.02977048233151436	train_acc:1.0	test_acc:0.832	test_f1:0.8239885814672989
epoch:28	train_loss:0.03104225918650627	train_acc:1.0	test_acc:0.837	test_f1:0.8258102140896579
epoch:29	train_loss:0.032472968101501465	train_acc:1.0	test_acc:0.83	test_f1:0.8212825797922604
epoch:30	train_loss:0.03553234785795212	train_acc:1.0	test_acc:0.822	test_f1:0.8152710558798415
epoch:31	train_loss:0.03691898658871651	train_acc:1.0	test_acc:0.82	test_f1:0.8121396163872995
epoch:32	train_loss:0.039574187248945236	train_acc:1.0	test_acc:0.826	test_f1:0.8177190848539432
epoch:33	train_loss:0.048665229231119156	train_acc:1.0	test_acc:0.839	test_f1:0.8303498348027993
epoch:34	train_loss:0.045913856476545334	train_acc:1.0	test_acc:0.837	test_f1:0.8281787076459078
epoch:35	train_loss:0.05269717797636986	train_acc:1.0	test_acc:0.824	test_f1:0.8131295861094456
epoch:36	train_loss:0.04915766417980194	train_acc:1.0	test_acc:0.82	test_f1:0.8115211804710166
epoch:37	train_loss:0.056648679077625275	train_acc:1.0	test_acc:0.829	test_f1:0.8216937668747208
epoch:38	train_loss:0.0520947128534317	train_acc:1.0	test_acc:0.834	test_f1:0.8257576262747441
epoch:39	train_loss:0.05983787402510643	train_acc:1.0	test_acc:0.832	test_f1:0.8210467787671679
epoch:40	train_loss:0.0577634759247303	train_acc:1.0	test_acc:0.82	test_f1:0.810993523376467
epoch:41	train_loss:0.056500889360904694	train_acc:1.0	test_acc:0.814	test_f1:0.8103572192238041
epoch:42	train_loss:0.05503265932202339	train_acc:1.0	test_acc:0.834	test_f1:0.8248822815902527
epoch:43	train_loss:0.05002787709236145	train_acc:1.0	test_acc:0.836	test_f1:0.8249975366306356
epoch:44	train_loss:0.05340801924467087	train_acc:1.0	test_acc:0.831	test_f1:0.8230569048456102
epoch:45	train_loss:0.049257792532444	train_acc:1.0	test_acc:0.831	test_f1:0.8254505778439514
epoch:46	train_loss:0.04821743443608284	train_acc:1.0	test_acc:0.825	test_f1:0.8131416805677213
epoch:47	train_loss:0.052511006593704224	train_acc:1.0	test_acc:0.841	test_f1:0.8311297640598327
epoch:48	train_loss:0.04217775911092758	train_acc:1.0	test_acc:0.825	test_f1:0.8196843419463821
epoch:49	train_loss:0.04669477790594101	train_acc:1.0	test_acc:0.831	test_f1:0.8249157948369813
epoch:50	train_loss:0.043964896351099014	train_acc:1.0	test_acc:0.824	test_f1:0.8168636956548403
训练并测试结束，共训练50轮，总用时60.19347286224365s
最佳正确率为:0.841,对应的macro_f1为:0.8311297640598327,对应的训练轮次为:47



2022-07-02 01:04:49.361849
epoch:1	train_loss:2.0084340572357178	train_acc:0.14285714285714285	test_acc:0.266	test_f1:0.12106957921761453
epoch:2	train_loss:2.192337989807129	train_acc:0.23214285714285715	test_acc:0.224	test_f1:0.184841483835936
epoch:3	train_loss:1.941798210144043	train_acc:0.3357142857142857	test_acc:0.395	test_f1:0.32855561983676485
epoch:4	train_loss:1.6880040168762207	train_acc:0.5392857142857143	test_acc:0.454	test_f1:0.4941878180803849
epoch:5	train_loss:1.5224920511245728	train_acc:0.725	test_acc:0.218	test_f1:0.2443703247548697
epoch:6	train_loss:1.4138151407241821	train_acc:0.41785714285714287	test_acc:0.594	test_f1:0.6001686212248404
epoch:7	train_loss:1.2170857191085815	train_acc:0.7607142857142857	test_acc:0.803	test_f1:0.7800164023517946
epoch:8	train_loss:1.0081039667129517	train_acc:0.925	test_acc:0.766	test_f1:0.7435523420675454
epoch:9	train_loss:0.8204054236412048	train_acc:0.8785714285714286	test_acc:0.72	test_f1:0.7151533107295099
epoch:10	train_loss:0.6687076687812805	train_acc:0.875	test_acc:0.771	test_f1:0.766859426288477
epoch:11	train_loss:0.5093602538108826	train_acc:0.8964285714285715	test_acc:0.822	test_f1:0.8094012097876214
epoch:12	train_loss:0.3916473090648651	train_acc:0.9392857142857143	test_acc:0.82	test_f1:0.8043056484788424
epoch:13	train_loss:0.3196570873260498	train_acc:0.9428571428571428	test_acc:0.811	test_f1:0.7964156154974659
epoch:14	train_loss:0.2565303146839142	train_acc:0.9428571428571428	test_acc:0.804	test_f1:0.7949392082048259
epoch:15	train_loss:0.2092423290014267	train_acc:0.9535714285714286	test_acc:0.823	test_f1:0.8169170321099923
epoch:16	train_loss:0.16572506725788116	train_acc:0.9642857142857143	test_acc:0.829	test_f1:0.8225329652050731
epoch:17	train_loss:0.14243382215499878	train_acc:0.9785714285714285	test_acc:0.84	test_f1:0.830711446418662
epoch:18	train_loss:0.12552674114704132	train_acc:0.9857142857142858	test_acc:0.827	test_f1:0.8177494063535954
epoch:19	train_loss:0.10855968296527863	train_acc:0.9964285714285714	test_acc:0.824	test_f1:0.8159100493440752
epoch:20	train_loss:0.0927087590098381	train_acc:1.0	test_acc:0.813	test_f1:0.8075705513182857
epoch:21	train_loss:0.08253046870231628	train_acc:1.0	test_acc:0.814	test_f1:0.8067163582115514
epoch:22	train_loss:0.07595948874950409	train_acc:1.0	test_acc:0.815	test_f1:0.8058104500475941
epoch:23	train_loss:0.0706108808517456	train_acc:1.0	test_acc:0.826	test_f1:0.8168603332291077
epoch:24	train_loss:0.06412295252084732	train_acc:1.0	test_acc:0.829	test_f1:0.8210582149266382
epoch:25	train_loss:0.061427973210811615	train_acc:1.0	test_acc:0.83	test_f1:0.8242929666887745
epoch:26	train_loss:0.058066464960575104	train_acc:1.0	test_acc:0.82	test_f1:0.8129484097328402
epoch:27	train_loss:0.05523631349205971	train_acc:1.0	test_acc:0.808	test_f1:0.8004111634922262
epoch:28	train_loss:0.05854126438498497	train_acc:1.0	test_acc:0.813	test_f1:0.807004032096973
epoch:29	train_loss:0.05868956819176674	train_acc:1.0	test_acc:0.812	test_f1:0.8043708522836278
epoch:30	train_loss:0.060131557285785675	train_acc:1.0	test_acc:0.818	test_f1:0.8106013003709239
epoch:31	train_loss:0.061343736946582794	train_acc:1.0	test_acc:0.827	test_f1:0.8217767556787744
epoch:32	train_loss:0.06273313611745834	train_acc:1.0	test_acc:0.822	test_f1:0.8158535113998785
epoch:33	train_loss:0.07033772766590118	train_acc:1.0	test_acc:0.824	test_f1:0.8155723136372571
epoch:34	train_loss:0.07146046310663223	train_acc:1.0	test_acc:0.815	test_f1:0.806192523613908
epoch:35	train_loss:0.07505965232849121	train_acc:1.0	test_acc:0.811	test_f1:0.8030996584043483
epoch:36	train_loss:0.07048999518156052	train_acc:1.0	test_acc:0.822	test_f1:0.8141449866330401
epoch:37	train_loss:0.07220685482025146	train_acc:1.0	test_acc:0.834	test_f1:0.8241806646398386
epoch:38	train_loss:0.0690239816904068	train_acc:1.0	test_acc:0.829	test_f1:0.8196576869512916
epoch:39	train_loss:0.07023458927869797	train_acc:1.0	test_acc:0.813	test_f1:0.8054070774806744
epoch:40	train_loss:0.06919417530298233	train_acc:1.0	test_acc:0.819	test_f1:0.8103275370049986
epoch:41	train_loss:0.06331178545951843	train_acc:1.0	test_acc:0.828	test_f1:0.818250519082628
epoch:42	train_loss:0.060215063393116	train_acc:1.0	test_acc:0.834	test_f1:0.8255812799490716
epoch:43	train_loss:0.05963509529829025	train_acc:1.0	test_acc:0.827	test_f1:0.8186553813386868
epoch:44	train_loss:0.058014094829559326	train_acc:1.0	test_acc:0.824	test_f1:0.8166036880676284
epoch:45	train_loss:0.055079590529203415	train_acc:1.0	test_acc:0.826	test_f1:0.8151597344452408
epoch:46	train_loss:0.053343623876571655	train_acc:1.0	test_acc:0.832	test_f1:0.8201015544748221
epoch:47	train_loss:0.05354487895965576	train_acc:1.0	test_acc:0.826	test_f1:0.8168848525471714
epoch:48	train_loss:0.048756759613752365	train_acc:1.0	test_acc:0.821	test_f1:0.8160703986985025
epoch:49	train_loss:0.05057583004236221	train_acc:1.0	test_acc:0.826	test_f1:0.8169560790351527
epoch:50	train_loss:0.04906624183058739	train_acc:1.0	test_acc:0.825	test_f1:0.8133114045714657
训练并测试结束，共训练50轮，总用时159.12980389595032s
最佳正确率为:0.84,对应的macro_f1为:0.830711446418662,对应的训练轮次为:17



2022-07-02 01:08:11.450943
epoch:1	train_loss:1.9632127285003662	train_acc:0.1392857142857143	test_acc:0.103	test_f1:0.026680481802875276
epoch:2	train_loss:2.5253138542175293	train_acc:0.14285714285714285	test_acc:0.216	test_f1:0.15451876810068393
epoch:3	train_loss:1.7884328365325928	train_acc:0.3464285714285714	test_acc:0.363	test_f1:0.3462651610749683
epoch:4	train_loss:1.7377376556396484	train_acc:0.5535714285714286	test_acc:0.479	test_f1:0.36337973801326173
epoch:5	train_loss:1.7091482877731323	train_acc:0.475	test_acc:0.476	test_f1:0.37051432668096346
epoch:6	train_loss:1.567531943321228	train_acc:0.45	test_acc:0.701	test_f1:0.6240211148333665
epoch:7	train_loss:1.3581994771957397	train_acc:0.775	test_acc:0.706	test_f1:0.6699093663363017
epoch:8	train_loss:1.165289282798767	train_acc:0.8357142857142857	test_acc:0.667	test_f1:0.6832833181082459
epoch:9	train_loss:0.9967525005340576	train_acc:0.8892857142857142	test_acc:0.666	test_f1:0.697239413680924
epoch:10	train_loss:0.8217863440513611	train_acc:0.875	test_acc:0.765	test_f1:0.7700029791411731
epoch:11	train_loss:0.6525339484214783	train_acc:0.925	test_acc:0.817	test_f1:0.809749358713608
epoch:12	train_loss:0.5134389996528625	train_acc:0.9321428571428572	test_acc:0.814	test_f1:0.7956467876273524
epoch:13	train_loss:0.41907674074172974	train_acc:0.9285714285714286	test_acc:0.815	test_f1:0.8002369014393828
epoch:14	train_loss:0.32663339376449585	train_acc:0.9392857142857143	test_acc:0.822	test_f1:0.812390674024447
epoch:15	train_loss:0.2527655065059662	train_acc:0.95	test_acc:0.818	test_f1:0.8101812249849153
epoch:16	train_loss:0.20970332622528076	train_acc:0.9678571428571429	test_acc:0.805	test_f1:0.7984372102864953
epoch:17	train_loss:0.18333397805690765	train_acc:0.9714285714285714	test_acc:0.818	test_f1:0.8114493208848964
epoch:18	train_loss:0.14830121397972107	train_acc:0.9892857142857143	test_acc:0.837	test_f1:0.8289083873432311
epoch:19	train_loss:0.1276167631149292	train_acc:0.9892857142857143	test_acc:0.84	test_f1:0.8315045221635256
epoch:20	train_loss:0.11222193390130997	train_acc:0.9892857142857143	test_acc:0.85	test_f1:0.8393034992883396
epoch:21	train_loss:0.10147909820079803	train_acc:0.9928571428571429	test_acc:0.851	test_f1:0.8390146017215673
epoch:22	train_loss:0.09536156058311462	train_acc:0.9964285714285714	test_acc:0.836	test_f1:0.8268056897490142
epoch:23	train_loss:0.08191688358783722	train_acc:1.0	test_acc:0.824	test_f1:0.8144619865092245
epoch:24	train_loss:0.07437432557344437	train_acc:1.0	test_acc:0.823	test_f1:0.8151417280434492
epoch:25	train_loss:0.07061253488063812	train_acc:1.0	test_acc:0.832	test_f1:0.8233195778692933
epoch:26	train_loss:0.06577795743942261	train_acc:1.0	test_acc:0.842	test_f1:0.8347332688275212
epoch:27	train_loss:0.06571032106876373	train_acc:1.0	test_acc:0.843	test_f1:0.8350575880963004
epoch:28	train_loss:0.06263291835784912	train_acc:1.0	test_acc:0.838	test_f1:0.8284252875123247
epoch:29	train_loss:0.06038884446024895	train_acc:1.0	test_acc:0.834	test_f1:0.8240965838527629
epoch:30	train_loss:0.06249465048313141	train_acc:1.0	test_acc:0.825	test_f1:0.8145774341321385
epoch:31	train_loss:0.06174958124756813	train_acc:1.0	test_acc:0.821	test_f1:0.8109958222433014
epoch:32	train_loss:0.06453480571508408	train_acc:1.0	test_acc:0.828	test_f1:0.8216096523433372
epoch:33	train_loss:0.06494801491498947	train_acc:1.0	test_acc:0.835	test_f1:0.8308809422876372
epoch:34	train_loss:0.07117938250303268	train_acc:1.0	test_acc:0.837	test_f1:0.8296554070273275
epoch:35	train_loss:0.06915606558322906	train_acc:1.0	test_acc:0.834	test_f1:0.8212379901331196
epoch:36	train_loss:0.07494678348302841	train_acc:1.0	test_acc:0.825	test_f1:0.8165423910597622
epoch:37	train_loss:0.07277200371026993	train_acc:1.0	test_acc:0.827	test_f1:0.8188888887838087
epoch:38	train_loss:0.07425109297037125	train_acc:1.0	test_acc:0.834	test_f1:0.8259737849415403
epoch:39	train_loss:0.06951303035020828	train_acc:1.0	test_acc:0.835	test_f1:0.8264363205862885
epoch:40	train_loss:0.07302414625883102	train_acc:1.0	test_acc:0.832	test_f1:0.8245494608506924
epoch:41	train_loss:0.06935881078243256	train_acc:1.0	test_acc:0.827	test_f1:0.8151294014174466
epoch:42	train_loss:0.06559368222951889	train_acc:1.0	test_acc:0.83	test_f1:0.8159110652956107
epoch:43	train_loss:0.0683164894580841	train_acc:1.0	test_acc:0.833	test_f1:0.8265761078629265
epoch:44	train_loss:0.06557643413543701	train_acc:1.0	test_acc:0.837	test_f1:0.8328256237837464
epoch:45	train_loss:0.06288831681013107	train_acc:1.0	test_acc:0.833	test_f1:0.8221164694312693
epoch:46	train_loss:0.06460142880678177	train_acc:1.0	test_acc:0.83	test_f1:0.816608553906514
epoch:47	train_loss:0.05963669344782829	train_acc:1.0	test_acc:0.828	test_f1:0.8215633601644108
epoch:48	train_loss:0.055554281920194626	train_acc:1.0	test_acc:0.835	test_f1:0.8287977339989296
epoch:49	train_loss:0.05310673639178276	train_acc:1.0	test_acc:0.841	test_f1:0.8312431392620467
epoch:50	train_loss:0.05066712200641632	train_acc:1.0	test_acc:0.84	test_f1:0.8292010342910148
训练并测试结束，共训练50轮，总用时167.21473026275635s
最佳正确率为:0.851,对应的macro_f1为:0.8390146017215673,对应的训练轮次为:21



2022-07-02 01:12:19.424336
epoch:1	train_loss:1.9739371538162231	train_acc:0.14285714285714285	test_acc:0.144	test_f1:0.03596403596403597
epoch:2	train_loss:2.1458451747894287	train_acc:0.14285714285714285	test_acc:0.13	test_f1:0.03286978508217447
epoch:3	train_loss:1.9205679893493652	train_acc:0.15	test_acc:0.282	test_f1:0.2776349300193068
epoch:4	train_loss:1.652064561843872	train_acc:0.5142857142857142	test_acc:0.372	test_f1:0.3602446993110617
epoch:5	train_loss:1.4756821393966675	train_acc:0.6428571428571429	test_acc:0.304	test_f1:0.35757449039284056
epoch:6	train_loss:1.3050563335418701	train_acc:0.6142857142857143	test_acc:0.621	test_f1:0.5779943313508235
epoch:7	train_loss:1.1019095182418823	train_acc:0.8214285714285714	test_acc:0.678	test_f1:0.6313062645939812
epoch:8	train_loss:0.891575813293457	train_acc:0.8928571428571429	test_acc:0.8	test_f1:0.789906890436785
epoch:9	train_loss:0.6738317608833313	train_acc:0.9642857142857143	test_acc:0.733	test_f1:0.7405840759819254
epoch:10	train_loss:0.5176739692687988	train_acc:0.9714285714285714	test_acc:0.748	test_f1:0.7533136278115603
epoch:11	train_loss:0.3915373682975769	train_acc:0.9714285714285714	test_acc:0.796	test_f1:0.7899537218568058
epoch:12	train_loss:0.26799115538597107	train_acc:0.9857142857142858	test_acc:0.802	test_f1:0.7904162869789465
epoch:13	train_loss:0.20252500474452972	train_acc:0.9857142857142858	test_acc:0.802	test_f1:0.7940717592074572
epoch:14	train_loss:0.1511135995388031	train_acc:0.9857142857142858	test_acc:0.788	test_f1:0.7812665212860859
epoch:15	train_loss:0.10903506726026535	train_acc:0.9785714285714285	test_acc:0.771	test_f1:0.7687779554163179
epoch:16	train_loss:0.08346446603536606	train_acc:0.9857142857142858	test_acc:0.783	test_f1:0.7821689775086015
epoch:17	train_loss:0.05933704227209091	train_acc:0.9928571428571429	test_acc:0.785	test_f1:0.781371590119173
epoch:18	train_loss:0.04503308981657028	train_acc:1.0	test_acc:0.79	test_f1:0.782460521278887
epoch:19	train_loss:0.03420216217637062	train_acc:1.0	test_acc:0.801	test_f1:0.7970295356944737
epoch:20	train_loss:0.0289644543081522	train_acc:1.0	test_acc:0.791	test_f1:0.7837176373662322
epoch:21	train_loss:0.024726521223783493	train_acc:1.0	test_acc:0.79	test_f1:0.7819780497008059
epoch:22	train_loss:0.018934698775410652	train_acc:1.0	test_acc:0.774	test_f1:0.7676289256989666
epoch:23	train_loss:0.018306147307157516	train_acc:1.0	test_acc:0.768	test_f1:0.7609000888726831
epoch:24	train_loss:0.017632951959967613	train_acc:1.0	test_acc:0.768	test_f1:0.7644123645125827
epoch:25	train_loss:0.01829267479479313	train_acc:1.0	test_acc:0.773	test_f1:0.7686142096919656
epoch:26	train_loss:0.01795591600239277	train_acc:1.0	test_acc:0.783	test_f1:0.7761824439793045
epoch:27	train_loss:0.017777767032384872	train_acc:1.0	test_acc:0.794	test_f1:0.787074339625919
epoch:28	train_loss:0.020519040524959564	train_acc:1.0	test_acc:0.803	test_f1:0.7920746507412929
epoch:29	train_loss:0.02128925919532776	train_acc:1.0	test_acc:0.804	test_f1:0.7945857008085918
epoch:30	train_loss:0.02441454865038395	train_acc:1.0	test_acc:0.793	test_f1:0.7847287468132447
epoch:31	train_loss:0.024030635133385658	train_acc:1.0	test_acc:0.795	test_f1:0.7908907713696006
epoch:32	train_loss:0.029011812061071396	train_acc:1.0	test_acc:0.794	test_f1:0.7883155410206539
epoch:33	train_loss:0.03111361712217331	train_acc:1.0	test_acc:0.796	test_f1:0.7892579702101982
epoch:34	train_loss:0.036500535905361176	train_acc:1.0	test_acc:0.801	test_f1:0.79034913101668
epoch:35	train_loss:0.03716392442584038	train_acc:1.0	test_acc:0.791	test_f1:0.7791281017703804
epoch:36	train_loss:0.04040725529193878	train_acc:1.0	test_acc:0.788	test_f1:0.7787236751943679
epoch:37	train_loss:0.040083710104227066	train_acc:1.0	test_acc:0.791	test_f1:0.7817623975968123
epoch:38	train_loss:0.04368918389081955	train_acc:1.0	test_acc:0.8	test_f1:0.7887202202212975
epoch:39	train_loss:0.04141026362776756	train_acc:1.0	test_acc:0.797	test_f1:0.785313065462908
epoch:40	train_loss:0.0422600582242012	train_acc:1.0	test_acc:0.794	test_f1:0.784051763026444
epoch:41	train_loss:0.04474756121635437	train_acc:1.0	test_acc:0.796	test_f1:0.7842124974907883
epoch:42	train_loss:0.04328792542219162	train_acc:1.0	test_acc:0.796	test_f1:0.7837339590028235
epoch:43	train_loss:0.042541489005088806	train_acc:1.0	test_acc:0.792	test_f1:0.7811538504438273
epoch:44	train_loss:0.04282057657837868	train_acc:1.0	test_acc:0.794	test_f1:0.7855464192650625
epoch:45	train_loss:0.041104383766651154	train_acc:1.0	test_acc:0.79	test_f1:0.7791058920484348
epoch:46	train_loss:0.04231671616435051	train_acc:1.0	test_acc:0.795	test_f1:0.7841961206915122
epoch:47	train_loss:0.03812027350068092	train_acc:1.0	test_acc:0.791	test_f1:0.7793856208239441
epoch:48	train_loss:0.03600352257490158	train_acc:1.0	test_acc:0.79	test_f1:0.7761641885177525
epoch:49	train_loss:0.03693689778447151	train_acc:1.0	test_acc:0.794	test_f1:0.781599281317636
epoch:50	train_loss:0.03369441255927086	train_acc:1.0	test_acc:0.798	test_f1:0.7872042915985692
训练并测试结束，共训练50轮，总用时53.52649641036987s
最佳正确率为:0.804,对应的macro_f1为:0.7945857008085918,对应的训练轮次为:29



2022-07-02 01:17:34.198544
epoch:1	train_loss:2.021470308303833	train_acc:0.14285714285714285	test_acc:0.213	test_f1:0.13056622804758017
epoch:2	train_loss:2.166390895843506	train_acc:0.25	test_acc:0.093	test_f1:0.027960901770756035
epoch:3	train_loss:1.8027215003967285	train_acc:0.15	test_acc:0.241	test_f1:0.29727344549491824
epoch:4	train_loss:1.558353304862976	train_acc:0.6	test_acc:0.46	test_f1:0.34201435861913815
epoch:5	train_loss:1.4254090785980225	train_acc:0.55	test_acc:0.493	test_f1:0.40511096869945
epoch:6	train_loss:1.2477335929870605	train_acc:0.6	test_acc:0.717	test_f1:0.6886872768756067
epoch:7	train_loss:1.0007414817810059	train_acc:0.9071428571428571	test_acc:0.743	test_f1:0.7454818060924315
epoch:8	train_loss:0.7720832228660583	train_acc:0.9642857142857143	test_acc:0.68	test_f1:0.6898750576606476
epoch:9	train_loss:0.5976042747497559	train_acc:0.95	test_acc:0.721	test_f1:0.7145886667292823
epoch:10	train_loss:0.4586736857891083	train_acc:0.9571428571428572	test_acc:0.772	test_f1:0.7619705584565095
epoch:11	train_loss:0.33053135871887207	train_acc:0.9642857142857143	test_acc:0.795	test_f1:0.7803152413461374
epoch:12	train_loss:0.2369476705789566	train_acc:0.9785714285714285	test_acc:0.8	test_f1:0.7889120212822814
epoch:13	train_loss:0.17419901490211487	train_acc:0.9928571428571429	test_acc:0.776	test_f1:0.7668060475216408
epoch:14	train_loss:0.1346680372953415	train_acc:0.9857142857142858	test_acc:0.769	test_f1:0.7593896113715273
epoch:15	train_loss:0.10526981204748154	train_acc:0.9928571428571429	test_acc:0.773	test_f1:0.7597705965556611
epoch:16	train_loss:0.09143458306789398	train_acc:0.9928571428571429	test_acc:0.785	test_f1:0.7674725615473043
epoch:17	train_loss:0.07599786669015884	train_acc:1.0	test_acc:0.786	test_f1:0.7672451509504213
epoch:18	train_loss:0.06749284267425537	train_acc:1.0	test_acc:0.773	test_f1:0.7589053719380409
epoch:19	train_loss:0.060711316764354706	train_acc:1.0	test_acc:0.772	test_f1:0.7597647057418176
epoch:20	train_loss:0.057164959609508514	train_acc:1.0	test_acc:0.771	test_f1:0.7626799472969736
epoch:21	train_loss:0.052378132939338684	train_acc:1.0	test_acc:0.777	test_f1:0.7701821147908765
epoch:22	train_loss:0.0477571040391922	train_acc:1.0	test_acc:0.784	test_f1:0.7754745568045168
epoch:23	train_loss:0.043517280369997025	train_acc:1.0	test_acc:0.784	test_f1:0.7740360674223774
epoch:24	train_loss:0.04060141742229462	train_acc:1.0	test_acc:0.779	test_f1:0.7699307994952587
epoch:25	train_loss:0.03832820802927017	train_acc:1.0	test_acc:0.784	test_f1:0.7769316764518329
epoch:26	train_loss:0.038391128182411194	train_acc:1.0	test_acc:0.783	test_f1:0.7745952792216743
epoch:27	train_loss:0.03759877383708954	train_acc:1.0	test_acc:0.772	test_f1:0.7593893639424102
epoch:28	train_loss:0.037924569100141525	train_acc:1.0	test_acc:0.769	test_f1:0.7551012521650933
epoch:29	train_loss:0.04143678396940231	train_acc:1.0	test_acc:0.772	test_f1:0.7597361767938674
epoch:30	train_loss:0.044168293476104736	train_acc:1.0	test_acc:0.775	test_f1:0.764001713635966
epoch:31	train_loss:0.045252811163663864	train_acc:1.0	test_acc:0.781	test_f1:0.7719152900836483
epoch:32	train_loss:0.048879481852054596	train_acc:1.0	test_acc:0.787	test_f1:0.7751901628495643
epoch:33	train_loss:0.05235539749264717	train_acc:1.0	test_acc:0.782	test_f1:0.7708184046570182
epoch:34	train_loss:0.0550694577395916	train_acc:1.0	test_acc:0.785	test_f1:0.7731765016703326
epoch:35	train_loss:0.05566997453570366	train_acc:1.0	test_acc:0.784	test_f1:0.7721477910859148
epoch:36	train_loss:0.05996673181653023	train_acc:1.0	test_acc:0.78	test_f1:0.7657500851152158
epoch:37	train_loss:0.0596364289522171	train_acc:1.0	test_acc:0.797	test_f1:0.7791352635277148
epoch:38	train_loss:0.060045816004276276	train_acc:1.0	test_acc:0.792	test_f1:0.7831720354686161
epoch:39	train_loss:0.06296206265687943	train_acc:1.0	test_acc:0.783	test_f1:0.7757876367267118
epoch:40	train_loss:0.058585070073604584	train_acc:1.0	test_acc:0.772	test_f1:0.757172038504918
epoch:41	train_loss:0.05529116094112396	train_acc:1.0	test_acc:0.783	test_f1:0.7705707115459116
epoch:42	train_loss:0.04684946686029434	train_acc:1.0	test_acc:0.791	test_f1:0.7801897977098703
epoch:43	train_loss:0.05018165707588196	train_acc:1.0	test_acc:0.794	test_f1:0.7863240416204621
epoch:44	train_loss:0.043727148324251175	train_acc:1.0	test_acc:0.785	test_f1:0.7734739827408352
epoch:45	train_loss:0.046278372406959534	train_acc:1.0	test_acc:0.785	test_f1:0.7708149492311758
epoch:46	train_loss:0.03976573050022125	train_acc:1.0	test_acc:0.787	test_f1:0.7716601567250275
epoch:47	train_loss:0.036892909556627274	train_acc:1.0	test_acc:0.786	test_f1:0.775914408581735
epoch:48	train_loss:0.039763204753398895	train_acc:1.0	test_acc:0.782	test_f1:0.77118316997184
epoch:49	train_loss:0.035866718739271164	train_acc:1.0	test_acc:0.784	test_f1:0.7720393278528573
epoch:50	train_loss:0.03502481058239937	train_acc:1.0	test_acc:0.789	test_f1:0.7757284467287301
训练并测试结束，共训练50轮，总用时155.20457816123962s
最佳正确率为:0.8,对应的macro_f1为:0.7889120212822814,对应的训练轮次为:12



2022-07-02 01:20:27.043549
epoch:1	train_loss:1.9761216640472412	train_acc:0.14285714285714285	test_acc:0.174	test_f1:0.09393157760545541
epoch:2	train_loss:2.1531386375427246	train_acc:0.2785714285714286	test_acc:0.319	test_f1:0.21250936764258258
epoch:3	train_loss:1.9234026670455933	train_acc:0.45	test_acc:0.284	test_f1:0.2760545719583534
epoch:4	train_loss:1.5658543109893799	train_acc:0.5071428571428571	test_acc:0.24	test_f1:0.24708893075187865
epoch:5	train_loss:1.396328330039978	train_acc:0.5214285714285715	test_acc:0.276	test_f1:0.29112873119973204
epoch:6	train_loss:1.251287817955017	train_acc:0.5857142857142857	test_acc:0.69	test_f1:0.6679559394097161
epoch:7	train_loss:1.0234148502349854	train_acc:0.9285714285714286	test_acc:0.784	test_f1:0.7650500571210266
epoch:8	train_loss:0.7867555022239685	train_acc:0.9428571428571428	test_acc:0.779	test_f1:0.7632001409606373
epoch:9	train_loss:0.6028980016708374	train_acc:0.9571428571428572	test_acc:0.721	test_f1:0.7131892698313586
epoch:10	train_loss:0.4745268225669861	train_acc:0.9571428571428572	test_acc:0.755	test_f1:0.7511676506453584
epoch:11	train_loss:0.33724597096443176	train_acc:0.9714285714285714	test_acc:0.794	test_f1:0.7865375704672947
epoch:12	train_loss:0.23042552173137665	train_acc:0.9785714285714285	test_acc:0.795	test_f1:0.7852778597501745
epoch:13	train_loss:0.17464299499988556	train_acc:0.9857142857142858	test_acc:0.789	test_f1:0.7806912940550557
epoch:14	train_loss:0.1440746933221817	train_acc:0.9857142857142858	test_acc:0.771	test_f1:0.7677087862947812
epoch:15	train_loss:0.11224319785833359	train_acc:0.9857142857142858	test_acc:0.77	test_f1:0.7695531439418526
epoch:16	train_loss:0.08740071952342987	train_acc:0.9928571428571429	test_acc:0.768	test_f1:0.7661008664990963
epoch:17	train_loss:0.07314993441104889	train_acc:0.9928571428571429	test_acc:0.768	test_f1:0.7603466425854314
epoch:18	train_loss:0.06296662986278534	train_acc:0.9928571428571429	test_acc:0.773	test_f1:0.7611258188780023
epoch:19	train_loss:0.05977821722626686	train_acc:0.9928571428571429	test_acc:0.785	test_f1:0.771190180120002
epoch:20	train_loss:0.05416592210531235	train_acc:1.0	test_acc:0.793	test_f1:0.7797029559783617
epoch:21	train_loss:0.05021467059850693	train_acc:1.0	test_acc:0.79	test_f1:0.779324757111661
epoch:22	train_loss:0.04597127437591553	train_acc:1.0	test_acc:0.788	test_f1:0.781331093726444
epoch:23	train_loss:0.04114701598882675	train_acc:1.0	test_acc:0.777	test_f1:0.7727598907466894
epoch:24	train_loss:0.042068079113960266	train_acc:1.0	test_acc:0.776	test_f1:0.7694081085228515
epoch:25	train_loss:0.04171202704310417	train_acc:1.0	test_acc:0.787	test_f1:0.7806189043972092
epoch:26	train_loss:0.03610796108841896	train_acc:1.0	test_acc:0.792	test_f1:0.785154627255222
epoch:27	train_loss:0.03669023513793945	train_acc:1.0	test_acc:0.787	test_f1:0.7809572107555126
epoch:28	train_loss:0.037261612713336945	train_acc:1.0	test_acc:0.782	test_f1:0.7743710005195776
epoch:29	train_loss:0.040378790348768234	train_acc:1.0	test_acc:0.776	test_f1:0.7689113569607049
epoch:30	train_loss:0.039626576006412506	train_acc:1.0	test_acc:0.773	test_f1:0.764399160274824
epoch:31	train_loss:0.04554254189133644	train_acc:1.0	test_acc:0.782	test_f1:0.7704089598319219
epoch:32	train_loss:0.04711760953068733	train_acc:1.0	test_acc:0.791	test_f1:0.779229578680438
epoch:33	train_loss:0.05349878594279289	train_acc:1.0	test_acc:0.789	test_f1:0.7797603927835944
epoch:34	train_loss:0.05499788373708725	train_acc:1.0	test_acc:0.788	test_f1:0.7791993876555535
epoch:35	train_loss:0.05613427236676216	train_acc:1.0	test_acc:0.783	test_f1:0.7721011377423661
epoch:36	train_loss:0.055214159190654755	train_acc:1.0	test_acc:0.798	test_f1:0.7805317587402527
epoch:37	train_loss:0.06065800413489342	train_acc:1.0	test_acc:0.8	test_f1:0.7851567977840851
epoch:38	train_loss:0.05982605367898941	train_acc:1.0	test_acc:0.781	test_f1:0.7748940178375762
epoch:39	train_loss:0.056479889899492264	train_acc:1.0	test_acc:0.786	test_f1:0.7782302315662994
epoch:40	train_loss:0.052856143563985825	train_acc:1.0	test_acc:0.796	test_f1:0.7835567229443995
epoch:41	train_loss:0.05573233589529991	train_acc:1.0	test_acc:0.799	test_f1:0.7854100158936006
epoch:42	train_loss:0.04959738254547119	train_acc:1.0	test_acc:0.784	test_f1:0.7727833176200163
epoch:43	train_loss:0.048774294555187225	train_acc:1.0	test_acc:0.782	test_f1:0.7742136757966428
epoch:44	train_loss:0.04605986922979355	train_acc:1.0	test_acc:0.792	test_f1:0.7838821274399496
epoch:45	train_loss:0.04498405009508133	train_acc:1.0	test_acc:0.804	test_f1:0.790659879060706
epoch:46	train_loss:0.03966482728719711	train_acc:1.0	test_acc:0.799	test_f1:0.7838257264962215
epoch:47	train_loss:0.040839578956365585	train_acc:1.0	test_acc:0.791	test_f1:0.7764714823235719
epoch:48	train_loss:0.039273399859666824	train_acc:1.0	test_acc:0.779	test_f1:0.7710734055071997
epoch:49	train_loss:0.035805054008960724	train_acc:1.0	test_acc:0.782	test_f1:0.7741651938919463
epoch:50	train_loss:0.03783572465181351	train_acc:1.0	test_acc:0.795	test_f1:0.7835394114306155
训练并测试结束，共训练50轮，总用时153.8695683479309s
最佳正确率为:0.804,对应的macro_f1为:0.790659879060706,对应的训练轮次为:45



2022-07-02 01:23:48.637937
epoch:1	train_loss:1.988320231437683	train_acc:0.14285714285714285	test_acc:0.322	test_f1:0.07570217336654707
epoch:2	train_loss:2.1582562923431396	train_acc:0.17857142857142858	test_acc:0.249	test_f1:0.2140295711356586
epoch:3	train_loss:1.8498203754425049	train_acc:0.4142857142857143	test_acc:0.143	test_f1:0.15943887157202877
epoch:4	train_loss:1.6502857208251953	train_acc:0.37142857142857144	test_acc:0.256	test_f1:0.30521994376559153
epoch:5	train_loss:1.4875128269195557	train_acc:0.5857142857142857	test_acc:0.197	test_f1:0.24724980131724386
epoch:6	train_loss:1.327391505241394	train_acc:0.5214285714285715	test_acc:0.639	test_f1:0.6369299069918751
epoch:7	train_loss:1.0971957445144653	train_acc:0.9285714285714286	test_acc:0.756	test_f1:0.7413843726679937
epoch:8	train_loss:0.8867368698120117	train_acc:0.9428571428571428	test_acc:0.736	test_f1:0.7300248660401498
epoch:9	train_loss:0.6942881345748901	train_acc:0.9571428571428572	test_acc:0.767	test_f1:0.7567270369743146
epoch:10	train_loss:0.5194751620292664	train_acc:0.9642857142857143	test_acc:0.791	test_f1:0.7797042235965501
epoch:11	train_loss:0.3694019615650177	train_acc:0.9714285714285714	test_acc:0.759	test_f1:0.7520401562343568
epoch:12	train_loss:0.266110897064209	train_acc:0.9785714285714285	test_acc:0.741	test_f1:0.7297019301996338
epoch:13	train_loss:0.1906101107597351	train_acc:0.9785714285714285	test_acc:0.757	test_f1:0.7475748215732592
epoch:14	train_loss:0.1310475468635559	train_acc:0.9857142857142858	test_acc:0.767	test_f1:0.758651592929764
epoch:15	train_loss:0.09902645647525787	train_acc:1.0	test_acc:0.781	test_f1:0.7743869776099946
epoch:16	train_loss:0.07085960358381271	train_acc:1.0	test_acc:0.794	test_f1:0.7846141235759773
epoch:17	train_loss:0.04917744919657707	train_acc:1.0	test_acc:0.793	test_f1:0.7836919701006708
epoch:18	train_loss:0.035388655960559845	train_acc:1.0	test_acc:0.784	test_f1:0.7754168340427466
epoch:19	train_loss:0.030228134244680405	train_acc:1.0	test_acc:0.777	test_f1:0.7682168503079856
epoch:20	train_loss:0.022306328639388084	train_acc:1.0	test_acc:0.772	test_f1:0.7655626171033001
epoch:21	train_loss:0.0186007097363472	train_acc:1.0	test_acc:0.769	test_f1:0.7622258703622784
epoch:22	train_loss:0.017142044380307198	train_acc:1.0	test_acc:0.776	test_f1:0.7686413448044835
epoch:23	train_loss:0.016032015904784203	train_acc:1.0	test_acc:0.783	test_f1:0.7758784978918991
epoch:24	train_loss:0.014066130854189396	train_acc:1.0	test_acc:0.791	test_f1:0.7837719302295347
epoch:25	train_loss:0.015626568347215652	train_acc:1.0	test_acc:0.796	test_f1:0.7869437498528106
epoch:26	train_loss:0.016894910484552383	train_acc:1.0	test_acc:0.795	test_f1:0.7842842836719568
epoch:27	train_loss:0.018322568386793137	train_acc:1.0	test_acc:0.785	test_f1:0.776146664709108
epoch:28	train_loss:0.01842874474823475	train_acc:1.0	test_acc:0.783	test_f1:0.7732608765542454
epoch:29	train_loss:0.021732455119490623	train_acc:1.0	test_acc:0.781	test_f1:0.7711387602673412
epoch:30	train_loss:0.023569349199533463	train_acc:1.0	test_acc:0.784	test_f1:0.7773639336160317
epoch:31	train_loss:0.026706017553806305	train_acc:1.0	test_acc:0.788	test_f1:0.7777940704269566
epoch:32	train_loss:0.026294812560081482	train_acc:1.0	test_acc:0.799	test_f1:0.785052641493144
epoch:33	train_loss:0.030926046893000603	train_acc:1.0	test_acc:0.795	test_f1:0.7823028814281081
epoch:34	train_loss:0.03756719082593918	train_acc:1.0	test_acc:0.788	test_f1:0.7749680153920311
epoch:35	train_loss:0.036828406155109406	train_acc:1.0	test_acc:0.785	test_f1:0.7743892577951668
epoch:36	train_loss:0.04471389204263687	train_acc:1.0	test_acc:0.789	test_f1:0.780934524322275
epoch:37	train_loss:0.0426153838634491	train_acc:1.0	test_acc:0.793	test_f1:0.7837000848870955
epoch:38	train_loss:0.04520173370838165	train_acc:1.0	test_acc:0.796	test_f1:0.7846004467667023
epoch:39	train_loss:0.047529228031635284	train_acc:1.0	test_acc:0.793	test_f1:0.7832117616520827
epoch:40	train_loss:0.042782630771398544	train_acc:1.0	test_acc:0.79	test_f1:0.7790643797060132
epoch:41	train_loss:0.045936889946460724	train_acc:1.0	test_acc:0.788	test_f1:0.7783791672699983
epoch:42	train_loss:0.04460649564862251	train_acc:1.0	test_acc:0.791	test_f1:0.7789243187367598
epoch:43	train_loss:0.04614919796586037	train_acc:1.0	test_acc:0.797	test_f1:0.7846108055498887
epoch:44	train_loss:0.04050963744521141	train_acc:1.0	test_acc:0.796	test_f1:0.7875330078539095
epoch:45	train_loss:0.04163435101509094	train_acc:1.0	test_acc:0.801	test_f1:0.791392091608772
epoch:46	train_loss:0.03633645921945572	train_acc:1.0	test_acc:0.79	test_f1:0.7762513093421735
epoch:47	train_loss:0.040052589029073715	train_acc:1.0	test_acc:0.788	test_f1:0.775550706165775
epoch:48	train_loss:0.032731715589761734	train_acc:1.0	test_acc:0.789	test_f1:0.7739673803229447
epoch:49	train_loss:0.03546488657593727	train_acc:1.0	test_acc:0.795	test_f1:0.7794846021162521
epoch:50	train_loss:0.03400491550564766	train_acc:1.0	test_acc:0.806	test_f1:0.7949872015469575
训练并测试结束，共训练50轮，总用时60.48776817321777s
最佳正确率为:0.806,对应的macro_f1为:0.7949872015469575,对应的训练轮次为:50



2022-07-02 01:25:29.487212
epoch:1	train_loss:1.9863463640213013	train_acc:0.12857142857142856	test_acc:0.109	test_f1:0.0356311851602037
epoch:2	train_loss:2.215972661972046	train_acc:0.16428571428571428	test_acc:0.092	test_f1:0.08327533320788681
epoch:3	train_loss:1.9079954624176025	train_acc:0.22142857142857142	test_acc:0.215	test_f1:0.21372609708363427
epoch:4	train_loss:1.5951679944992065	train_acc:0.4357142857142857	test_acc:0.362	test_f1:0.31189638005364434
epoch:5	train_loss:1.47614324092865	train_acc:0.5357142857142857	test_acc:0.321	test_f1:0.2663661734438673
epoch:6	train_loss:1.3370474576950073	train_acc:0.4857142857142857	test_acc:0.565	test_f1:0.5572439769947624
epoch:7	train_loss:1.0934792757034302	train_acc:0.8428571428571429	test_acc:0.775	test_f1:0.7683967464335649
epoch:8	train_loss:0.8583666682243347	train_acc:0.9642857142857143	test_acc:0.774	test_f1:0.7573871778913625
epoch:9	train_loss:0.6776420474052429	train_acc:0.9714285714285714	test_acc:0.735	test_f1:0.7255157907534489
epoch:10	train_loss:0.5130730867385864	train_acc:0.9714285714285714	test_acc:0.759	test_f1:0.7507025921615876
epoch:11	train_loss:0.3672780990600586	train_acc:0.9714285714285714	test_acc:0.791	test_f1:0.7818345023585168
epoch:12	train_loss:0.25934699177742004	train_acc:0.9857142857142858	test_acc:0.792	test_f1:0.7861631135780657
epoch:13	train_loss:0.1952860802412033	train_acc:0.9857142857142858	test_acc:0.783	test_f1:0.776869481524928
epoch:14	train_loss:0.15439915657043457	train_acc:0.9857142857142858	test_acc:0.8	test_f1:0.7918355361421907
epoch:15	train_loss:0.11420693248510361	train_acc:0.9928571428571429	test_acc:0.8	test_f1:0.7899678343526758
epoch:16	train_loss:0.09119728207588196	train_acc:0.9857142857142858	test_acc:0.797	test_f1:0.7866122267966337
epoch:17	train_loss:0.07926066219806671	train_acc:0.9857142857142858	test_acc:0.784	test_f1:0.771885071383531
epoch:18	train_loss:0.06796948611736298	train_acc:1.0	test_acc:0.772	test_f1:0.76084846308261
epoch:19	train_loss:0.0605509877204895	train_acc:1.0	test_acc:0.764	test_f1:0.7551031006660024
epoch:20	train_loss:0.054934754967689514	train_acc:1.0	test_acc:0.757	test_f1:0.7481333598821728
epoch:21	train_loss:0.05037715286016464	train_acc:1.0	test_acc:0.77	test_f1:0.7592365348969121
epoch:22	train_loss:0.04583550617098808	train_acc:1.0	test_acc:0.777	test_f1:0.7674112758903605
epoch:23	train_loss:0.04166851192712784	train_acc:1.0	test_acc:0.788	test_f1:0.7751665274919333
epoch:24	train_loss:0.039182066917419434	train_acc:1.0	test_acc:0.79	test_f1:0.7796698882787715
epoch:25	train_loss:0.0391545295715332	train_acc:1.0	test_acc:0.79	test_f1:0.7804447029095052
epoch:26	train_loss:0.03694366663694382	train_acc:1.0	test_acc:0.781	test_f1:0.7738435918996275
epoch:27	train_loss:0.03730025142431259	train_acc:1.0	test_acc:0.774	test_f1:0.766487173449489
epoch:28	train_loss:0.038156501948833466	train_acc:1.0	test_acc:0.776	test_f1:0.768898760718358
epoch:29	train_loss:0.039502911269664764	train_acc:1.0	test_acc:0.782	test_f1:0.7769562303000297
epoch:30	train_loss:0.04064914211630821	train_acc:1.0	test_acc:0.79	test_f1:0.7843144492514702
epoch:31	train_loss:0.04348120465874672	train_acc:1.0	test_acc:0.794	test_f1:0.7842767835419082
epoch:32	train_loss:0.04575899988412857	train_acc:1.0	test_acc:0.788	test_f1:0.7783931351481572
epoch:33	train_loss:0.05060531944036484	train_acc:1.0	test_acc:0.784	test_f1:0.7743158086732433
epoch:34	train_loss:0.052356868982315063	train_acc:1.0	test_acc:0.776	test_f1:0.7666505795188038
epoch:35	train_loss:0.05978309363126755	train_acc:1.0	test_acc:0.789	test_f1:0.771632288684377
epoch:36	train_loss:0.05764912813901901	train_acc:1.0	test_acc:0.777	test_f1:0.7683996678821113
epoch:37	train_loss:0.05530187860131264	train_acc:1.0	test_acc:0.785	test_f1:0.7780485603777297
epoch:38	train_loss:0.0539143867790699	train_acc:1.0	test_acc:0.796	test_f1:0.7830495612678854
epoch:39	train_loss:0.054747164249420166	train_acc:1.0	test_acc:0.804	test_f1:0.7928133800565877
epoch:40	train_loss:0.059541672468185425	train_acc:1.0	test_acc:0.788	test_f1:0.7817446749397686
epoch:41	train_loss:0.052941229194402695	train_acc:1.0	test_acc:0.782	test_f1:0.779007103322877
epoch:42	train_loss:0.05185071378946304	train_acc:1.0	test_acc:0.792	test_f1:0.7753602280279582
epoch:43	train_loss:0.052358515560626984	train_acc:1.0	test_acc:0.796	test_f1:0.7779664120466674
epoch:44	train_loss:0.04925141856074333	train_acc:1.0	test_acc:0.786	test_f1:0.776691764392843
epoch:45	train_loss:0.04287390783429146	train_acc:1.0	test_acc:0.783	test_f1:0.7749578528819251
epoch:46	train_loss:0.04054289311170578	train_acc:1.0	test_acc:0.793	test_f1:0.7816121841490087
epoch:47	train_loss:0.03698104992508888	train_acc:1.0	test_acc:0.794	test_f1:0.7813983489957986
epoch:48	train_loss:0.0391499362885952	train_acc:1.0	test_acc:0.791	test_f1:0.7788895803805759
epoch:49	train_loss:0.03604036942124367	train_acc:1.0	test_acc:0.789	test_f1:0.7842194741849767
epoch:50	train_loss:0.04040263965725899	train_acc:1.0	test_acc:0.798	test_f1:0.7860131186063434
训练并测试结束，共训练50轮，总用时158.92756605148315s
最佳正确率为:0.804,对应的macro_f1为:0.7928133800565877,对应的训练轮次为:39



2022-07-02 01:28:25.455642
epoch:1	train_loss:2.0378944873809814	train_acc:0.14285714285714285	test_acc:0.149	test_f1:0.03705085167226159
epoch:2	train_loss:2.2625458240509033	train_acc:0.17142857142857143	test_acc:0.134	test_f1:0.13744149571307193
epoch:3	train_loss:1.8940457105636597	train_acc:0.36428571428571427	test_acc:0.257	test_f1:0.20859365617129594
epoch:4	train_loss:1.677829623222351	train_acc:0.4714285714285714	test_acc:0.57	test_f1:0.4334379385050507
epoch:5	train_loss:1.53159761428833	train_acc:0.6857142857142857	test_acc:0.453	test_f1:0.33397377076169193
epoch:6	train_loss:1.3938288688659668	train_acc:0.5214285714285715	test_acc:0.626	test_f1:0.5966276486970828
epoch:7	train_loss:1.170979619026184	train_acc:0.8	test_acc:0.721	test_f1:0.7416148433743187
epoch:8	train_loss:0.9426032900810242	train_acc:0.9571428571428572	test_acc:0.588	test_f1:0.6211285368328558
epoch:9	train_loss:0.7659013867378235	train_acc:0.8928571428571429	test_acc:0.625	test_f1:0.6528099130654412
epoch:10	train_loss:0.5921483635902405	train_acc:0.9142857142857143	test_acc:0.762	test_f1:0.7611119616097309
epoch:11	train_loss:0.42850181460380554	train_acc:0.9714285714285714	test_acc:0.8	test_f1:0.7841573437346145
epoch:12	train_loss:0.32462674379348755	train_acc:0.9714285714285714	test_acc:0.788	test_f1:0.7712679638422835
epoch:13	train_loss:0.24095435440540314	train_acc:0.9785714285714285	test_acc:0.794	test_f1:0.7850151572175958
epoch:14	train_loss:0.17285847663879395	train_acc:0.9857142857142858	test_acc:0.762	test_f1:0.7640422864853366
epoch:15	train_loss:0.13619385659694672	train_acc:0.9857142857142858	test_acc:0.759	test_f1:0.7556633259119844
epoch:16	train_loss:0.11050020903348923	train_acc:0.9928571428571429	test_acc:0.779	test_f1:0.7667543409917368
epoch:17	train_loss:0.08529189229011536	train_acc:0.9928571428571429	test_acc:0.801	test_f1:0.7856898719754264
epoch:18	train_loss:0.0719660297036171	train_acc:1.0	test_acc:0.814	test_f1:0.7996174034140203
epoch:19	train_loss:0.06289446353912354	train_acc:1.0	test_acc:0.816	test_f1:0.8036124491316363
epoch:20	train_loss:0.05633755028247833	train_acc:1.0	test_acc:0.805	test_f1:0.7973388544864398
epoch:21	train_loss:0.050581857562065125	train_acc:1.0	test_acc:0.806	test_f1:0.7973629635297963
epoch:22	train_loss:0.04870755225419998	train_acc:1.0	test_acc:0.796	test_f1:0.7909871247917392
epoch:23	train_loss:0.04591118544340134	train_acc:1.0	test_acc:0.796	test_f1:0.7888713977080702
epoch:24	train_loss:0.03948729857802391	train_acc:1.0	test_acc:0.786	test_f1:0.7762175858730426
epoch:25	train_loss:0.037164606153964996	train_acc:1.0	test_acc:0.781	test_f1:0.7671317145350259
epoch:26	train_loss:0.035033680498600006	train_acc:1.0	test_acc:0.778	test_f1:0.762012787185294
epoch:27	train_loss:0.03688813000917435	train_acc:1.0	test_acc:0.777	test_f1:0.7624236286487888
epoch:28	train_loss:0.0363941416144371	train_acc:1.0	test_acc:0.781	test_f1:0.7689904848773701
epoch:29	train_loss:0.03552505373954773	train_acc:1.0	test_acc:0.792	test_f1:0.7836270562751088
epoch:30	train_loss:0.036215201020240784	train_acc:1.0	test_acc:0.795	test_f1:0.7872945780365972
epoch:31	train_loss:0.04044099152088165	train_acc:1.0	test_acc:0.8	test_f1:0.7907849439969471
epoch:32	train_loss:0.044369716197252274	train_acc:1.0	test_acc:0.797	test_f1:0.7819720304699288
epoch:33	train_loss:0.04466972500085831	train_acc:1.0	test_acc:0.793	test_f1:0.7760043584343482
epoch:34	train_loss:0.04877374693751335	train_acc:1.0	test_acc:0.778	test_f1:0.7610267645246137
epoch:35	train_loss:0.05326469615101814	train_acc:1.0	test_acc:0.779	test_f1:0.7684310161276298
epoch:36	train_loss:0.05607279762625694	train_acc:1.0	test_acc:0.791	test_f1:0.782089639369012
epoch:37	train_loss:0.05733779817819595	train_acc:1.0	test_acc:0.804	test_f1:0.793615994038156
epoch:38	train_loss:0.05788354575634003	train_acc:1.0	test_acc:0.814	test_f1:0.7979171938174995
epoch:39	train_loss:0.060655705630779266	train_acc:1.0	test_acc:0.797	test_f1:0.7792523222071458
epoch:40	train_loss:0.06094876676797867	train_acc:1.0	test_acc:0.782	test_f1:0.7756840080945528
epoch:41	train_loss:0.056437522172927856	train_acc:1.0	test_acc:0.775	test_f1:0.7654259380462543
epoch:42	train_loss:0.05547622963786125	train_acc:1.0	test_acc:0.796	test_f1:0.7861458745751487
epoch:43	train_loss:0.052872125059366226	train_acc:1.0	test_acc:0.81	test_f1:0.7980657363527058
epoch:44	train_loss:0.049496255815029144	train_acc:1.0	test_acc:0.809	test_f1:0.7976096513016653
epoch:45	train_loss:0.04698843136429787	train_acc:1.0	test_acc:0.802	test_f1:0.7886233799588662
epoch:46	train_loss:0.044988762587308884	train_acc:1.0	test_acc:0.787	test_f1:0.7743668789322984
epoch:47	train_loss:0.04331423342227936	train_acc:1.0	test_acc:0.781	test_f1:0.7691318310066332
epoch:48	train_loss:0.04119141027331352	train_acc:1.0	test_acc:0.782	test_f1:0.7742379119841651
epoch:49	train_loss:0.03947658836841583	train_acc:1.0	test_acc:0.795	test_f1:0.7806880569295885
epoch:50	train_loss:0.03630287945270538	train_acc:1.0	test_acc:0.809	test_f1:0.7917292629830205
训练并测试结束，共训练50轮，总用时159.97653651237488s
最佳正确率为:0.816,对应的macro_f1为:0.8036124491316363,对应的训练轮次为:19



2022-07-02 01:32:00.336929
epoch:1	train_loss:2.0044093132019043	train_acc:0.14047619047619048	test_acc:0.174	test_f1:0.08580408068244176
epoch:2	train_loss:2.3300743103027344	train_acc:0.26904761904761904	test_acc:0.236	test_f1:0.2346294802931901
epoch:3	train_loss:1.9061596393585205	train_acc:0.3523809523809524	test_acc:0.575	test_f1:0.42165853252049396
epoch:4	train_loss:1.6807105541229248	train_acc:0.5357142857142857	test_acc:0.437	test_f1:0.2243207350011097
epoch:5	train_loss:1.6315770149230957	train_acc:0.3404761904761905	test_acc:0.46	test_f1:0.32664425341922965
epoch:6	train_loss:1.4918168783187866	train_acc:0.45714285714285713	test_acc:0.727	test_f1:0.7136768571417035
epoch:7	train_loss:1.2761248350143433	train_acc:0.8	test_acc:0.702	test_f1:0.6992904480656018
epoch:8	train_loss:1.093770146369934	train_acc:0.8809523809523809	test_acc:0.634	test_f1:0.607564317947178
epoch:9	train_loss:0.9325577616691589	train_acc:0.819047619047619	test_acc:0.707	test_f1:0.6854334849154974
epoch:10	train_loss:0.7559249997138977	train_acc:0.8666666666666667	test_acc:0.808	test_f1:0.7942433982255859
epoch:11	train_loss:0.5976987481117249	train_acc:0.9214285714285714	test_acc:0.808	test_f1:0.7995153944515172
epoch:12	train_loss:0.4958069920539856	train_acc:0.9	test_acc:0.815	test_f1:0.8037573148079888
epoch:13	train_loss:0.40901196002960205	train_acc:0.9095238095238095	test_acc:0.807	test_f1:0.7991608970463819
epoch:14	train_loss:0.32526111602783203	train_acc:0.9380952380952381	test_acc:0.804	test_f1:0.7974565997565597
epoch:15	train_loss:0.2701711058616638	train_acc:0.9523809523809523	test_acc:0.799	test_f1:0.7894489435305392
epoch:16	train_loss:0.23279394209384918	train_acc:0.9404761904761905	test_acc:0.814	test_f1:0.805197500220085
epoch:17	train_loss:0.18806560337543488	train_acc:0.9452380952380952	test_acc:0.83	test_f1:0.820354431622451
epoch:18	train_loss:0.15530654788017273	train_acc:0.9595238095238096	test_acc:0.838	test_f1:0.8299448943692774
epoch:19	train_loss:0.13440942764282227	train_acc:0.9642857142857143	test_acc:0.843	test_f1:0.8326038455448026
epoch:20	train_loss:0.1140696331858635	train_acc:0.9738095238095238	test_acc:0.84	test_f1:0.830512548157906
epoch:21	train_loss:0.09577540308237076	train_acc:0.9833333333333333	test_acc:0.826	test_f1:0.8162533360529158
epoch:22	train_loss:0.08414999395608902	train_acc:0.9880952380952381	test_acc:0.814	test_f1:0.8072947211489925
epoch:23	train_loss:0.07581969350576401	train_acc:0.9976190476190476	test_acc:0.816	test_f1:0.810418042984746
epoch:24	train_loss:0.06899694353342056	train_acc:0.9952380952380953	test_acc:0.815	test_f1:0.8076833100104338
epoch:25	train_loss:0.059488240629434586	train_acc:0.9976190476190476	test_acc:0.817	test_f1:0.8078224346275276
epoch:26	train_loss:0.055940546095371246	train_acc:0.9976190476190476	test_acc:0.827	test_f1:0.8164687545019654
epoch:27	train_loss:0.05583895370364189	train_acc:0.9976190476190476	test_acc:0.825	test_f1:0.8148058945124484
epoch:28	train_loss:0.05308667942881584	train_acc:1.0	test_acc:0.825	test_f1:0.8163246811279327
epoch:29	train_loss:0.053334422409534454	train_acc:1.0	test_acc:0.818	test_f1:0.8095735038283981
epoch:30	train_loss:0.05103689804673195	train_acc:1.0	test_acc:0.812	test_f1:0.8010207117470068
epoch:31	train_loss:0.05389116331934929	train_acc:1.0	test_acc:0.807	test_f1:0.7969705158612354
epoch:32	train_loss:0.05614747107028961	train_acc:1.0	test_acc:0.812	test_f1:0.8033197603125449
epoch:33	train_loss:0.05562984198331833	train_acc:1.0	test_acc:0.81	test_f1:0.7989806747322874
epoch:34	train_loss:0.05832333490252495	train_acc:1.0	test_acc:0.816	test_f1:0.8070411411878087
epoch:35	train_loss:0.05990181118249893	train_acc:1.0	test_acc:0.818	test_f1:0.807135920684454
epoch:36	train_loss:0.06446053832769394	train_acc:1.0	test_acc:0.818	test_f1:0.806477585726103
epoch:37	train_loss:0.06440521031618118	train_acc:1.0	test_acc:0.811	test_f1:0.8019562259262899
epoch:38	train_loss:0.06389112770557404	train_acc:1.0	test_acc:0.808	test_f1:0.7990854244647912
epoch:39	train_loss:0.0689157247543335	train_acc:1.0	test_acc:0.818	test_f1:0.8083869135971178
epoch:40	train_loss:0.06538094580173492	train_acc:1.0	test_acc:0.816	test_f1:0.8064686556881063
epoch:41	train_loss:0.06523752212524414	train_acc:1.0	test_acc:0.818	test_f1:0.8094726158797021
epoch:42	train_loss:0.06429865211248398	train_acc:1.0	test_acc:0.813	test_f1:0.8037634527051435
epoch:43	train_loss:0.06490472704172134	train_acc:1.0	test_acc:0.82	test_f1:0.8116060108209349
epoch:44	train_loss:0.06328336894512177	train_acc:1.0	test_acc:0.818	test_f1:0.8084951417390832
epoch:45	train_loss:0.06171749159693718	train_acc:1.0	test_acc:0.807	test_f1:0.7999682190082946
epoch:46	train_loss:0.06274616718292236	train_acc:1.0	test_acc:0.813	test_f1:0.8023505775763715
epoch:47	train_loss:0.05721566453576088	train_acc:1.0	test_acc:0.818	test_f1:0.8082146188422296
epoch:48	train_loss:0.053581591695547104	train_acc:1.0	test_acc:0.822	test_f1:0.8129422095217312
epoch:49	train_loss:0.05660395696759224	train_acc:1.0	test_acc:0.819	test_f1:0.8095232399454598
epoch:50	train_loss:0.05357763171195984	train_acc:1.0	test_acc:0.815	test_f1:0.8038408403182972
训练并测试结束，共训练50轮，总用时54.223376989364624s
最佳正确率为:0.843,对应的macro_f1为:0.8326038455448026,对应的训练轮次为:19



2022-07-02 01:34:04.840327
epoch:1	train_loss:2.0114781856536865	train_acc:0.13095238095238096	test_acc:0.091	test_f1:0.02383134738771769
epoch:2	train_loss:2.3386363983154297	train_acc:0.14285714285714285	test_acc:0.344	test_f1:0.11383504382126353
epoch:3	train_loss:1.9715839624404907	train_acc:0.1880952380952381	test_acc:0.556	test_f1:0.4117869028006563
epoch:4	train_loss:1.750409483909607	train_acc:0.5214285714285715	test_acc:0.209	test_f1:0.25260414376980833
epoch:5	train_loss:1.6952435970306396	train_acc:0.3761904761904762	test_acc:0.307	test_f1:0.29248254243121874
epoch:6	train_loss:1.6168092489242554	train_acc:0.4928571428571429	test_acc:0.365	test_f1:0.38426805533556535
epoch:7	train_loss:1.4682230949401855	train_acc:0.5357142857142857	test_acc:0.564	test_f1:0.6076276589815192
epoch:8	train_loss:1.2890421152114868	train_acc:0.7880952380952381	test_acc:0.719	test_f1:0.7302563077064755
epoch:9	train_loss:1.1109554767608643	train_acc:0.8761904761904762	test_acc:0.79	test_f1:0.7654342794216388
epoch:10	train_loss:0.9438328146934509	train_acc:0.8761904761904762	test_acc:0.816	test_f1:0.7939092577583086
epoch:11	train_loss:0.7881814241409302	train_acc:0.8809523809523809	test_acc:0.822	test_f1:0.8038471380220829
epoch:12	train_loss:0.6268633008003235	train_acc:0.9095238095238095	test_acc:0.793	test_f1:0.7918257944817786
epoch:13	train_loss:0.508334755897522	train_acc:0.919047619047619	test_acc:0.784	test_f1:0.7922651303336741
epoch:14	train_loss:0.4207477867603302	train_acc:0.919047619047619	test_acc:0.809	test_f1:0.8101902263442876
epoch:15	train_loss:0.3376000225543976	train_acc:0.930952380952381	test_acc:0.836	test_f1:0.8311233673305575
epoch:16	train_loss:0.26991450786590576	train_acc:0.9476190476190476	test_acc:0.847	test_f1:0.8332266199927911
epoch:17	train_loss:0.22802211344242096	train_acc:0.9404761904761905	test_acc:0.848	test_f1:0.8345337696812163
epoch:18	train_loss:0.19139429926872253	train_acc:0.9571428571428572	test_acc:0.84	test_f1:0.8294308406778309
epoch:19	train_loss:0.1585855931043625	train_acc:0.9714285714285714	test_acc:0.831	test_f1:0.8267497665743121
epoch:20	train_loss:0.13222990930080414	train_acc:0.9785714285714285	test_acc:0.831	test_f1:0.8270217854726577
epoch:21	train_loss:0.1105307787656784	train_acc:0.9904761904761905	test_acc:0.833	test_f1:0.8279911503191439
epoch:22	train_loss:0.09717579185962677	train_acc:0.9880952380952381	test_acc:0.839	test_f1:0.830260228892558
epoch:23	train_loss:0.08072534948587418	train_acc:0.9880952380952381	test_acc:0.836	test_f1:0.826142623287823
epoch:24	train_loss:0.0669156089425087	train_acc:0.9928571428571429	test_acc:0.839	test_f1:0.8298361246581499
epoch:25	train_loss:0.0628243237733841	train_acc:0.9952380952380953	test_acc:0.833	test_f1:0.8251612242896682
epoch:26	train_loss:0.05723179876804352	train_acc:1.0	test_acc:0.829	test_f1:0.8197942874568457
epoch:27	train_loss:0.05195312201976776	train_acc:1.0	test_acc:0.833	test_f1:0.8238681519359655
epoch:28	train_loss:0.05188102275133133	train_acc:1.0	test_acc:0.839	test_f1:0.8281474985472467
epoch:29	train_loss:0.05137849226593971	train_acc:1.0	test_acc:0.842	test_f1:0.8303383322976366
epoch:30	train_loss:0.049761977046728134	train_acc:1.0	test_acc:0.836	test_f1:0.8276700921844975
epoch:31	train_loss:0.04986345022916794	train_acc:1.0	test_acc:0.828	test_f1:0.8189519767987722
epoch:32	train_loss:0.04915698245167732	train_acc:1.0	test_acc:0.822	test_f1:0.8100129189296067
epoch:33	train_loss:0.05414804443717003	train_acc:1.0	test_acc:0.83	test_f1:0.8185618721740259
epoch:34	train_loss:0.056211818009614944	train_acc:1.0	test_acc:0.826	test_f1:0.8155361966528769
epoch:35	train_loss:0.055032879114151	train_acc:1.0	test_acc:0.832	test_f1:0.8207863561433483
epoch:36	train_loss:0.05886267125606537	train_acc:1.0	test_acc:0.841	test_f1:0.8295915606032244
epoch:37	train_loss:0.060447901487350464	train_acc:1.0	test_acc:0.83	test_f1:0.8190384457252622
epoch:38	train_loss:0.06166059896349907	train_acc:1.0	test_acc:0.823	test_f1:0.8152000367837812
epoch:39	train_loss:0.06913301348686218	train_acc:1.0	test_acc:0.822	test_f1:0.8114958387585262
epoch:40	train_loss:0.06429322063922882	train_acc:1.0	test_acc:0.83	test_f1:0.8175444897383226
epoch:41	train_loss:0.06869839131832123	train_acc:0.9976190476190476	test_acc:0.826	test_f1:0.8169467424466904
epoch:42	train_loss:0.06958416849374771	train_acc:0.9976190476190476	test_acc:0.823	test_f1:0.8152985458863208
epoch:43	train_loss:0.06220470741391182	train_acc:1.0	test_acc:0.816	test_f1:0.8078770146944122
epoch:44	train_loss:0.06476243585348129	train_acc:1.0	test_acc:0.826	test_f1:0.8176740018931773
epoch:45	train_loss:0.064146988093853	train_acc:1.0	test_acc:0.82	test_f1:0.8096367976520205
epoch:46	train_loss:0.06318368762731552	train_acc:1.0	test_acc:0.825	test_f1:0.8139890085803715
epoch:47	train_loss:0.060033224523067474	train_acc:1.0	test_acc:0.829	test_f1:0.8181237727685691
epoch:48	train_loss:0.06243407353758812	train_acc:1.0	test_acc:0.82	test_f1:0.8121668457125645
epoch:49	train_loss:0.054257795214653015	train_acc:1.0	test_acc:0.821	test_f1:0.8150667125997718
epoch:50	train_loss:0.05896040424704552	train_acc:1.0	test_acc:0.826	test_f1:0.8168258683303103
训练并测试结束，共训练50轮，总用时53.66956639289856s
最佳正确率为:0.848,对应的macro_f1为:0.8345337696812163,对应的训练轮次为:17



2022-07-02 01:35:12.091720
epoch:1	train_loss:2.038475751876831	train_acc:0.14285714285714285	test_acc:0.287	test_f1:0.1619291800980359
epoch:2	train_loss:2.1810121536254883	train_acc:0.3047619047619048	test_acc:0.466	test_f1:0.25345930451388476
epoch:3	train_loss:1.9494011402130127	train_acc:0.38333333333333336	test_acc:0.4	test_f1:0.2960278247248123
epoch:4	train_loss:1.7078737020492554	train_acc:0.49523809523809526	test_acc:0.571	test_f1:0.5903366266802383
epoch:5	train_loss:1.546093225479126	train_acc:0.7642857142857142	test_acc:0.242	test_f1:0.3202132249535335
epoch:6	train_loss:1.4430198669433594	train_acc:0.46904761904761905	test_acc:0.511	test_f1:0.5474101297034891
epoch:7	train_loss:1.260784387588501	train_acc:0.7333333333333333	test_acc:0.731	test_f1:0.7261694368851995
epoch:8	train_loss:1.0568583011627197	train_acc:0.8976190476190476	test_acc:0.785	test_f1:0.7697662110967809
epoch:9	train_loss:0.8717330694198608	train_acc:0.8571428571428571	test_acc:0.82	test_f1:0.7967644500255399
epoch:10	train_loss:0.7168339490890503	train_acc:0.8642857142857143	test_acc:0.833	test_f1:0.8198255344474198
epoch:11	train_loss:0.5713990330696106	train_acc:0.9023809523809524	test_acc:0.818	test_f1:0.8029977014209795
epoch:12	train_loss:0.44355684518814087	train_acc:0.9261904761904762	test_acc:0.782	test_f1:0.7721452659713713
epoch:13	train_loss:0.3675459623336792	train_acc:0.9238095238095239	test_acc:0.782	test_f1:0.7746867428546695
epoch:14	train_loss:0.2952233552932739	train_acc:0.9333333333333333	test_acc:0.807	test_f1:0.7984690367592918
epoch:15	train_loss:0.23602363467216492	train_acc:0.9452380952380952	test_acc:0.833	test_f1:0.8226622150552227
epoch:16	train_loss:0.19051292538642883	train_acc:0.95	test_acc:0.843	test_f1:0.8331326074221092
epoch:17	train_loss:0.1584426462650299	train_acc:0.9642857142857143	test_acc:0.84	test_f1:0.8314976995259099
epoch:18	train_loss:0.13602669537067413	train_acc:0.969047619047619	test_acc:0.83	test_f1:0.8246678001783921
epoch:19	train_loss:0.11184579879045486	train_acc:0.9761904761904762	test_acc:0.819	test_f1:0.8124594428118002
epoch:20	train_loss:0.08844159543514252	train_acc:0.9880952380952381	test_acc:0.817	test_f1:0.8091908091749558
epoch:21	train_loss:0.07305712252855301	train_acc:0.9952380952380953	test_acc:0.822	test_f1:0.8111066751274439
epoch:22	train_loss:0.06458202749490738	train_acc:0.9952380952380953	test_acc:0.822	test_f1:0.8095928843959145
epoch:23	train_loss:0.05760528892278671	train_acc:0.9976190476190476	test_acc:0.817	test_f1:0.8072712016806537
epoch:24	train_loss:0.05429761856794357	train_acc:1.0	test_acc:0.817	test_f1:0.8085931202322344
epoch:25	train_loss:0.046994201838970184	train_acc:0.9976190476190476	test_acc:0.82	test_f1:0.8113231772006432
epoch:26	train_loss:0.04702999070286751	train_acc:0.9976190476190476	test_acc:0.821	test_f1:0.8116361276007129
epoch:27	train_loss:0.04511503875255585	train_acc:1.0	test_acc:0.824	test_f1:0.8152680453673673
epoch:28	train_loss:0.04640653729438782	train_acc:1.0	test_acc:0.816	test_f1:0.8108822099032753
epoch:29	train_loss:0.046437639743089676	train_acc:1.0	test_acc:0.817	test_f1:0.8105521766737034
epoch:30	train_loss:0.04466491937637329	train_acc:1.0	test_acc:0.823	test_f1:0.812990853307376
epoch:31	train_loss:0.0453292578458786	train_acc:1.0	test_acc:0.823	test_f1:0.811010691468754
epoch:32	train_loss:0.04906008020043373	train_acc:1.0	test_acc:0.818	test_f1:0.8071582930649405
epoch:33	train_loss:0.04938177391886711	train_acc:1.0	test_acc:0.804	test_f1:0.7959393086422066
epoch:34	train_loss:0.05787602439522743	train_acc:1.0	test_acc:0.808	test_f1:0.7998655015456375
epoch:35	train_loss:0.055540066212415695	train_acc:1.0	test_acc:0.814	test_f1:0.7998466404570085
epoch:36	train_loss:0.0568370446562767	train_acc:1.0	test_acc:0.819	test_f1:0.8091298359257254
epoch:37	train_loss:0.05665100738406181	train_acc:1.0	test_acc:0.818	test_f1:0.809023230443041
epoch:38	train_loss:0.06307555735111237	train_acc:1.0	test_acc:0.827	test_f1:0.8144340499172898
epoch:39	train_loss:0.06598156690597534	train_acc:1.0	test_acc:0.815	test_f1:0.8087216476255336
epoch:40	train_loss:0.0634922981262207	train_acc:1.0	test_acc:0.804	test_f1:0.7987168256352177
epoch:41	train_loss:0.05773480236530304	train_acc:1.0	test_acc:0.822	test_f1:0.8078030668396099
epoch:42	train_loss:0.06348082423210144	train_acc:1.0	test_acc:0.821	test_f1:0.8091340797099084
epoch:43	train_loss:0.058476101607084274	train_acc:1.0	test_acc:0.805	test_f1:0.7987776125767206
epoch:44	train_loss:0.060956258326768875	train_acc:1.0	test_acc:0.814	test_f1:0.8051541138824753
epoch:45	train_loss:0.05413159355521202	train_acc:1.0	test_acc:0.823	test_f1:0.8094083032698879
epoch:46	train_loss:0.05389473959803581	train_acc:1.0	test_acc:0.821	test_f1:0.8111335444841223
epoch:47	train_loss:0.05544494092464447	train_acc:1.0	test_acc:0.81	test_f1:0.803853809549335
epoch:48	train_loss:0.05664166435599327	train_acc:1.0	test_acc:0.822	test_f1:0.8091898369604377
epoch:49	train_loss:0.05684702843427658	train_acc:0.9976190476190476	test_acc:0.819	test_f1:0.8029069089426226
epoch:50	train_loss:0.05616775527596474	train_acc:1.0	test_acc:0.799	test_f1:0.7942558859057218
训练并测试结束，共训练50轮，总用时54.94686579704285s
最佳正确率为:0.843,对应的macro_f1为:0.8331326074221092,对应的训练轮次为:16



2022-07-02 01:36:46.956135
epoch:1	train_loss:1.9775664806365967	train_acc:0.1523809523809524	test_acc:0.149	test_f1:0.03705085167226159
epoch:2	train_loss:2.3114802837371826	train_acc:0.14285714285714285	test_acc:0.233	test_f1:0.2245359924036942
epoch:3	train_loss:1.9693001508712769	train_acc:0.35714285714285715	test_acc:0.312	test_f1:0.2243522264288183
epoch:4	train_loss:1.7655876874923706	train_acc:0.44285714285714284	test_acc:0.553	test_f1:0.4630539258165675
epoch:5	train_loss:1.6428086757659912	train_acc:0.5761904761904761	test_acc:0.411	test_f1:0.30995475064346856
epoch:6	train_loss:1.5487635135650635	train_acc:0.44047619047619047	test_acc:0.474	test_f1:0.4560445549787565
epoch:7	train_loss:1.3908840417861938	train_acc:0.5904761904761905	test_acc:0.75	test_f1:0.7352216295395354
epoch:8	train_loss:1.195478081703186	train_acc:0.8642857142857143	test_acc:0.733	test_f1:0.7361953318844112
epoch:9	train_loss:1.0246689319610596	train_acc:0.8761904761904762	test_acc:0.731	test_f1:0.7268866137838582
epoch:10	train_loss:0.8715013861656189	train_acc:0.888095238095238	test_acc:0.753	test_f1:0.7539106453290448
epoch:11	train_loss:0.7176911234855652	train_acc:0.9047619047619048	test_acc:0.807	test_f1:0.8013357361997983
epoch:12	train_loss:0.5666009783744812	train_acc:0.9142857142857143	test_acc:0.81	test_f1:0.7973206379368307
epoch:13	train_loss:0.47012847661972046	train_acc:0.9142857142857143	test_acc:0.819	test_f1:0.8014386222914631
epoch:14	train_loss:0.3949792981147766	train_acc:0.9261904761904762	test_acc:0.837	test_f1:0.8231540592206174
epoch:15	train_loss:0.3242909014225006	train_acc:0.9476190476190476	test_acc:0.831	test_f1:0.8241705331346696
epoch:16	train_loss:0.2655545473098755	train_acc:0.9452380952380952	test_acc:0.812	test_f1:0.8089073838141341
epoch:17	train_loss:0.24002555012702942	train_acc:0.9452380952380952	test_acc:0.815	test_f1:0.809963510591991
epoch:18	train_loss:0.20987677574157715	train_acc:0.9547619047619048	test_acc:0.831	test_f1:0.825692356170371
epoch:19	train_loss:0.17365583777427673	train_acc:0.9761904761904762	test_acc:0.841	test_f1:0.832755868831134
epoch:20	train_loss:0.15404443442821503	train_acc:0.9785714285714285	test_acc:0.847	test_f1:0.8361860358474165
epoch:21	train_loss:0.13871285319328308	train_acc:0.9833333333333333	test_acc:0.844	test_f1:0.8332441609099935
epoch:22	train_loss:0.12337251007556915	train_acc:0.9880952380952381	test_acc:0.837	test_f1:0.8255722277513888
epoch:23	train_loss:0.11301913857460022	train_acc:0.9976190476190476	test_acc:0.836	test_f1:0.8260203136812331
epoch:24	train_loss:0.09934301674365997	train_acc:1.0	test_acc:0.839	test_f1:0.8304690048775277
epoch:25	train_loss:0.09416114538908005	train_acc:1.0	test_acc:0.835	test_f1:0.8259688120833089
epoch:26	train_loss:0.08805768191814423	train_acc:0.9976190476190476	test_acc:0.824	test_f1:0.8168318399468554
epoch:27	train_loss:0.07895521819591522	train_acc:1.0	test_acc:0.818	test_f1:0.8130591773434973
epoch:28	train_loss:0.08038192987442017	train_acc:1.0	test_acc:0.825	test_f1:0.8197991190105227
epoch:29	train_loss:0.08214150369167328	train_acc:1.0	test_acc:0.825	test_f1:0.8174195854238248
epoch:30	train_loss:0.07988416403532028	train_acc:1.0	test_acc:0.814	test_f1:0.8036256904305809
epoch:31	train_loss:0.08025570213794708	train_acc:1.0	test_acc:0.813	test_f1:0.8034778399598012
epoch:32	train_loss:0.08309533447027206	train_acc:1.0	test_acc:0.82	test_f1:0.8133409012568164
epoch:33	train_loss:0.08052316308021545	train_acc:1.0	test_acc:0.83	test_f1:0.8187079371175725
epoch:34	train_loss:0.07949260622262955	train_acc:1.0	test_acc:0.823	test_f1:0.8151267816401807
epoch:35	train_loss:0.08082836866378784	train_acc:1.0	test_acc:0.81	test_f1:0.8010889308223362
epoch:36	train_loss:0.0824669823050499	train_acc:1.0	test_acc:0.817	test_f1:0.8050803032949546
epoch:37	train_loss:0.0825534537434578	train_acc:1.0	test_acc:0.823	test_f1:0.8103626017934541
epoch:38	train_loss:0.07521915435791016	train_acc:1.0	test_acc:0.83	test_f1:0.8176813259972411
epoch:39	train_loss:0.08177787810564041	train_acc:1.0	test_acc:0.82	test_f1:0.8085483103742609
epoch:40	train_loss:0.07815269380807877	train_acc:1.0	test_acc:0.828	test_f1:0.814630739619363
epoch:41	train_loss:0.07399845868349075	train_acc:1.0	test_acc:0.827	test_f1:0.8156069072179886
epoch:42	train_loss:0.07520957291126251	train_acc:1.0	test_acc:0.825	test_f1:0.8155151991800741
epoch:43	train_loss:0.07071666419506073	train_acc:1.0	test_acc:0.822	test_f1:0.8137253455695888
epoch:44	train_loss:0.07067419588565826	train_acc:1.0	test_acc:0.825	test_f1:0.8136474558235446
epoch:45	train_loss:0.07028743624687195	train_acc:1.0	test_acc:0.839	test_f1:0.8250880977047564
epoch:46	train_loss:0.07157456874847412	train_acc:1.0	test_acc:0.825	test_f1:0.8163433493981878
epoch:47	train_loss:0.06659882515668869	train_acc:1.0	test_acc:0.821	test_f1:0.8113338766356983
epoch:48	train_loss:0.06536932289600372	train_acc:1.0	test_acc:0.838	test_f1:0.8260651414506438
epoch:49	train_loss:0.06612146645784378	train_acc:1.0	test_acc:0.829	test_f1:0.8194358885028352
epoch:50	train_loss:0.06251365691423416	train_acc:1.0	test_acc:0.823	test_f1:0.8151167653348496
训练并测试结束，共训练50轮，总用时153.65103840827942s
最佳正确率为:0.847,对应的macro_f1为:0.8361860358474165,对应的训练轮次为:20



2022-07-02 01:41:26.399397
epoch:1	train_loss:1.965518832206726	train_acc:0.1261904761904762	test_acc:0.091	test_f1:0.02383134738771769
epoch:2	train_loss:2.3184731006622314	train_acc:0.14285714285714285	test_acc:0.16	test_f1:0.1222238183397484
epoch:3	train_loss:1.8492738008499146	train_acc:0.22380952380952382	test_acc:0.503	test_f1:0.40588034601398376
epoch:4	train_loss:1.7159795761108398	train_acc:0.5261904761904762	test_acc:0.573	test_f1:0.4097116195310037
epoch:5	train_loss:1.6760907173156738	train_acc:0.5428571428571428	test_acc:0.51	test_f1:0.40562414912418904
epoch:6	train_loss:1.5368943214416504	train_acc:0.5452380952380952	test_acc:0.633	test_f1:0.5324263133454114
epoch:7	train_loss:1.3308634757995605	train_acc:0.6738095238095239	test_acc:0.729	test_f1:0.6752314783870066
epoch:8	train_loss:1.1370594501495361	train_acc:0.8023809523809524	test_acc:0.769	test_f1:0.7584546442566101
epoch:9	train_loss:0.9673741459846497	train_acc:0.8690476190476191	test_acc:0.77	test_f1:0.7563916655353496
epoch:10	train_loss:0.7885702848434448	train_acc:0.888095238095238	test_acc:0.74	test_f1:0.7454932435606054
epoch:11	train_loss:0.6416955590248108	train_acc:0.8904761904761904	test_acc:0.781	test_f1:0.7782732246145512
epoch:12	train_loss:0.5093984007835388	train_acc:0.9071428571428571	test_acc:0.803	test_f1:0.7994995405314329
epoch:13	train_loss:0.4065650403499603	train_acc:0.9095238095238095	test_acc:0.806	test_f1:0.796492391748824
epoch:14	train_loss:0.34196022152900696	train_acc:0.9166666666666666	test_acc:0.816	test_f1:0.8058598875892887
epoch:15	train_loss:0.2862992286682129	train_acc:0.930952380952381	test_acc:0.809	test_f1:0.7979019996279062
epoch:16	train_loss:0.2332373708486557	train_acc:0.9428571428571428	test_acc:0.804	test_f1:0.7993304811181074
epoch:17	train_loss:0.19873228669166565	train_acc:0.95	test_acc:0.801	test_f1:0.7957637371107703
epoch:18	train_loss:0.1701253056526184	train_acc:0.9523809523809523	test_acc:0.817	test_f1:0.808583496199091
epoch:19	train_loss:0.1414685845375061	train_acc:0.9571428571428572	test_acc:0.83	test_f1:0.8199110902709904
epoch:20	train_loss:0.1203543171286583	train_acc:0.9738095238095238	test_acc:0.828	test_f1:0.8189059229574333
epoch:21	train_loss:0.10269790142774582	train_acc:0.9809523809523809	test_acc:0.825	test_f1:0.8175046538859088
epoch:22	train_loss:0.08637971431016922	train_acc:0.9904761904761905	test_acc:0.83	test_f1:0.8225606084965007
epoch:23	train_loss:0.0750613808631897	train_acc:0.9928571428571429	test_acc:0.828	test_f1:0.8181031265864009
epoch:24	train_loss:0.06363660097122192	train_acc:1.0	test_acc:0.824	test_f1:0.8143676966142663
epoch:25	train_loss:0.05925358086824417	train_acc:0.9976190476190476	test_acc:0.82	test_f1:0.8096296659717804
epoch:26	train_loss:0.055978864431381226	train_acc:0.9976190476190476	test_acc:0.819	test_f1:0.80826229157307
epoch:27	train_loss:0.053868647664785385	train_acc:1.0	test_acc:0.82	test_f1:0.8108152579338304
epoch:28	train_loss:0.0532924085855484	train_acc:1.0	test_acc:0.816	test_f1:0.8056512653366703
epoch:29	train_loss:0.05200621113181114	train_acc:1.0	test_acc:0.819	test_f1:0.8093038726510402
epoch:30	train_loss:0.05272480845451355	train_acc:1.0	test_acc:0.822	test_f1:0.8122352811399393
epoch:31	train_loss:0.05200977623462677	train_acc:1.0	test_acc:0.826	test_f1:0.815863901509804
epoch:32	train_loss:0.05356612801551819	train_acc:1.0	test_acc:0.823	test_f1:0.8116492038723707
epoch:33	train_loss:0.055451542139053345	train_acc:1.0	test_acc:0.819	test_f1:0.8083168197491354
epoch:34	train_loss:0.06342466175556183	train_acc:1.0	test_acc:0.812	test_f1:0.8032958966303222
epoch:35	train_loss:0.05698563531041145	train_acc:1.0	test_acc:0.819	test_f1:0.8072960337401442
epoch:36	train_loss:0.05933718755841255	train_acc:1.0	test_acc:0.821	test_f1:0.8083455027202716
epoch:37	train_loss:0.06061980500817299	train_acc:1.0	test_acc:0.814	test_f1:0.8006200661175977
epoch:38	train_loss:0.06493406742811203	train_acc:0.9976190476190476	test_acc:0.806	test_f1:0.7989834265145558
epoch:39	train_loss:0.06633242219686508	train_acc:1.0	test_acc:0.817	test_f1:0.8071600685675301
epoch:40	train_loss:0.06475171446800232	train_acc:1.0	test_acc:0.824	test_f1:0.8128826470354003
epoch:41	train_loss:0.06870220601558685	train_acc:0.9976190476190476	test_acc:0.82	test_f1:0.8091098998628692
epoch:42	train_loss:0.06250034272670746	train_acc:1.0	test_acc:0.803	test_f1:0.7960015890782521
epoch:43	train_loss:0.0687810480594635	train_acc:1.0	test_acc:0.813	test_f1:0.8040110165263334
epoch:44	train_loss:0.061603792011737823	train_acc:1.0	test_acc:0.817	test_f1:0.8046108251936744
epoch:45	train_loss:0.0630800873041153	train_acc:1.0	test_acc:0.817	test_f1:0.8027575360897192
epoch:46	train_loss:0.062118224799633026	train_acc:1.0	test_acc:0.805	test_f1:0.795558910285661
epoch:47	train_loss:0.05995766445994377	train_acc:1.0	test_acc:0.806	test_f1:0.8000001342955715
epoch:48	train_loss:0.06234517693519592	train_acc:1.0	test_acc:0.818	test_f1:0.8038484116594306
epoch:49	train_loss:0.061224564909935	train_acc:1.0	test_acc:0.827	test_f1:0.8126215453661499
epoch:50	train_loss:0.05983780324459076	train_acc:0.9976190476190476	test_acc:0.814	test_f1:0.8060191057169475
训练并测试结束，共训练50轮，总用时60.15182685852051s
最佳正确率为:0.83,对应的macro_f1为:0.8225606084965007,对应的训练轮次为:22



2022-07-02 01:43:03.207725
epoch:1	train_loss:1.9636456966400146	train_acc:0.14285714285714285	test_acc:0.13	test_f1:0.03286978508217447
epoch:2	train_loss:2.2447540760040283	train_acc:0.14285714285714285	test_acc:0.338	test_f1:0.3498570723190939
epoch:3	train_loss:1.8818211555480957	train_acc:0.5	test_acc:0.187	test_f1:0.18812386213778343
epoch:4	train_loss:1.6684621572494507	train_acc:0.3142857142857143	test_acc:0.386	test_f1:0.2288608821446775
epoch:5	train_loss:1.5664011240005493	train_acc:0.2904761904761905	test_acc:0.479	test_f1:0.3601332455334573
epoch:6	train_loss:1.408095359802246	train_acc:0.4380952380952381	test_acc:0.785	test_f1:0.7670604121873487
epoch:7	train_loss:1.1937332153320312	train_acc:0.8523809523809524	test_acc:0.634	test_f1:0.6494991763433762
epoch:8	train_loss:1.0188801288604736	train_acc:0.8404761904761905	test_acc:0.618	test_f1:0.6457347668718049
epoch:9	train_loss:0.8511340022087097	train_acc:0.8285714285714286	test_acc:0.676	test_f1:0.7032001579286545
epoch:10	train_loss:0.7085757851600647	train_acc:0.8761904761904762	test_acc:0.788	test_f1:0.7927506498940363
epoch:11	train_loss:0.5595592856407166	train_acc:0.9166666666666666	test_acc:0.828	test_f1:0.8162979839158814
epoch:12	train_loss:0.4561249315738678	train_acc:0.9142857142857143	test_acc:0.825	test_f1:0.8108633505269492
epoch:13	train_loss:0.38006219267845154	train_acc:0.9238095238095239	test_acc:0.823	test_f1:0.8123467469040041
epoch:14	train_loss:0.31165891885757446	train_acc:0.930952380952381	test_acc:0.804	test_f1:0.8040380385133756
epoch:15	train_loss:0.2553599774837494	train_acc:0.9404761904761905	test_acc:0.805	test_f1:0.8052798786767168
epoch:16	train_loss:0.2091866433620453	train_acc:0.95	test_acc:0.812	test_f1:0.809892410997775
epoch:17	train_loss:0.18397049605846405	train_acc:0.9523809523809523	test_acc:0.827	test_f1:0.8209551805275208
epoch:18	train_loss:0.1486016809940338	train_acc:0.9642857142857143	test_acc:0.836	test_f1:0.8239989349456034
epoch:19	train_loss:0.12674348056316376	train_acc:0.9761904761904762	test_acc:0.846	test_f1:0.8346264263007063
epoch:20	train_loss:0.10006293654441833	train_acc:0.9857142857142858	test_acc:0.848	test_f1:0.8368596067298989
epoch:21	train_loss:0.08540019392967224	train_acc:0.9880952380952381	test_acc:0.843	test_f1:0.8338362356138488
epoch:22	train_loss:0.07384662330150604	train_acc:0.9976190476190476	test_acc:0.833	test_f1:0.8246824285157298
epoch:23	train_loss:0.06908098608255386	train_acc:0.9952380952380953	test_acc:0.829	test_f1:0.8209868565622663
epoch:24	train_loss:0.06125582009553909	train_acc:1.0	test_acc:0.836	test_f1:0.8267437118622842
epoch:25	train_loss:0.05352313444018364	train_acc:1.0	test_acc:0.834	test_f1:0.8224361694207978
epoch:26	train_loss:0.04884691536426544	train_acc:1.0	test_acc:0.838	test_f1:0.8257037501602095
epoch:27	train_loss:0.04977774992585182	train_acc:1.0	test_acc:0.836	test_f1:0.8239362378514118
epoch:28	train_loss:0.05047795921564102	train_acc:1.0	test_acc:0.826	test_f1:0.8151979620982402
epoch:29	train_loss:0.05001659318804741	train_acc:1.0	test_acc:0.821	test_f1:0.811583780712526
epoch:30	train_loss:0.05150078982114792	train_acc:1.0	test_acc:0.815	test_f1:0.8059094590857239
epoch:31	train_loss:0.05700164660811424	train_acc:0.9976190476190476	test_acc:0.823	test_f1:0.8125647990693142
epoch:32	train_loss:0.05337110906839371	train_acc:1.0	test_acc:0.83	test_f1:0.8182305411658135
epoch:33	train_loss:0.0559890940785408	train_acc:1.0	test_acc:0.835	test_f1:0.8232133623473041
epoch:34	train_loss:0.056883908808231354	train_acc:1.0	test_acc:0.827	test_f1:0.8136302175460465
epoch:35	train_loss:0.0619407556951046	train_acc:1.0	test_acc:0.82	test_f1:0.8083036490591453
epoch:36	train_loss:0.06076357513666153	train_acc:1.0	test_acc:0.818	test_f1:0.809495697478168
epoch:37	train_loss:0.06597205996513367	train_acc:1.0	test_acc:0.82	test_f1:0.807969112309058
epoch:38	train_loss:0.06077379360795021	train_acc:1.0	test_acc:0.823	test_f1:0.810832806022738
epoch:39	train_loss:0.06567951291799545	train_acc:1.0	test_acc:0.822	test_f1:0.8099380830653775
epoch:40	train_loss:0.0614122711122036	train_acc:1.0	test_acc:0.829	test_f1:0.8163168796153569
epoch:41	train_loss:0.060288313776254654	train_acc:1.0	test_acc:0.825	test_f1:0.8132973054057346
epoch:42	train_loss:0.062268611043691635	train_acc:1.0	test_acc:0.823	test_f1:0.8124788811597847
epoch:43	train_loss:0.06265100836753845	train_acc:1.0	test_acc:0.822	test_f1:0.809833062507444
epoch:44	train_loss:0.060086287558078766	train_acc:1.0	test_acc:0.824	test_f1:0.8116230724861001
epoch:45	train_loss:0.06221425533294678	train_acc:1.0	test_acc:0.826	test_f1:0.8161404858850615
epoch:46	train_loss:0.057868245989084244	train_acc:1.0	test_acc:0.818	test_f1:0.806454645602947
epoch:47	train_loss:0.05748186260461807	train_acc:1.0	test_acc:0.819	test_f1:0.8075846188283082
epoch:48	train_loss:0.05450259521603584	train_acc:1.0	test_acc:0.825	test_f1:0.8134743545595465
epoch:49	train_loss:0.05479662865400314	train_acc:1.0	test_acc:0.828	test_f1:0.8171046849029934
epoch:50	train_loss:0.050390273332595825	train_acc:1.0	test_acc:0.825	test_f1:0.812011136501752
训练并测试结束，共训练50轮，总用时60.0669264793396s
最佳正确率为:0.848,对应的macro_f1为:0.8368596067298989,对应的训练轮次为:20



2022-07-02 01:44:57.646153
epoch:1	train_loss:2.0345587730407715	train_acc:0.14285714285714285	test_acc:0.13	test_f1:0.03286978508217447
epoch:2	train_loss:2.1592905521392822	train_acc:0.1619047619047619	test_acc:0.24	test_f1:0.23764438545771246
epoch:3	train_loss:1.9418785572052002	train_acc:0.4023809523809524	test_acc:0.512	test_f1:0.4273419723254777
epoch:4	train_loss:1.7438483238220215	train_acc:0.5619047619047619	test_acc:0.728	test_f1:0.6538901675447241
epoch:5	train_loss:1.5706942081451416	train_acc:0.7642857142857142	test_acc:0.4	test_f1:0.4357957748108049
epoch:6	train_loss:1.4506936073303223	train_acc:0.5523809523809524	test_acc:0.543	test_f1:0.5948520420759545
epoch:7	train_loss:1.2797660827636719	train_acc:0.7404761904761905	test_acc:0.778	test_f1:0.7779321951157326
epoch:8	train_loss:1.0740450620651245	train_acc:0.8809523809523809	test_acc:0.754	test_f1:0.7382375327261224
epoch:9	train_loss:0.8984212279319763	train_acc:0.8547619047619047	test_acc:0.779	test_f1:0.7565145317397538
epoch:10	train_loss:0.7406172156333923	train_acc:0.85	test_acc:0.807	test_f1:0.7884625762076022
epoch:11	train_loss:0.5956756472587585	train_acc:0.888095238095238	test_acc:0.81	test_f1:0.8011636268723233
epoch:12	train_loss:0.468793660402298	train_acc:0.9095238095238095	test_acc:0.802	test_f1:0.8018559614158403
epoch:13	train_loss:0.39009788632392883	train_acc:0.9214285714285714	test_acc:0.801	test_f1:0.7965372594366309
epoch:14	train_loss:0.33136534690856934	train_acc:0.9142857142857143	test_acc:0.82	test_f1:0.8103967166961982
epoch:15	train_loss:0.27034467458724976	train_acc:0.9357142857142857	test_acc:0.833	test_f1:0.8235182100054228
epoch:16	train_loss:0.22745946049690247	train_acc:0.9523809523809523	test_acc:0.833	test_f1:0.8230869474269963
epoch:17	train_loss:0.20391631126403809	train_acc:0.9547619047619048	test_acc:0.835	test_f1:0.8264950979754246
epoch:18	train_loss:0.18206575512886047	train_acc:0.9642857142857143	test_acc:0.838	test_f1:0.8315688777975508
epoch:19	train_loss:0.15676075220108032	train_acc:0.9761904761904762	test_acc:0.83	test_f1:0.8231128656261818
epoch:20	train_loss:0.14182819426059723	train_acc:0.9833333333333333	test_acc:0.821	test_f1:0.8143259193195119
epoch:21	train_loss:0.131462961435318	train_acc:0.9880952380952381	test_acc:0.82	test_f1:0.8124734203251945
epoch:22	train_loss:0.1135874018073082	train_acc:0.9928571428571429	test_acc:0.827	test_f1:0.8191575443509297
epoch:23	train_loss:0.10003127157688141	train_acc:0.9976190476190476	test_acc:0.834	test_f1:0.8270948381666521
epoch:24	train_loss:0.09503273665904999	train_acc:0.9952380952380953	test_acc:0.834	test_f1:0.8267671656776778
epoch:25	train_loss:0.08987210690975189	train_acc:0.9976190476190476	test_acc:0.829	test_f1:0.821450759833905
epoch:26	train_loss:0.08245784789323807	train_acc:1.0	test_acc:0.827	test_f1:0.8197435448675506
epoch:27	train_loss:0.0782053992152214	train_acc:1.0	test_acc:0.815	test_f1:0.8075901474528905
epoch:28	train_loss:0.0795876681804657	train_acc:1.0	test_acc:0.815	test_f1:0.8083225171763495
epoch:29	train_loss:0.07973536849021912	train_acc:1.0	test_acc:0.815	test_f1:0.8077089637959428
epoch:30	train_loss:0.07757028937339783	train_acc:1.0	test_acc:0.819	test_f1:0.812027190486239
epoch:31	train_loss:0.07720784097909927	train_acc:1.0	test_acc:0.818	test_f1:0.8076769582936232
epoch:32	train_loss:0.0824507623910904	train_acc:1.0	test_acc:0.827	test_f1:0.816066741102408
epoch:33	train_loss:0.08234024792909622	train_acc:1.0	test_acc:0.818	test_f1:0.8085004637529235
epoch:34	train_loss:0.08148631453514099	train_acc:1.0	test_acc:0.815	test_f1:0.8069850231318517
epoch:35	train_loss:0.08382018655538559	train_acc:1.0	test_acc:0.826	test_f1:0.8163432163777219
epoch:36	train_loss:0.08234903961420059	train_acc:1.0	test_acc:0.821	test_f1:0.8075949138080263
epoch:37	train_loss:0.0843457505106926	train_acc:1.0	test_acc:0.82	test_f1:0.8079147621248716
epoch:38	train_loss:0.08307957649230957	train_acc:1.0	test_acc:0.821	test_f1:0.813037083521906
epoch:39	train_loss:0.08128873258829117	train_acc:1.0	test_acc:0.824	test_f1:0.8144354261745242
epoch:40	train_loss:0.07877524197101593	train_acc:1.0	test_acc:0.828	test_f1:0.8154370339870184
epoch:41	train_loss:0.0779980942606926	train_acc:0.9976190476190476	test_acc:0.819	test_f1:0.8098097127720084
epoch:42	train_loss:0.07154417037963867	train_acc:1.0	test_acc:0.814	test_f1:0.8085985839348279
epoch:43	train_loss:0.07528822869062424	train_acc:1.0	test_acc:0.813	test_f1:0.8043174087593109
epoch:44	train_loss:0.06707112491130829	train_acc:1.0	test_acc:0.829	test_f1:0.8165963291938251
epoch:45	train_loss:0.06616353988647461	train_acc:1.0	test_acc:0.836	test_f1:0.8246841564898704
epoch:46	train_loss:0.06580972671508789	train_acc:1.0	test_acc:0.814	test_f1:0.8070719880363999
epoch:47	train_loss:0.06292685121297836	train_acc:1.0	test_acc:0.806	test_f1:0.7998200781205594
epoch:48	train_loss:0.06056015565991402	train_acc:1.0	test_acc:0.826	test_f1:0.8144254508577341
epoch:49	train_loss:0.05736396461725235	train_acc:1.0	test_acc:0.841	test_f1:0.827070815611621
epoch:50	train_loss:0.06218155845999718	train_acc:1.0	test_acc:0.826	test_f1:0.8147550113802613
训练并测试结束，共训练50轮，总用时159.24968600273132s
最佳正确率为:0.841,对应的macro_f1为:0.827070815611621,对应的训练轮次为:49



2022-07-02 01:47:49.860173
epoch:1	train_loss:1.9875867366790771	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:2	train_loss:2.311445713043213	train_acc:0.14285714285714285	test_acc:0.331	test_f1:0.23731849679119593
epoch:3	train_loss:1.9107062816619873	train_acc:0.41904761904761906	test_acc:0.207	test_f1:0.16036505800429798
epoch:4	train_loss:1.7774300575256348	train_acc:0.3142857142857143	test_acc:0.453	test_f1:0.48410715177948394
epoch:5	train_loss:1.6223658323287964	train_acc:0.6642857142857143	test_acc:0.245	test_f1:0.2912886103864092
epoch:6	train_loss:1.5154831409454346	train_acc:0.38333333333333336	test_acc:0.411	test_f1:0.45021706613998064
epoch:7	train_loss:1.3638781309127808	train_acc:0.5714285714285714	test_acc:0.756	test_f1:0.7584151979035069
epoch:8	train_loss:1.171282410621643	train_acc:0.8666666666666667	test_acc:0.801	test_f1:0.783178736964072
epoch:9	train_loss:0.9898446202278137	train_acc:0.8857142857142857	test_acc:0.761	test_f1:0.7396461350454443
epoch:10	train_loss:0.8403729200363159	train_acc:0.8571428571428571	test_acc:0.76	test_f1:0.7453855341531053
epoch:11	train_loss:0.686082124710083	train_acc:0.8738095238095238	test_acc:0.801	test_f1:0.793130107593895
epoch:12	train_loss:0.5386615991592407	train_acc:0.9071428571428571	test_acc:0.816	test_f1:0.8122157347443663
epoch:13	train_loss:0.441013365983963	train_acc:0.9261904761904762	test_acc:0.816	test_f1:0.8075600649675818
epoch:14	train_loss:0.3763778805732727	train_acc:0.9214285714285714	test_acc:0.811	test_f1:0.8028547857017256
epoch:15	train_loss:0.3144773840904236	train_acc:0.9357142857142857	test_acc:0.825	test_f1:0.8168294971894604
epoch:16	train_loss:0.2592828869819641	train_acc:0.9476190476190476	test_acc:0.824	test_f1:0.8178148385536851
epoch:17	train_loss:0.2203897386789322	train_acc:0.9523809523809523	test_acc:0.831	test_f1:0.8254022212998511
epoch:18	train_loss:0.20525512099266052	train_acc:0.9547619047619048	test_acc:0.843	test_f1:0.8354253743530544
epoch:19	train_loss:0.1772674024105072	train_acc:0.9666666666666667	test_acc:0.845	test_f1:0.836050308918763
epoch:20	train_loss:0.15689615905284882	train_acc:0.9809523809523809	test_acc:0.843	test_f1:0.8335907712025656
epoch:21	train_loss:0.1432170569896698	train_acc:0.9904761904761905	test_acc:0.825	test_f1:0.8182119302645352
epoch:22	train_loss:0.12927496433258057	train_acc:0.9928571428571429	test_acc:0.822	test_f1:0.8151081368347471
epoch:23	train_loss:0.11988851428031921	train_acc:1.0	test_acc:0.824	test_f1:0.8140506885091631
epoch:24	train_loss:0.11212795972824097	train_acc:0.9952380952380953	test_acc:0.831	test_f1:0.8218453068747864
epoch:25	train_loss:0.10011574625968933	train_acc:1.0	test_acc:0.837	test_f1:0.8277426690618441
epoch:26	train_loss:0.09304153919219971	train_acc:0.9976190476190476	test_acc:0.837	test_f1:0.8271841787392022
epoch:27	train_loss:0.09058473259210587	train_acc:1.0	test_acc:0.831	test_f1:0.8195777297034523
epoch:28	train_loss:0.08625365048646927	train_acc:0.9976190476190476	test_acc:0.819	test_f1:0.8105973156600561
epoch:29	train_loss:0.08832612633705139	train_acc:1.0	test_acc:0.818	test_f1:0.8074573755765799
epoch:30	train_loss:0.08695715665817261	train_acc:1.0	test_acc:0.823	test_f1:0.8109181420724179
epoch:31	train_loss:0.08510389178991318	train_acc:1.0	test_acc:0.824	test_f1:0.8133730298317884
epoch:32	train_loss:0.08704216033220291	train_acc:1.0	test_acc:0.821	test_f1:0.8125625160569505
epoch:33	train_loss:0.08657059073448181	train_acc:1.0	test_acc:0.814	test_f1:0.803577280938241
epoch:34	train_loss:0.09139767289161682	train_acc:1.0	test_acc:0.813	test_f1:0.8017426104330625
epoch:35	train_loss:0.08944902569055557	train_acc:1.0	test_acc:0.825	test_f1:0.8130643912782681
epoch:36	train_loss:0.08791482448577881	train_acc:1.0	test_acc:0.824	test_f1:0.8130903428519269
epoch:37	train_loss:0.08724238723516464	train_acc:1.0	test_acc:0.813	test_f1:0.8032441942214731
epoch:38	train_loss:0.08807375282049179	train_acc:1.0	test_acc:0.822	test_f1:0.8125270766298549
epoch:39	train_loss:0.088141068816185	train_acc:1.0	test_acc:0.823	test_f1:0.8134504821693807
epoch:40	train_loss:0.08291663229465485	train_acc:1.0	test_acc:0.824	test_f1:0.8116072320901943
epoch:41	train_loss:0.08225132524967194	train_acc:1.0	test_acc:0.827	test_f1:0.8152305966344945
epoch:42	train_loss:0.07472763955593109	train_acc:1.0	test_acc:0.819	test_f1:0.8101976377029994
epoch:43	train_loss:0.07508041709661484	train_acc:0.9976190476190476	test_acc:0.826	test_f1:0.8162274899832046
epoch:44	train_loss:0.07404713332653046	train_acc:0.9976190476190476	test_acc:0.831	test_f1:0.8197015553446746
epoch:45	train_loss:0.07020426541566849	train_acc:0.9976190476190476	test_acc:0.838	test_f1:0.827963575284067
epoch:46	train_loss:0.06741250306367874	train_acc:1.0	test_acc:0.826	test_f1:0.8185747014528723
epoch:47	train_loss:0.06336448341608047	train_acc:1.0	test_acc:0.816	test_f1:0.8081799865002839
epoch:48	train_loss:0.06409401446580887	train_acc:1.0	test_acc:0.82	test_f1:0.809742770923737
epoch:49	train_loss:0.06128937751054764	train_acc:1.0	test_acc:0.833	test_f1:0.8222839224778007
epoch:50	train_loss:0.06348789483308792	train_acc:1.0	test_acc:0.835	test_f1:0.8235888107613523
训练并测试结束，共训练50轮，总用时161.43053531646729s
最佳正确率为:0.845,对应的macro_f1为:0.836050308918763,对应的训练轮次为:19



2022-07-02 01:50:46.822221
epoch:1	train_loss:1.9612483978271484	train_acc:0.14761904761904762	test_acc:0.091	test_f1:0.02383134738771769
epoch:2	train_loss:2.3801686763763428	train_acc:0.14285714285714285	test_acc:0.559	test_f1:0.37981863978554214
epoch:3	train_loss:1.882251262664795	train_acc:0.5142857142857142	test_acc:0.557	test_f1:0.43651527167172105
epoch:4	train_loss:1.722827672958374	train_acc:0.580952380952381	test_acc:0.292	test_f1:0.2421226672834023
epoch:5	train_loss:1.674932599067688	train_acc:0.4119047619047619	test_acc:0.329	test_f1:0.3052462979915024
epoch:6	train_loss:1.54241943359375	train_acc:0.4523809523809524	test_acc:0.569	test_f1:0.5417387899912491
epoch:7	train_loss:1.3333170413970947	train_acc:0.6904761904761905	test_acc:0.741	test_f1:0.7329448625398791
epoch:8	train_loss:1.1441148519515991	train_acc:0.8523809523809524	test_acc:0.732	test_f1:0.6819968513689618
epoch:9	train_loss:0.9960502982139587	train_acc:0.8214285714285714	test_acc:0.76	test_f1:0.7121334553320164
epoch:10	train_loss:0.8350868225097656	train_acc:0.8428571428571429	test_acc:0.818	test_f1:0.7998688237555075
epoch:11	train_loss:0.6520226001739502	train_acc:0.9071428571428571	test_acc:0.808	test_f1:0.8062485283298065
epoch:12	train_loss:0.5334544777870178	train_acc:0.9166666666666666	test_acc:0.796	test_f1:0.7973629560320658
epoch:13	train_loss:0.44732099771499634	train_acc:0.9142857142857143	test_acc:0.813	test_f1:0.8107925400834951
epoch:14	train_loss:0.35612279176712036	train_acc:0.9214285714285714	test_acc:0.834	test_f1:0.8229877451313167
epoch:15	train_loss:0.29363277554512024	train_acc:0.9452380952380952	test_acc:0.844	test_f1:0.8284299295029385
epoch:16	train_loss:0.2513151168823242	train_acc:0.9523809523809523	test_acc:0.842	test_f1:0.8304877402315191
epoch:17	train_loss:0.22499848902225494	train_acc:0.9571428571428572	test_acc:0.834	test_f1:0.8270920867598759
epoch:18	train_loss:0.1886858344078064	train_acc:0.9642857142857143	test_acc:0.833	test_f1:0.828254970054695
epoch:19	train_loss:0.1692892611026764	train_acc:0.9761904761904762	test_acc:0.837	test_f1:0.8320331422922994
epoch:20	train_loss:0.14921005070209503	train_acc:0.9785714285714285	test_acc:0.836	test_f1:0.828601597131437
epoch:21	train_loss:0.13453292846679688	train_acc:0.9880952380952381	test_acc:0.834	test_f1:0.8276966640147245
epoch:22	train_loss:0.12067177891731262	train_acc:0.9880952380952381	test_acc:0.839	test_f1:0.8309592926556638
epoch:23	train_loss:0.10973992943763733	train_acc:0.9952380952380953	test_acc:0.837	test_f1:0.827067272802019
epoch:24	train_loss:0.09562234580516815	train_acc:1.0	test_acc:0.837	test_f1:0.8288750802937132
epoch:25	train_loss:0.08900229632854462	train_acc:1.0	test_acc:0.831	test_f1:0.8248734652663744
epoch:26	train_loss:0.08699192106723785	train_acc:1.0	test_acc:0.82	test_f1:0.8131229768222008
epoch:27	train_loss:0.08346914499998093	train_acc:1.0	test_acc:0.824	test_f1:0.8179833065900776
epoch:28	train_loss:0.07663442939519882	train_acc:1.0	test_acc:0.834	test_f1:0.8208812172557252
epoch:29	train_loss:0.0753655657172203	train_acc:1.0	test_acc:0.832	test_f1:0.8183489965348302
epoch:30	train_loss:0.07486521452665329	train_acc:1.0	test_acc:0.826	test_f1:0.8121178693023651
epoch:31	train_loss:0.07728450745344162	train_acc:1.0	test_acc:0.808	test_f1:0.7980605482070374
epoch:32	train_loss:0.07782411575317383	train_acc:1.0	test_acc:0.812	test_f1:0.8027861913587785
epoch:33	train_loss:0.08289273828268051	train_acc:1.0	test_acc:0.831	test_f1:0.8203682474567634
epoch:34	train_loss:0.08040554821491241	train_acc:1.0	test_acc:0.829	test_f1:0.8175907905606973
epoch:35	train_loss:0.08587868511676788	train_acc:1.0	test_acc:0.822	test_f1:0.8106043810314789
epoch:36	train_loss:0.08275779336690903	train_acc:1.0	test_acc:0.807	test_f1:0.7960366254610005
epoch:37	train_loss:0.07945869117975235	train_acc:1.0	test_acc:0.816	test_f1:0.804527480214334
epoch:38	train_loss:0.08361025899648666	train_acc:1.0	test_acc:0.83	test_f1:0.8175540672663576
epoch:39	train_loss:0.07931429147720337	train_acc:1.0	test_acc:0.825	test_f1:0.8151669417879741
epoch:40	train_loss:0.08334656804800034	train_acc:1.0	test_acc:0.82	test_f1:0.8092791331678875
epoch:41	train_loss:0.07320481538772583	train_acc:1.0	test_acc:0.826	test_f1:0.8137553301780045
epoch:42	train_loss:0.07515574991703033	train_acc:1.0	test_acc:0.829	test_f1:0.817774608902752
epoch:43	train_loss:0.07095585763454437	train_acc:1.0	test_acc:0.821	test_f1:0.813321011625178
epoch:44	train_loss:0.07319595664739609	train_acc:1.0	test_acc:0.818	test_f1:0.8102007168942215
epoch:45	train_loss:0.07063870131969452	train_acc:1.0	test_acc:0.838	test_f1:0.8249210914473578
epoch:46	train_loss:0.06593069434165955	train_acc:1.0	test_acc:0.832	test_f1:0.8194564110561622
epoch:47	train_loss:0.06463507562875748	train_acc:1.0	test_acc:0.808	test_f1:0.8019466943160617
epoch:48	train_loss:0.0623781718313694	train_acc:1.0	test_acc:0.82	test_f1:0.8120551453359004
epoch:49	train_loss:0.05902623012661934	train_acc:1.0	test_acc:0.843	test_f1:0.8279618055498625
epoch:50	train_loss:0.05754490941762924	train_acc:1.0	test_acc:0.837	test_f1:0.8235760560356831
训练并测试结束，共训练50轮，总用时161.39957213401794s
最佳正确率为:0.844,对应的macro_f1为:0.8284299295029385,对应的训练轮次为:15



2022-07-02 01:54:01.872994
epoch:1	train_loss:2.0153584480285645	train_acc:0.1595238095238095	test_acc:0.323	test_f1:0.07999106540025483
epoch:2	train_loss:2.862623929977417	train_acc:0.1738095238095238	test_acc:0.108	test_f1:0.10178957718780726
epoch:3	train_loss:1.829329252243042	train_acc:0.22380952380952382	test_acc:0.288	test_f1:0.20981033564705664
epoch:4	train_loss:1.682544231414795	train_acc:0.3761904761904762	test_acc:0.451	test_f1:0.4014040920133657
epoch:5	train_loss:1.5808380842208862	train_acc:0.5523809523809524	test_acc:0.496	test_f1:0.501373913124994
epoch:6	train_loss:1.3755310773849487	train_acc:0.6428571428571429	test_acc:0.759	test_f1:0.7652779719037345
epoch:7	train_loss:1.103332757949829	train_acc:0.8928571428571429	test_acc:0.718	test_f1:0.6497489249166882
epoch:8	train_loss:0.9034396409988403	train_acc:0.7880952380952381	test_acc:0.791	test_f1:0.766500783803309
epoch:9	train_loss:0.6651867032051086	train_acc:0.8904761904761904	test_acc:0.803	test_f1:0.8054960209517393
epoch:10	train_loss:0.5072193741798401	train_acc:0.9119047619047619	test_acc:0.792	test_f1:0.7925938764247166
epoch:11	train_loss:0.40771934390068054	train_acc:0.8833333333333333	test_acc:0.801	test_f1:0.7972821148845252
epoch:12	train_loss:0.3236628770828247	train_acc:0.9285714285714286	test_acc:0.826	test_f1:0.8206552666222214
epoch:13	train_loss:0.2839732766151428	train_acc:0.9452380952380952	test_acc:0.832	test_f1:0.8252761364391569
epoch:14	train_loss:0.2562621533870697	train_acc:0.9452380952380952	test_acc:0.836	test_f1:0.8290279208619521
epoch:15	train_loss:0.2295532524585724	train_acc:0.9523809523809523	test_acc:0.832	test_f1:0.823160896961259
epoch:16	train_loss:0.19847558438777924	train_acc:0.9738095238095238	test_acc:0.827	test_f1:0.8201018358035993
epoch:17	train_loss:0.17688678205013275	train_acc:0.9738095238095238	test_acc:0.814	test_f1:0.80977999013676
epoch:18	train_loss:0.14571458101272583	train_acc:0.9880952380952381	test_acc:0.812	test_f1:0.8077625192329185
epoch:19	train_loss:0.1339608132839203	train_acc:0.9976190476190476	test_acc:0.816	test_f1:0.8123191181843469
epoch:20	train_loss:0.12100625783205032	train_acc:0.9904761904761905	test_acc:0.815	test_f1:0.8066816677819011
epoch:21	train_loss:0.10758591443300247	train_acc:0.9976190476190476	test_acc:0.821	test_f1:0.8150213847568797
epoch:22	train_loss:0.09829240292310715	train_acc:0.9976190476190476	test_acc:0.822	test_f1:0.8152862857885779
epoch:23	train_loss:0.09905900061130524	train_acc:0.9976190476190476	test_acc:0.812	test_f1:0.8015286784067763
epoch:24	train_loss:0.09787949919700623	train_acc:0.9976190476190476	test_acc:0.808	test_f1:0.7977955647147658
epoch:25	train_loss:0.09614773094654083	train_acc:1.0	test_acc:0.805	test_f1:0.8016123517151339
epoch:26	train_loss:0.09866440296173096	train_acc:1.0	test_acc:0.82	test_f1:0.8098932540699704
epoch:27	train_loss:0.10488336533308029	train_acc:0.9952380952380953	test_acc:0.796	test_f1:0.7863315966174161
epoch:28	train_loss:0.09609483182430267	train_acc:1.0	test_acc:0.8	test_f1:0.7910551865051708
epoch:29	train_loss:0.0985400602221489	train_acc:0.9976190476190476	test_acc:0.822	test_f1:0.8115710750654507
epoch:30	train_loss:0.09810450673103333	train_acc:0.9952380952380953	test_acc:0.802	test_f1:0.7942504138398488
epoch:31	train_loss:0.10304582118988037	train_acc:0.9952380952380953	test_acc:0.83	test_f1:0.8186029405518747
epoch:32	train_loss:0.08618509024381638	train_acc:1.0	test_acc:0.82	test_f1:0.8090396935044932
epoch:33	train_loss:0.09538457542657852	train_acc:1.0	test_acc:0.799	test_f1:0.7950869334175206
epoch:34	train_loss:0.08212029188871384	train_acc:0.9976190476190476	test_acc:0.803	test_f1:0.7992916815325701
epoch:35	train_loss:0.0798831507563591	train_acc:0.9976190476190476	test_acc:0.827	test_f1:0.8149997268492125
epoch:36	train_loss:0.07744351774454117	train_acc:0.9976190476190476	test_acc:0.827	test_f1:0.8159776681379565
epoch:37	train_loss:0.06780938059091568	train_acc:1.0	test_acc:0.815	test_f1:0.7999425377981056
epoch:38	train_loss:0.07591350376605988	train_acc:0.9928571428571429	test_acc:0.817	test_f1:0.8084986982479998
epoch:39	train_loss:0.06809534877538681	train_acc:1.0	test_acc:0.819	test_f1:0.8124156368938894
epoch:40	train_loss:0.07156015932559967	train_acc:0.9928571428571429	test_acc:0.814	test_f1:0.8068738827856061
epoch:41	train_loss:0.07116800546646118	train_acc:0.9976190476190476	test_acc:0.823	test_f1:0.811791261989951
epoch:42	train_loss:0.06211661174893379	train_acc:0.9976190476190476	test_acc:0.82	test_f1:0.8076912832042291
epoch:43	train_loss:0.06397461891174316	train_acc:1.0	test_acc:0.811	test_f1:0.801900503916756
epoch:44	train_loss:0.05789729207754135	train_acc:1.0	test_acc:0.811	test_f1:0.8046482813473731
epoch:45	train_loss:0.06353498250246048	train_acc:1.0	test_acc:0.825	test_f1:0.8140766461591858
epoch:46	train_loss:0.06253822892904282	train_acc:1.0	test_acc:0.816	test_f1:0.8052186533718333
epoch:47	train_loss:0.058173369616270065	train_acc:1.0	test_acc:0.812	test_f1:0.7986507588497908
epoch:48	train_loss:0.06277571618556976	train_acc:1.0	test_acc:0.815	test_f1:0.8050945869932643
epoch:49	train_loss:0.057443760335445404	train_acc:1.0	test_acc:0.832	test_f1:0.8210224488414714
epoch:50	train_loss:0.06360167264938354	train_acc:1.0	test_acc:0.815	test_f1:0.805917075233342
训练并测试结束，共训练50轮，总用时159.99793672561646s
最佳正确率为:0.836,对应的macro_f1为:0.8290279208619521,对应的训练轮次为:14



2022-07-02 01:56:57.027057
epoch:1	train_loss:2.045444965362549	train_acc:0.14047619047619048	test_acc:0.091	test_f1:0.02383134738771769
epoch:2	train_loss:1.9345927238464355	train_acc:0.14285714285714285	test_acc:0.266	test_f1:0.22519687223067186
epoch:3	train_loss:1.9020452499389648	train_acc:0.3404761904761905	test_acc:0.076	test_f1:0.040076735018386746
epoch:4	train_loss:1.892301321029663	train_acc:0.1761904761904762	test_acc:0.078	test_f1:0.03766911481534723
epoch:5	train_loss:1.8716686964035034	train_acc:0.2119047619047619	test_acc:0.334	test_f1:0.24669649772785154
epoch:6	train_loss:1.8357977867126465	train_acc:0.37857142857142856	test_acc:0.588	test_f1:0.48100269480989855
epoch:7	train_loss:1.7996927499771118	train_acc:0.5785714285714286	test_acc:0.742	test_f1:0.665008984380853
epoch:8	train_loss:1.7659943103790283	train_acc:0.7333333333333333	test_acc:0.662	test_f1:0.5977599101088772
epoch:9	train_loss:1.7322027683258057	train_acc:0.7238095238095238	test_acc:0.588	test_f1:0.5862956823068732
epoch:10	train_loss:1.6988139152526855	train_acc:0.7166666666666667	test_acc:0.611	test_f1:0.618593371272656
epoch:11	train_loss:1.6635444164276123	train_acc:0.7619047619047619	test_acc:0.572	test_f1:0.6032740614141382
epoch:12	train_loss:1.6313029527664185	train_acc:0.7357142857142858	test_acc:0.519	test_f1:0.5832558114961665
epoch:13	train_loss:1.5884286165237427	train_acc:0.7404761904761905	test_acc:0.553	test_f1:0.6138606813494377
epoch:14	train_loss:1.5439828634262085	train_acc:0.7690476190476191	test_acc:0.66	test_f1:0.6842349362934533
epoch:15	train_loss:1.4966912269592285	train_acc:0.8476190476190476	test_acc:0.761	test_f1:0.750282363088966
epoch:16	train_loss:1.4469670057296753	train_acc:0.8857142857142857	test_acc:0.79	test_f1:0.7767400002322276
epoch:17	train_loss:1.3988425731658936	train_acc:0.8952380952380953	test_acc:0.797	test_f1:0.7840043291010502
epoch:18	train_loss:1.3472145795822144	train_acc:0.888095238095238	test_acc:0.787	test_f1:0.7717646875406196
epoch:19	train_loss:1.2932474613189697	train_acc:0.8761904761904762	test_acc:0.785	test_f1:0.7679458910594902
epoch:20	train_loss:1.2394604682922363	train_acc:0.8714285714285714	test_acc:0.778	test_f1:0.7619278638893163
epoch:21	train_loss:1.1789673566818237	train_acc:0.8761904761904762	test_acc:0.776	test_f1:0.762269168069035
epoch:22	train_loss:1.1228764057159424	train_acc:0.8833333333333333	test_acc:0.783	test_f1:0.7735836358482976
epoch:23	train_loss:1.0722906589508057	train_acc:0.8928571428571429	test_acc:0.79	test_f1:0.781611365302083
epoch:24	train_loss:1.0085091590881348	train_acc:0.8928571428571429	test_acc:0.794	test_f1:0.7870193153691781
epoch:25	train_loss:0.9508370757102966	train_acc:0.9071428571428571	test_acc:0.795	test_f1:0.787231497999884
epoch:26	train_loss:0.8997425436973572	train_acc:0.9071428571428571	test_acc:0.802	test_f1:0.7942121295785413
epoch:27	train_loss:0.8449636697769165	train_acc:0.9047619047619048	test_acc:0.801	test_f1:0.7943999074311353
epoch:28	train_loss:0.7869575619697571	train_acc:0.9	test_acc:0.804	test_f1:0.7971014201934518
epoch:29	train_loss:0.7366684079170227	train_acc:0.9071428571428571	test_acc:0.806	test_f1:0.8000717988104175
epoch:30	train_loss:0.6975404620170593	train_acc:0.9071428571428571	test_acc:0.813	test_f1:0.8075359828786056
epoch:31	train_loss:0.6497138142585754	train_acc:0.9047619047619048	test_acc:0.811	test_f1:0.8050881608050512
epoch:32	train_loss:0.6012450456619263	train_acc:0.9166666666666666	test_acc:0.808	test_f1:0.801250041774109
epoch:33	train_loss:0.5582690834999084	train_acc:0.9166666666666666	test_acc:0.81	test_f1:0.8038141416833146
epoch:34	train_loss:0.526846170425415	train_acc:0.9166666666666666	test_acc:0.812	test_f1:0.8057170461825125
epoch:35	train_loss:0.49122175574302673	train_acc:0.9214285714285714	test_acc:0.815	test_f1:0.8091939425275232
epoch:36	train_loss:0.45383694767951965	train_acc:0.9214285714285714	test_acc:0.816	test_f1:0.8086479345673071
epoch:37	train_loss:0.4296271800994873	train_acc:0.9333333333333333	test_acc:0.815	test_f1:0.8073631706267653
epoch:38	train_loss:0.405584454536438	train_acc:0.930952380952381	test_acc:0.816	test_f1:0.8075235600807649
epoch:39	train_loss:0.37913787364959717	train_acc:0.9380952380952381	test_acc:0.82	test_f1:0.8126212386269992
epoch:40	train_loss:0.35513079166412354	train_acc:0.9404761904761905	test_acc:0.82	test_f1:0.8132613635609649
epoch:41	train_loss:0.3328859210014343	train_acc:0.9428571428571428	test_acc:0.823	test_f1:0.8159793551282621
epoch:42	train_loss:0.3139815330505371	train_acc:0.95	test_acc:0.826	test_f1:0.8174337649843341
epoch:43	train_loss:0.29530414938926697	train_acc:0.95	test_acc:0.825	test_f1:0.8156733446351513
epoch:44	train_loss:0.28016534447669983	train_acc:0.9523809523809523	test_acc:0.826	test_f1:0.8169502312744541
epoch:45	train_loss:0.26200437545776367	train_acc:0.9523809523809523	test_acc:0.829	test_f1:0.8192239188112602
epoch:46	train_loss:0.24864345788955688	train_acc:0.9642857142857143	test_acc:0.831	test_f1:0.8211608191688295
epoch:47	train_loss:0.23345956206321716	train_acc:0.9666666666666667	test_acc:0.831	test_f1:0.8213440496202761
epoch:48	train_loss:0.22351470589637756	train_acc:0.969047619047619	test_acc:0.83	test_f1:0.8198456134316068
epoch:49	train_loss:0.2121955156326294	train_acc:0.9714285714285714	test_acc:0.832	test_f1:0.8225629493158582
epoch:50	train_loss:0.20639671385288239	train_acc:0.9666666666666667	test_acc:0.832	test_f1:0.8230525357913089
训练并测试结束，共训练50轮，总用时160.14507460594177s
最佳正确率为:0.832,对应的macro_f1为:0.8230525357913089,对应的训练轮次为:50



2022-07-02 02:00:07.161421
epoch:1	train_loss:1.9620991945266724	train_acc:0.14285714285714285	test_acc:0.091	test_f1:0.02383134738771769
epoch:2	train_loss:2.037491798400879	train_acc:0.14285714285714285	test_acc:0.159	test_f1:0.15796418407609145
epoch:3	train_loss:1.8357759714126587	train_acc:0.28095238095238095	test_acc:0.4	test_f1:0.20640512438417474
epoch:4	train_loss:1.7642467021942139	train_acc:0.2904761904761905	test_acc:0.514	test_f1:0.3646820108822317
epoch:5	train_loss:1.6945972442626953	train_acc:0.4928571428571429	test_acc:0.391	test_f1:0.3809360454792854
epoch:6	train_loss:1.5809496641159058	train_acc:0.5190476190476191	test_acc:0.491	test_f1:0.49742228136837374
epoch:7	train_loss:1.4574918746948242	train_acc:0.65	test_acc:0.6	test_f1:0.620937516935885
epoch:8	train_loss:1.3290091753005981	train_acc:0.819047619047619	test_acc:0.605	test_f1:0.6207284807095431
epoch:9	train_loss:1.2035746574401855	train_acc:0.8380952380952381	test_acc:0.666	test_f1:0.6616016464016843
epoch:10	train_loss:1.0806732177734375	train_acc:0.8428571428571429	test_acc:0.769	test_f1:0.7378970470231164
epoch:11	train_loss:0.9550061225891113	train_acc:0.8690476190476191	test_acc:0.804	test_f1:0.7818696853432562
epoch:12	train_loss:0.8263019323348999	train_acc:0.8976190476190476	test_acc:0.82	test_f1:0.8078546126039552
epoch:13	train_loss:0.7152407765388489	train_acc:0.9023809523809524	test_acc:0.807	test_f1:0.8021841794515611
epoch:14	train_loss:0.6120820045471191	train_acc:0.9047619047619048	test_acc:0.779	test_f1:0.7855616999456608
epoch:15	train_loss:0.5398805737495422	train_acc:0.9047619047619048	test_acc:0.779	test_f1:0.7845733888350546
epoch:16	train_loss:0.4626941382884979	train_acc:0.9238095238095239	test_acc:0.798	test_f1:0.7945169621904025
epoch:17	train_loss:0.3950926959514618	train_acc:0.9166666666666666	test_acc:0.822	test_f1:0.8113006639747525
epoch:18	train_loss:0.336111843585968	train_acc:0.9428571428571428	test_acc:0.832	test_f1:0.8198150784596299
epoch:19	train_loss:0.2938254177570343	train_acc:0.9476190476190476	test_acc:0.827	test_f1:0.813822637764123
epoch:20	train_loss:0.2549056112766266	train_acc:0.95	test_acc:0.822	test_f1:0.8129891641631666
epoch:21	train_loss:0.22377364337444305	train_acc:0.95	test_acc:0.807	test_f1:0.8010475936591084
epoch:22	train_loss:0.19112133979797363	train_acc:0.9595238095238096	test_acc:0.81	test_f1:0.8030882802027764
epoch:23	train_loss:0.1730383038520813	train_acc:0.9642857142857143	test_acc:0.817	test_f1:0.8107059861155042
epoch:24	train_loss:0.1493297517299652	train_acc:0.969047619047619	test_acc:0.821	test_f1:0.8136779084025448
epoch:25	train_loss:0.12678031623363495	train_acc:0.9809523809523809	test_acc:0.827	test_f1:0.8171644951909581
epoch:26	train_loss:0.11643260717391968	train_acc:0.9880952380952381	test_acc:0.837	test_f1:0.826333856216463
epoch:27	train_loss:0.10202602297067642	train_acc:0.9904761904761905	test_acc:0.834	test_f1:0.8237559076287785
epoch:28	train_loss:0.0904310792684555	train_acc:0.9976190476190476	test_acc:0.833	test_f1:0.8248233401227435
epoch:29	train_loss:0.0874411016702652	train_acc:0.9928571428571429	test_acc:0.831	test_f1:0.8227667147650294
epoch:30	train_loss:0.07796334475278854	train_acc:0.9976190476190476	test_acc:0.831	test_f1:0.8233793106280853
epoch:31	train_loss:0.07428985834121704	train_acc:1.0	test_acc:0.83	test_f1:0.8213673570872124
epoch:32	train_loss:0.06977108120918274	train_acc:1.0	test_acc:0.832	test_f1:0.8232887063080202
epoch:33	train_loss:0.06924016028642654	train_acc:1.0	test_acc:0.829	test_f1:0.8220410732866172
epoch:34	train_loss:0.06576959043741226	train_acc:1.0	test_acc:0.825	test_f1:0.8174144407870548
epoch:35	train_loss:0.06373278051614761	train_acc:1.0	test_acc:0.829	test_f1:0.8194017780664525
epoch:36	train_loss:0.061944711953401566	train_acc:1.0	test_acc:0.831	test_f1:0.8188608020639625
epoch:37	train_loss:0.06597594171762466	train_acc:0.9976190476190476	test_acc:0.822	test_f1:0.8113876939571953
epoch:38	train_loss:0.06214421987533569	train_acc:1.0	test_acc:0.818	test_f1:0.8094504588347978
epoch:39	train_loss:0.06154995039105415	train_acc:1.0	test_acc:0.816	test_f1:0.8090173011140116
epoch:40	train_loss:0.06499134749174118	train_acc:1.0	test_acc:0.818	test_f1:0.810940997357151
epoch:41	train_loss:0.06639019399881363	train_acc:1.0	test_acc:0.831	test_f1:0.8193124250796743
epoch:42	train_loss:0.06751270592212677	train_acc:1.0	test_acc:0.829	test_f1:0.8192369532307803
epoch:43	train_loss:0.06726300716400146	train_acc:1.0	test_acc:0.822	test_f1:0.8138151952623512
epoch:44	train_loss:0.06840463727712631	train_acc:1.0	test_acc:0.823	test_f1:0.8147301279007405
epoch:45	train_loss:0.06851980090141296	train_acc:1.0	test_acc:0.824	test_f1:0.8135151922515499
epoch:46	train_loss:0.06889447569847107	train_acc:1.0	test_acc:0.822	test_f1:0.8095859649407019
epoch:47	train_loss:0.07192187011241913	train_acc:1.0	test_acc:0.821	test_f1:0.8099666037979476
epoch:48	train_loss:0.0708823874592781	train_acc:1.0	test_acc:0.823	test_f1:0.8153171912156612
epoch:49	train_loss:0.07103154063224792	train_acc:1.0	test_acc:0.826	test_f1:0.8175251983855067
epoch:50	train_loss:0.07067830115556717	train_acc:1.0	test_acc:0.833	test_f1:0.8223910202905119
训练并测试结束，共训练50轮，总用时161.09437727928162s
最佳正确率为:0.837,对应的macro_f1为:0.826333856216463,对应的训练轮次为:26



2022-07-02 02:03:21.304503
epoch:1	train_loss:1.9676339626312256	train_acc:0.14285714285714285	test_acc:0.131	test_f1:0.03486934250197437
epoch:2	train_loss:2.32255482673645	train_acc:0.14523809523809525	test_acc:0.355	test_f1:0.16487237326328033
epoch:3	train_loss:1.891955018043518	train_acc:0.26904761904761904	test_acc:0.419	test_f1:0.3047246054197439
epoch:4	train_loss:1.7067323923110962	train_acc:0.5428571428571428	test_acc:0.274	test_f1:0.2997047004841113
epoch:5	train_loss:1.62168550491333	train_acc:0.4380952380952381	test_acc:0.237	test_f1:0.2500546497761304
epoch:6	train_loss:1.4935113191604614	train_acc:0.36904761904761907	test_acc:0.507	test_f1:0.5354269167734256
epoch:7	train_loss:1.2779121398925781	train_acc:0.7261904761904762	test_acc:0.794	test_f1:0.7741594190709715
epoch:8	train_loss:1.0929481983184814	train_acc:0.8857142857142857	test_acc:0.775	test_f1:0.7591465306029587
epoch:9	train_loss:0.9250044226646423	train_acc:0.861904761904762	test_acc:0.779	test_f1:0.7659950112829959
epoch:10	train_loss:0.7603349089622498	train_acc:0.8738095238095238	test_acc:0.819	test_f1:0.8112295152857818
epoch:11	train_loss:0.5956167578697205	train_acc:0.9119047619047619	test_acc:0.793	test_f1:0.7942600978487867
epoch:12	train_loss:0.4831027686595917	train_acc:0.9285714285714286	test_acc:0.765	test_f1:0.7702139484077251
epoch:13	train_loss:0.40776026248931885	train_acc:0.9166666666666666	test_acc:0.79	test_f1:0.7846767548969948
epoch:14	train_loss:0.334607869386673	train_acc:0.9261904761904762	test_acc:0.817	test_f1:0.8099051204714584
epoch:15	train_loss:0.2831723093986511	train_acc:0.9380952380952381	test_acc:0.828	test_f1:0.8177459970717954
epoch:16	train_loss:0.2528199255466461	train_acc:0.9404761904761905	test_acc:0.824	test_f1:0.8162561398884333
epoch:17	train_loss:0.22718031704425812	train_acc:0.9523809523809523	test_acc:0.828	test_f1:0.8189481739431427
epoch:18	train_loss:0.1966182291507721	train_acc:0.9619047619047619	test_acc:0.825	test_f1:0.8161837696341863
epoch:19	train_loss:0.17757603526115417	train_acc:0.9642857142857143	test_acc:0.814	test_f1:0.8047870851659207
epoch:20	train_loss:0.15564624965190887	train_acc:0.9785714285714285	test_acc:0.811	test_f1:0.8008616724045361
epoch:21	train_loss:0.14297540485858917	train_acc:0.9833333333333333	test_acc:0.822	test_f1:0.8152814923491493
epoch:22	train_loss:0.12555816769599915	train_acc:0.9952380952380953	test_acc:0.821	test_f1:0.813595084609099
epoch:23	train_loss:0.1101955771446228	train_acc:1.0	test_acc:0.825	test_f1:0.818609713201228
epoch:24	train_loss:0.10629197210073471	train_acc:0.9976190476190476	test_acc:0.827	test_f1:0.8179765571544145
epoch:25	train_loss:0.09904841333627701	train_acc:1.0	test_acc:0.833	test_f1:0.8211949280797824
epoch:26	train_loss:0.09191979467868805	train_acc:0.9976190476190476	test_acc:0.825	test_f1:0.8140834615927488
epoch:27	train_loss:0.08843261748552322	train_acc:1.0	test_acc:0.813	test_f1:0.8051497371263563
epoch:28	train_loss:0.08727005124092102	train_acc:1.0	test_acc:0.809	test_f1:0.8019176004568063
epoch:29	train_loss:0.08708012849092484	train_acc:1.0	test_acc:0.812	test_f1:0.8052778315237582
epoch:30	train_loss:0.08697749674320221	train_acc:1.0	test_acc:0.822	test_f1:0.809667233980825
epoch:31	train_loss:0.08806531131267548	train_acc:1.0	test_acc:0.82	test_f1:0.8068832030089502
epoch:32	train_loss:0.08766235411167145	train_acc:1.0	test_acc:0.812	test_f1:0.8033311813238091
epoch:33	train_loss:0.08519589900970459	train_acc:1.0	test_acc:0.809	test_f1:0.8014918505608131
epoch:34	train_loss:0.09043203294277191	train_acc:1.0	test_acc:0.82	test_f1:0.8110904632668428
epoch:35	train_loss:0.0887124165892601	train_acc:1.0	test_acc:0.818	test_f1:0.8064381508991898
epoch:36	train_loss:0.08639657497406006	train_acc:1.0	test_acc:0.814	test_f1:0.8034067741628083
epoch:37	train_loss:0.09030022472143173	train_acc:1.0	test_acc:0.811	test_f1:0.8046365551709816
epoch:38	train_loss:0.08718762546777725	train_acc:0.9976190476190476	test_acc:0.817	test_f1:0.8094687062029797
epoch:39	train_loss:0.08121563494205475	train_acc:1.0	test_acc:0.821	test_f1:0.8101029091002575
epoch:40	train_loss:0.08049893379211426	train_acc:1.0	test_acc:0.818	test_f1:0.8078239293797564
epoch:41	train_loss:0.08082331717014313	train_acc:1.0	test_acc:0.819	test_f1:0.8100635712968389
epoch:42	train_loss:0.07621439546346664	train_acc:1.0	test_acc:0.827	test_f1:0.8157589730310887
epoch:43	train_loss:0.07572133839130402	train_acc:1.0	test_acc:0.829	test_f1:0.8177030927661532
epoch:44	train_loss:0.07367391139268875	train_acc:1.0	test_acc:0.825	test_f1:0.8139711833946803
epoch:45	train_loss:0.07135200500488281	train_acc:1.0	test_acc:0.813	test_f1:0.8064109022456599
epoch:46	train_loss:0.06718612462282181	train_acc:1.0	test_acc:0.817	test_f1:0.8049375757075296
epoch:47	train_loss:0.06330995261669159	train_acc:1.0	test_acc:0.832	test_f1:0.8197261952914496
epoch:48	train_loss:0.06368265300989151	train_acc:1.0	test_acc:0.829	test_f1:0.8186506352645223
epoch:49	train_loss:0.0657629668712616	train_acc:1.0	test_acc:0.823	test_f1:0.8128276889582908
epoch:50	train_loss:0.06113796681165695	train_acc:1.0	test_acc:0.817	test_f1:0.80765431143412
训练并测试结束，共训练50轮，总用时174.44617700576782s
最佳正确率为:0.833,对应的macro_f1为:0.8211949280797824,对应的训练轮次为:25



2022-07-02 02:06:26.147918
epoch:1	train_loss:2.009730815887451	train_acc:0.14285714285714285	test_acc:0.319	test_f1:0.06909996750785227
epoch:2	train_loss:2.210611581802368	train_acc:0.15	test_acc:0.189	test_f1:0.14698623735270175
epoch:3	train_loss:1.9595258235931396	train_acc:0.2619047619047619	test_acc:0.275	test_f1:0.2581046705497724
epoch:4	train_loss:1.7283105850219727	train_acc:0.4142857142857143	test_acc:0.501	test_f1:0.526787557768826
epoch:5	train_loss:1.5567620992660522	train_acc:0.6928571428571428	test_acc:0.244	test_f1:0.2485663046507649
epoch:6	train_loss:1.4487602710723877	train_acc:0.38571428571428573	test_acc:0.577	test_f1:0.5791091175082437
epoch:7	train_loss:1.2613577842712402	train_acc:0.7404761904761905	test_acc:0.74	test_f1:0.7111816873266008
epoch:8	train_loss:1.068795919418335	train_acc:0.8666666666666667	test_acc:0.768	test_f1:0.7486214991534273
epoch:9	train_loss:0.8821578621864319	train_acc:0.8928571428571429	test_acc:0.756	test_f1:0.7584423921760121
epoch:10	train_loss:0.7294824123382568	train_acc:0.8809523809523809	test_acc:0.788	test_f1:0.7856092209930126
epoch:11	train_loss:0.588908314704895	train_acc:0.8952380952380953	test_acc:0.818	test_f1:0.8099152264042029
epoch:12	train_loss:0.4658743739128113	train_acc:0.9047619047619048	test_acc:0.815	test_f1:0.8055733621069816
epoch:13	train_loss:0.3825744688510895	train_acc:0.9119047619047619	test_acc:0.814	test_f1:0.8074242650936252
epoch:14	train_loss:0.33242306113243103	train_acc:0.9238095238095239	test_acc:0.821	test_f1:0.8121837036900242
epoch:15	train_loss:0.27444660663604736	train_acc:0.9404761904761905	test_acc:0.831	test_f1:0.8224768590678009
epoch:16	train_loss:0.23339757323265076	train_acc:0.95	test_acc:0.835	test_f1:0.8254879480843698
epoch:17	train_loss:0.20901794731616974	train_acc:0.9619047619047619	test_acc:0.838	test_f1:0.8295722978860073
epoch:18	train_loss:0.17866122722625732	train_acc:0.969047619047619	test_acc:0.839	test_f1:0.8318810842002236
epoch:19	train_loss:0.16334383189678192	train_acc:0.9714285714285714	test_acc:0.832	test_f1:0.8243262333207811
epoch:20	train_loss:0.13609212636947632	train_acc:0.9833333333333333	test_acc:0.822	test_f1:0.8140422528744355
epoch:21	train_loss:0.12337644398212433	train_acc:0.9904761904761905	test_acc:0.824	test_f1:0.8154963626586943
epoch:22	train_loss:0.11372457444667816	train_acc:0.9928571428571429	test_acc:0.834	test_f1:0.8236722621009077
epoch:23	train_loss:0.10440640151500702	train_acc:0.9928571428571429	test_acc:0.835	test_f1:0.8243766983501546
epoch:24	train_loss:0.09309675544500351	train_acc:0.9976190476190476	test_acc:0.828	test_f1:0.8178364522300251
epoch:25	train_loss:0.08809377253055573	train_acc:0.9976190476190476	test_acc:0.816	test_f1:0.8082457043896307
epoch:26	train_loss:0.0807102769613266	train_acc:1.0	test_acc:0.82	test_f1:0.8118184420903708
epoch:27	train_loss:0.082283616065979	train_acc:1.0	test_acc:0.836	test_f1:0.8246329563837003
epoch:28	train_loss:0.08083799481391907	train_acc:1.0	test_acc:0.837	test_f1:0.8240023144258484
epoch:29	train_loss:0.08156582713127136	train_acc:1.0	test_acc:0.821	test_f1:0.8111106920071723
epoch:30	train_loss:0.0825764387845993	train_acc:1.0	test_acc:0.809	test_f1:0.8021369804520991
epoch:31	train_loss:0.08543957769870758	train_acc:1.0	test_acc:0.815	test_f1:0.8059581827648769
epoch:32	train_loss:0.08670616894960403	train_acc:0.9976190476190476	test_acc:0.831	test_f1:0.8152876079129436
epoch:33	train_loss:0.08668117225170135	train_acc:1.0	test_acc:0.818	test_f1:0.8070319180192304
epoch:34	train_loss:0.08106816560029984	train_acc:1.0	test_acc:0.816	test_f1:0.809862565967218
epoch:35	train_loss:0.0893036499619484	train_acc:0.9976190476190476	test_acc:0.826	test_f1:0.8155246450100221
epoch:36	train_loss:0.08589345961809158	train_acc:1.0	test_acc:0.831	test_f1:0.8159947722910978
epoch:37	train_loss:0.08476635813713074	train_acc:1.0	test_acc:0.82	test_f1:0.8083405445743878
epoch:38	train_loss:0.08057869225740433	train_acc:1.0	test_acc:0.804	test_f1:0.7990071240920127
epoch:39	train_loss:0.08789233863353729	train_acc:1.0	test_acc:0.82	test_f1:0.8099673056271783
epoch:40	train_loss:0.07787727564573288	train_acc:1.0	test_acc:0.836	test_f1:0.8193824421577244
epoch:41	train_loss:0.07687695324420929	train_acc:1.0	test_acc:0.829	test_f1:0.8176351063693771
epoch:42	train_loss:0.07064129412174225	train_acc:1.0	test_acc:0.815	test_f1:0.8060796721282546
epoch:43	train_loss:0.07280915975570679	train_acc:1.0	test_acc:0.826	test_f1:0.813813522767091
epoch:44	train_loss:0.06807649880647659	train_acc:1.0	test_acc:0.837	test_f1:0.8221556286700579
epoch:45	train_loss:0.06712350994348526	train_acc:0.9976190476190476	test_acc:0.822	test_f1:0.8110964224492034
epoch:46	train_loss:0.06415823847055435	train_acc:1.0	test_acc:0.807	test_f1:0.7998786549220641
epoch:47	train_loss:0.06431751698255539	train_acc:1.0	test_acc:0.814	test_f1:0.8031134938566442
epoch:48	train_loss:0.06490025669336319	train_acc:1.0	test_acc:0.832	test_f1:0.817898610767519
epoch:49	train_loss:0.0605773963034153	train_acc:0.9976190476190476	test_acc:0.829	test_f1:0.8179714333510866
epoch:50	train_loss:0.056864410638809204	train_acc:1.0	test_acc:0.819	test_f1:0.8122151151839246
训练并测试结束，共训练50轮，总用时199.95767998695374s
最佳正确率为:0.839,对应的macro_f1为:0.8318810842002236,对应的训练轮次为:18



2022-07-02 02:11:02.022323
epoch:1	train_loss:1.9752557277679443	train_acc:0.1380952380952381	test_acc:0.103	test_f1:0.026680481802875276
epoch:2	train_loss:2.3446390628814697	train_acc:0.14285714285714285	test_acc:0.211	test_f1:0.11881050229132827
epoch:3	train_loss:1.9580020904541016	train_acc:0.23333333333333334	test_acc:0.431	test_f1:0.4184915275677378
epoch:4	train_loss:1.7242716550827026	train_acc:0.5261904761904762	test_acc:0.505	test_f1:0.34444051696411204
epoch:5	train_loss:1.6592166423797607	train_acc:0.49047619047619045	test_acc:0.535	test_f1:0.4119201167106243
epoch:6	train_loss:1.5635919570922852	train_acc:0.4642857142857143	test_acc:0.577	test_f1:0.4779190364914337
epoch:7	train_loss:1.4048672914505005	train_acc:0.5857142857142857	test_acc:0.732	test_f1:0.6976091087839452
epoch:8	train_loss:1.2125567197799683	train_acc:0.8357142857142857	test_acc:0.757	test_f1:0.759112131040243
epoch:9	train_loss:1.0246031284332275	train_acc:0.8952380952380953	test_acc:0.637	test_f1:0.6857313412079059
epoch:10	train_loss:0.8746063113212585	train_acc:0.8357142857142857	test_acc:0.69	test_f1:0.7266356492023112
epoch:11	train_loss:0.7206652760505676	train_acc:0.8761904761904762	test_acc:0.813	test_f1:0.8076529378425287
epoch:12	train_loss:0.5759077072143555	train_acc:0.9047619047619048	test_acc:0.81	test_f1:0.7982292142921522
epoch:13	train_loss:0.47098395228385925	train_acc:0.919047619047619	test_acc:0.806	test_f1:0.7955083795653347
epoch:14	train_loss:0.40508130192756653	train_acc:0.9166666666666666	test_acc:0.815	test_f1:0.8017738161007353
epoch:15	train_loss:0.34652093052864075	train_acc:0.9166666666666666	test_acc:0.822	test_f1:0.8124528460063035
epoch:16	train_loss:0.2895863354206085	train_acc:0.9333333333333333	test_acc:0.816	test_f1:0.809951138009447
epoch:17	train_loss:0.25445756316185	train_acc:0.9404761904761905	test_acc:0.819	test_f1:0.814973840304906
epoch:18	train_loss:0.23300260305404663	train_acc:0.95	test_acc:0.815	test_f1:0.8144622071351887
epoch:19	train_loss:0.20680363476276398	train_acc:0.9523809523809523	test_acc:0.822	test_f1:0.8184677316508754
epoch:20	train_loss:0.17506346106529236	train_acc:0.9738095238095238	test_acc:0.836	test_f1:0.8267218204688288
epoch:21	train_loss:0.15993614494800568	train_acc:0.9714285714285714	test_acc:0.842	test_f1:0.8296216568296026
epoch:22	train_loss:0.1436854600906372	train_acc:0.9904761904761905	test_acc:0.843	test_f1:0.8311546410471242
epoch:23	train_loss:0.12659406661987305	train_acc:0.9952380952380953	test_acc:0.845	test_f1:0.8342842388360355
epoch:24	train_loss:0.11185265332460403	train_acc:0.9952380952380953	test_acc:0.825	test_f1:0.82092882442918
epoch:25	train_loss:0.10056056827306747	train_acc:1.0	test_acc:0.822	test_f1:0.8178955049476274
epoch:26	train_loss:0.09791015088558197	train_acc:0.9976190476190476	test_acc:0.831	test_f1:0.823811381914264
epoch:27	train_loss:0.08798044919967651	train_acc:1.0	test_acc:0.831	test_f1:0.8219582473964465
epoch:28	train_loss:0.08352077007293701	train_acc:1.0	test_acc:0.826	test_f1:0.8172651553115643
epoch:29	train_loss:0.08564034849405289	train_acc:1.0	test_acc:0.821	test_f1:0.811319180322205
epoch:30	train_loss:0.08936907351016998	train_acc:1.0	test_acc:0.814	test_f1:0.8034807486745196
epoch:31	train_loss:0.08436012268066406	train_acc:1.0	test_acc:0.829	test_f1:0.8194226006753239
epoch:32	train_loss:0.08490324765443802	train_acc:1.0	test_acc:0.833	test_f1:0.8243189315888593
epoch:33	train_loss:0.08539430052042007	train_acc:1.0	test_acc:0.84	test_f1:0.8307998829742022
epoch:34	train_loss:0.08498071879148483	train_acc:1.0	test_acc:0.825	test_f1:0.8168209185403116
epoch:35	train_loss:0.0838179960846901	train_acc:1.0	test_acc:0.825	test_f1:0.8162169077559386
epoch:36	train_loss:0.08663099259138107	train_acc:1.0	test_acc:0.815	test_f1:0.8051877581415958
epoch:37	train_loss:0.08882755786180496	train_acc:1.0	test_acc:0.818	test_f1:0.8079627184563227
epoch:38	train_loss:0.08340439200401306	train_acc:1.0	test_acc:0.827	test_f1:0.8137314112481085
epoch:39	train_loss:0.08460263162851334	train_acc:1.0	test_acc:0.831	test_f1:0.8204075379798939
epoch:40	train_loss:0.07998377829790115	train_acc:1.0	test_acc:0.834	test_f1:0.8240648365770682
epoch:41	train_loss:0.07939387112855911	train_acc:1.0	test_acc:0.828	test_f1:0.8156640853100584
epoch:42	train_loss:0.07798948884010315	train_acc:1.0	test_acc:0.827	test_f1:0.8175441543603116
epoch:43	train_loss:0.08107311278581619	train_acc:1.0	test_acc:0.822	test_f1:0.8107551079536724
epoch:44	train_loss:0.07440351694822311	train_acc:1.0	test_acc:0.831	test_f1:0.8207732327294075
epoch:45	train_loss:0.07022450119256973	train_acc:1.0	test_acc:0.836	test_f1:0.8268844177903835
epoch:46	train_loss:0.06750234961509705	train_acc:1.0	test_acc:0.827	test_f1:0.8180039684485184
epoch:47	train_loss:0.06844204664230347	train_acc:1.0	test_acc:0.822	test_f1:0.8123087591458299
epoch:48	train_loss:0.06941705197095871	train_acc:1.0	test_acc:0.827	test_f1:0.8145058983533018
epoch:49	train_loss:0.0627785250544548	train_acc:1.0	test_acc:0.833	test_f1:0.8211403241395239
epoch:50	train_loss:0.06485285609960556	train_acc:1.0	test_acc:0.826	test_f1:0.8182616431777878
训练并测试结束，共训练50轮，总用时200.96100854873657s
最佳正确率为:0.845,对应的macro_f1为:0.8342842388360355,对应的训练轮次为:23



2022-07-02 02:14:31.549077
epoch:1	train_loss:1.9828064441680908	train_acc:0.1619047619047619	test_acc:0.356	test_f1:0.14862092479434783
epoch:2	train_loss:2.220533847808838	train_acc:0.23333333333333334	test_acc:0.479	test_f1:0.29823609773416926
epoch:3	train_loss:1.7901499271392822	train_acc:0.4357142857142857	test_acc:0.318	test_f1:0.3203138637382605
epoch:4	train_loss:1.6377184391021729	train_acc:0.43333333333333335	test_acc:0.351	test_f1:0.2980217399357316
epoch:5	train_loss:1.5388123989105225	train_acc:0.4714285714285714	test_acc:0.424	test_f1:0.45583467963802676
epoch:6	train_loss:1.3513453006744385	train_acc:0.6404761904761904	test_acc:0.584	test_f1:0.6285732223094698
epoch:7	train_loss:1.1231616735458374	train_acc:0.8238095238095238	test_acc:0.809	test_f1:0.7972286990377092
epoch:8	train_loss:0.9136751890182495	train_acc:0.8952380952380953	test_acc:0.774	test_f1:0.7584087245439217
epoch:9	train_loss:0.7552706599235535	train_acc:0.8785714285714286	test_acc:0.807	test_f1:0.7949377601866056
epoch:10	train_loss:0.5971567630767822	train_acc:0.9095238095238095	test_acc:0.812	test_f1:0.8063021373811254
epoch:11	train_loss:0.4700016975402832	train_acc:0.9166666666666666	test_acc:0.779	test_f1:0.7788944071785028
epoch:12	train_loss:0.3933980464935303	train_acc:0.9119047619047619	test_acc:0.782	test_f1:0.7778080113913595
epoch:13	train_loss:0.33868545293807983	train_acc:0.9142857142857143	test_acc:0.807	test_f1:0.8016658133732133
epoch:14	train_loss:0.2829633057117462	train_acc:0.9404761904761905	test_acc:0.825	test_f1:0.8176632537145683
epoch:15	train_loss:0.2506251931190491	train_acc:0.95	test_acc:0.836	test_f1:0.8284552311908675
epoch:16	train_loss:0.22704127430915833	train_acc:0.9547619047619048	test_acc:0.842	test_f1:0.8315069133122429
epoch:17	train_loss:0.2001548558473587	train_acc:0.9642857142857143	test_acc:0.843	test_f1:0.8346630909727792
epoch:18	train_loss:0.17627224326133728	train_acc:0.9738095238095238	test_acc:0.836	test_f1:0.8287267262577993
epoch:19	train_loss:0.15481485426425934	train_acc:0.9857142857142858	test_acc:0.814	test_f1:0.8103365859565523
epoch:20	train_loss:0.13874775171279907	train_acc:0.9928571428571429	test_acc:0.812	test_f1:0.8081321600713355
epoch:21	train_loss:0.12424789369106293	train_acc:0.9928571428571429	test_acc:0.812	test_f1:0.8054331617936178
epoch:22	train_loss:0.11451372504234314	train_acc:0.9928571428571429	test_acc:0.825	test_f1:0.8157463148856186
epoch:23	train_loss:0.10159896314144135	train_acc:1.0	test_acc:0.825	test_f1:0.8165089437568963
epoch:24	train_loss:0.09448502957820892	train_acc:1.0	test_acc:0.825	test_f1:0.8159289291833772
epoch:25	train_loss:0.09100743383169174	train_acc:1.0	test_acc:0.83	test_f1:0.8206966373024465
epoch:26	train_loss:0.08922013640403748	train_acc:0.9976190476190476	test_acc:0.828	test_f1:0.8162234583326928
epoch:27	train_loss:0.08585795015096664	train_acc:1.0	test_acc:0.826	test_f1:0.8166551062964835
epoch:28	train_loss:0.09079771488904953	train_acc:1.0	test_acc:0.816	test_f1:0.8072871891392476
epoch:29	train_loss:0.08352761715650558	train_acc:1.0	test_acc:0.809	test_f1:0.8006226610188589
epoch:30	train_loss:0.09019072353839874	train_acc:1.0	test_acc:0.81	test_f1:0.7991176955639282
epoch:31	train_loss:0.0882338136434555	train_acc:1.0	test_acc:0.803	test_f1:0.7959633294131814
epoch:32	train_loss:0.08892841637134552	train_acc:1.0	test_acc:0.812	test_f1:0.8044903323972435
epoch:33	train_loss:0.09407742321491241	train_acc:1.0	test_acc:0.821	test_f1:0.8078967805492615
epoch:34	train_loss:0.08584631234407425	train_acc:1.0	test_acc:0.816	test_f1:0.8054158473695626
epoch:35	train_loss:0.08122943341732025	train_acc:1.0	test_acc:0.82	test_f1:0.8091319881712236
epoch:36	train_loss:0.08171580731868744	train_acc:1.0	test_acc:0.815	test_f1:0.8040287095594777
epoch:37	train_loss:0.08056642860174179	train_acc:1.0	test_acc:0.808	test_f1:0.7977298680387327
epoch:38	train_loss:0.08384145051240921	train_acc:1.0	test_acc:0.815	test_f1:0.8051208512517631
epoch:39	train_loss:0.07840374857187271	train_acc:1.0	test_acc:0.822	test_f1:0.8123354215937985
epoch:40	train_loss:0.07788845896720886	train_acc:1.0	test_acc:0.815	test_f1:0.801420102008149
epoch:41	train_loss:0.07719747722148895	train_acc:0.9976190476190476	test_acc:0.815	test_f1:0.8048619125992805
epoch:42	train_loss:0.06884538382291794	train_acc:1.0	test_acc:0.826	test_f1:0.8162995451338506
epoch:43	train_loss:0.06970982998609543	train_acc:1.0	test_acc:0.816	test_f1:0.8014042397397283
epoch:44	train_loss:0.0635366141796112	train_acc:1.0	test_acc:0.81	test_f1:0.8012778160154037
epoch:45	train_loss:0.06632118672132492	train_acc:1.0	test_acc:0.814	test_f1:0.8051779535585037
epoch:46	train_loss:0.05944918096065521	train_acc:1.0	test_acc:0.82	test_f1:0.8080928027358877
epoch:47	train_loss:0.06465691328048706	train_acc:1.0	test_acc:0.808	test_f1:0.7981018742888865
epoch:48	train_loss:0.061774998903274536	train_acc:1.0	test_acc:0.815	test_f1:0.8024518104349391
epoch:49	train_loss:0.05578484758734703	train_acc:1.0	test_acc:0.823	test_f1:0.812679652520174
epoch:50	train_loss:0.05933721363544464	train_acc:1.0	test_acc:0.82	test_f1:0.808583450092884
训练并测试结束，共训练50轮，总用时201.61483693122864s
最佳正确率为:0.843,对应的macro_f1为:0.8346630909727792,对应的训练轮次为:17



