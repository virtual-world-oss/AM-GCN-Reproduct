2022-07-01 23:17:00.389122
epoch:1	train_loss:1.9496285915374756	train_acc:0.12857142857142856	test_acc:0.242	test_f1:0.1869052765222798
epoch:2	train_loss:1.9485950469970703	train_acc:0.14285714285714285	test_acc:0.292	test_f1:0.22736447813350982
epoch:3	train_loss:1.9389783143997192	train_acc:0.22857142857142856	test_acc:0.338	test_f1:0.27498933036108175
epoch:4	train_loss:1.937220811843872	train_acc:0.17857142857142858	test_acc:0.389	test_f1:0.3302225115677537
epoch:5	train_loss:1.930843710899353	train_acc:0.2857142857142857	test_acc:0.451	test_f1:0.40411948646508683
epoch:6	train_loss:1.9369049072265625	train_acc:0.2785714285714286	test_acc:0.495	test_f1:0.45814863303069503
epoch:7	train_loss:1.9324098825454712	train_acc:0.3357142857142857	test_acc:0.551	test_f1:0.5211162940983386
epoch:8	train_loss:1.9254169464111328	train_acc:0.37142857142857144	test_acc:0.594	test_f1:0.5645233787126893
epoch:9	train_loss:1.925634503364563	train_acc:0.42142857142857143	test_acc:0.619	test_f1:0.5920668110739555
epoch:10	train_loss:1.9237613677978516	train_acc:0.4928571428571429	test_acc:0.635	test_f1:0.6094248448965012
epoch:11	train_loss:1.919162631034851	train_acc:0.5	test_acc:0.658	test_f1:0.6358895775208584
epoch:12	train_loss:1.9189821481704712	train_acc:0.4785714285714286	test_acc:0.667	test_f1:0.6459475726713687
epoch:13	train_loss:1.9172611236572266	train_acc:0.5357142857142857	test_acc:0.682	test_f1:0.6619147238661208
epoch:14	train_loss:1.913027286529541	train_acc:0.55	test_acc:0.702	test_f1:0.6843297409951836
epoch:15	train_loss:1.9139914512634277	train_acc:0.55	test_acc:0.715	test_f1:0.6973953728591152
epoch:16	train_loss:1.9073007106781006	train_acc:0.5928571428571429	test_acc:0.721	test_f1:0.7022700476875752
epoch:17	train_loss:1.910369634628296	train_acc:0.5928571428571429	test_acc:0.73	test_f1:0.7113903001190346
epoch:18	train_loss:1.9076954126358032	train_acc:0.6642857142857143	test_acc:0.737	test_f1:0.7178662393399043
epoch:19	train_loss:1.8985334634780884	train_acc:0.6857142857142857	test_acc:0.743	test_f1:0.7251045652041094
epoch:20	train_loss:1.9029510021209717	train_acc:0.6928571428571428	test_acc:0.75	test_f1:0.7337208907142612
epoch:21	train_loss:1.8987600803375244	train_acc:0.6928571428571428	test_acc:0.754	test_f1:0.7379229269580351
epoch:22	train_loss:1.8957598209381104	train_acc:0.7285714285714285	test_acc:0.759	test_f1:0.7423922704462029
epoch:23	train_loss:1.8944501876831055	train_acc:0.75	test_acc:0.763	test_f1:0.7461296042313978
epoch:24	train_loss:1.8812131881713867	train_acc:0.7285714285714285	test_acc:0.763	test_f1:0.7458386469132531
epoch:25	train_loss:1.8866455554962158	train_acc:0.7285714285714285	test_acc:0.765	test_f1:0.7474282521115555
epoch:26	train_loss:1.880154013633728	train_acc:0.7785714285714286	test_acc:0.769	test_f1:0.751008090936101
epoch:27	train_loss:1.884161353111267	train_acc:0.75	test_acc:0.769	test_f1:0.7513950558006384
epoch:28	train_loss:1.8827627897262573	train_acc:0.75	test_acc:0.772	test_f1:0.7541295020793708
epoch:29	train_loss:1.8854228258132935	train_acc:0.7142857142857143	test_acc:0.773	test_f1:0.7560569251329297
epoch:30	train_loss:1.8740234375	train_acc:0.7571428571428571	test_acc:0.775	test_f1:0.7588690056370453
epoch:31	train_loss:1.869867205619812	train_acc:0.7714285714285715	test_acc:0.775	test_f1:0.7584672569391385
epoch:32	train_loss:1.8743185997009277	train_acc:0.7642857142857142	test_acc:0.776	test_f1:0.7592056808555642
epoch:33	train_loss:1.8782180547714233	train_acc:0.7428571428571429	test_acc:0.777	test_f1:0.7608351827575568
epoch:34	train_loss:1.8633135557174683	train_acc:0.8142857142857143	test_acc:0.777	test_f1:0.7609304919971615
epoch:35	train_loss:1.8613601922988892	train_acc:0.8142857142857143	test_acc:0.775	test_f1:0.7594960280451859
epoch:36	train_loss:1.854162573814392	train_acc:0.85	test_acc:0.776	test_f1:0.7609929127872158
epoch:37	train_loss:1.8559561967849731	train_acc:0.8428571428571429	test_acc:0.777	test_f1:0.7618768908719427
epoch:38	train_loss:1.8559470176696777	train_acc:0.8214285714285714	test_acc:0.775	test_f1:0.759808853883208
epoch:39	train_loss:1.8428571224212646	train_acc:0.7928571428571428	test_acc:0.777	test_f1:0.7620249955029992
epoch:40	train_loss:1.8608075380325317	train_acc:0.7714285714285715	test_acc:0.779	test_f1:0.764597191283757
epoch:41	train_loss:1.84683358669281	train_acc:0.8214285714285714	test_acc:0.782	test_f1:0.768539016647578
epoch:42	train_loss:1.8417645692825317	train_acc:0.8214285714285714	test_acc:0.784	test_f1:0.7706332140828822
epoch:43	train_loss:1.843725323677063	train_acc:0.8	test_acc:0.782	test_f1:0.768419542656125
epoch:44	train_loss:1.8345733880996704	train_acc:0.8142857142857143	test_acc:0.783	test_f1:0.7691951591096042
epoch:45	train_loss:1.8327484130859375	train_acc:0.8071428571428572	test_acc:0.785	test_f1:0.771134043057628
epoch:46	train_loss:1.8343793153762817	train_acc:0.7928571428571428	test_acc:0.785	test_f1:0.771134043057628
epoch:47	train_loss:1.834286093711853	train_acc:0.8357142857142857	test_acc:0.785	test_f1:0.771134043057628
epoch:48	train_loss:1.8196866512298584	train_acc:0.8642857142857143	test_acc:0.785	test_f1:0.7718604202497552
epoch:49	train_loss:1.832492470741272	train_acc:0.8214285714285714	test_acc:0.785	test_f1:0.7721289037679234
epoch:50	train_loss:1.825359582901001	train_acc:0.8214285714285714	test_acc:0.785	test_f1:0.7720276652658573
训练并测试结束，共训练50轮，总用时174.08429050445557s
最佳正确率为:0.785,对应的macro_f1为:0.7720276652658573,对应的训练轮次为:50



2022-07-01 23:21:46.113369
epoch:1	train_loss:1.9496285915374756	train_acc:0.12857142857142856	test_acc:0.242	test_f1:0.1869052765222798
epoch:2	train_loss:1.9485950469970703	train_acc:0.14285714285714285	test_acc:0.292	test_f1:0.22736447813350982
epoch:3	train_loss:1.9389783143997192	train_acc:0.22857142857142856	test_acc:0.338	test_f1:0.27498933036108175
epoch:4	train_loss:1.937220811843872	train_acc:0.17857142857142858	test_acc:0.389	test_f1:0.3302225115677537
epoch:5	train_loss:1.930843710899353	train_acc:0.2857142857142857	test_acc:0.451	test_f1:0.40411948646508683
epoch:6	train_loss:1.9369049072265625	train_acc:0.2785714285714286	test_acc:0.495	test_f1:0.45814863303069503
epoch:7	train_loss:1.9324098825454712	train_acc:0.3357142857142857	test_acc:0.551	test_f1:0.5211162940983386
epoch:8	train_loss:1.9254169464111328	train_acc:0.37142857142857144	test_acc:0.594	test_f1:0.5645233787126893
epoch:9	train_loss:1.925634503364563	train_acc:0.42142857142857143	test_acc:0.619	test_f1:0.5920668110739555
epoch:10	train_loss:1.9237613677978516	train_acc:0.4928571428571429	test_acc:0.635	test_f1:0.6094248448965012
epoch:11	train_loss:1.919162631034851	train_acc:0.5	test_acc:0.658	test_f1:0.6358895775208584
epoch:12	train_loss:1.9189821481704712	train_acc:0.4785714285714286	test_acc:0.667	test_f1:0.6459475726713687
epoch:13	train_loss:1.9172611236572266	train_acc:0.5357142857142857	test_acc:0.682	test_f1:0.6619147238661208
epoch:14	train_loss:1.913027286529541	train_acc:0.55	test_acc:0.702	test_f1:0.6843297409951836
epoch:15	train_loss:1.9139914512634277	train_acc:0.55	test_acc:0.715	test_f1:0.6973953728591152
epoch:16	train_loss:1.9073007106781006	train_acc:0.5928571428571429	test_acc:0.721	test_f1:0.7022700476875752
epoch:17	train_loss:1.910369634628296	train_acc:0.5928571428571429	test_acc:0.73	test_f1:0.7113903001190346
epoch:18	train_loss:1.9076954126358032	train_acc:0.6642857142857143	test_acc:0.737	test_f1:0.7178662393399043
epoch:19	train_loss:1.8985334634780884	train_acc:0.6857142857142857	test_acc:0.743	test_f1:0.7251045652041094
epoch:20	train_loss:1.9029510021209717	train_acc:0.6928571428571428	test_acc:0.75	test_f1:0.7337208907142612
epoch:21	train_loss:1.8987600803375244	train_acc:0.6928571428571428	test_acc:0.754	test_f1:0.7379229269580351
epoch:22	train_loss:1.8957598209381104	train_acc:0.7285714285714285	test_acc:0.759	test_f1:0.7423922704462029
epoch:23	train_loss:1.8944501876831055	train_acc:0.75	test_acc:0.763	test_f1:0.7461296042313978
epoch:24	train_loss:1.8812131881713867	train_acc:0.7285714285714285	test_acc:0.763	test_f1:0.7458386469132531
epoch:25	train_loss:1.8866455554962158	train_acc:0.7285714285714285	test_acc:0.765	test_f1:0.7474282521115555
epoch:26	train_loss:1.880154013633728	train_acc:0.7785714285714286	test_acc:0.769	test_f1:0.751008090936101
epoch:27	train_loss:1.884161353111267	train_acc:0.75	test_acc:0.769	test_f1:0.7513950558006384
epoch:28	train_loss:1.8827627897262573	train_acc:0.75	test_acc:0.772	test_f1:0.7541295020793708
epoch:29	train_loss:1.8854228258132935	train_acc:0.7142857142857143	test_acc:0.773	test_f1:0.7560569251329297
epoch:30	train_loss:1.8740234375	train_acc:0.7571428571428571	test_acc:0.775	test_f1:0.7588690056370453
epoch:31	train_loss:1.869867205619812	train_acc:0.7714285714285715	test_acc:0.775	test_f1:0.7584672569391385
epoch:32	train_loss:1.8743185997009277	train_acc:0.7642857142857142	test_acc:0.776	test_f1:0.7592056808555642
epoch:33	train_loss:1.8782180547714233	train_acc:0.7428571428571429	test_acc:0.777	test_f1:0.7608351827575568
epoch:34	train_loss:1.8633135557174683	train_acc:0.8142857142857143	test_acc:0.777	test_f1:0.7609304919971615
epoch:35	train_loss:1.8613601922988892	train_acc:0.8142857142857143	test_acc:0.775	test_f1:0.7594960280451859
epoch:36	train_loss:1.854162573814392	train_acc:0.85	test_acc:0.776	test_f1:0.7609929127872158
epoch:37	train_loss:1.8559561967849731	train_acc:0.8428571428571429	test_acc:0.777	test_f1:0.7618768908719427
epoch:38	train_loss:1.8559470176696777	train_acc:0.8214285714285714	test_acc:0.775	test_f1:0.759808853883208
epoch:39	train_loss:1.8428571224212646	train_acc:0.7928571428571428	test_acc:0.777	test_f1:0.7620249955029992
epoch:40	train_loss:1.8608075380325317	train_acc:0.7714285714285715	test_acc:0.779	test_f1:0.764597191283757
epoch:41	train_loss:1.84683358669281	train_acc:0.8214285714285714	test_acc:0.782	test_f1:0.768539016647578
epoch:42	train_loss:1.8417645692825317	train_acc:0.8214285714285714	test_acc:0.784	test_f1:0.7706332140828822
epoch:43	train_loss:1.843725323677063	train_acc:0.8	test_acc:0.782	test_f1:0.768419542656125
epoch:44	train_loss:1.8345733880996704	train_acc:0.8142857142857143	test_acc:0.783	test_f1:0.7691951591096042
epoch:45	train_loss:1.8327484130859375	train_acc:0.8071428571428572	test_acc:0.785	test_f1:0.771134043057628
epoch:46	train_loss:1.8343793153762817	train_acc:0.7928571428571428	test_acc:0.785	test_f1:0.771134043057628
epoch:47	train_loss:1.834286093711853	train_acc:0.8357142857142857	test_acc:0.785	test_f1:0.771134043057628
epoch:48	train_loss:1.8196866512298584	train_acc:0.8642857142857143	test_acc:0.785	test_f1:0.7718604202497552
epoch:49	train_loss:1.832492470741272	train_acc:0.8214285714285714	test_acc:0.785	test_f1:0.7721289037679234
epoch:50	train_loss:1.825359582901001	train_acc:0.8214285714285714	test_acc:0.785	test_f1:0.7720276652658573
训练并测试结束，共训练50轮，总用时277.967493057251s
最佳正确率为:0.785,对应的macro_f1为:0.7720276652658573,对应的训练轮次为:50



2022-07-01 23:27:31.688126
epoch:1	train_loss:1.9492745399475098	train_acc:0.12142857142857143	test_acc:0.137	test_f1:0.11904000342764058
epoch:2	train_loss:1.9472603797912598	train_acc:0.11428571428571428	test_acc:0.17	test_f1:0.1536550828571254
epoch:3	train_loss:1.9418890476226807	train_acc:0.16428571428571428	test_acc:0.213	test_f1:0.19417012282854376
epoch:4	train_loss:1.9394947290420532	train_acc:0.21428571428571427	test_acc:0.268	test_f1:0.24772275942055635
epoch:5	train_loss:1.9347978830337524	train_acc:0.2357142857142857	test_acc:0.312	test_f1:0.29187458268300465
epoch:6	train_loss:1.932470440864563	train_acc:0.2785714285714286	test_acc:0.348	test_f1:0.3284026662306346
epoch:7	train_loss:1.9337308406829834	train_acc:0.24285714285714285	test_acc:0.408	test_f1:0.3903799446456672
epoch:8	train_loss:1.9313188791275024	train_acc:0.2785714285714286	test_acc:0.456	test_f1:0.4389676668138806
epoch:9	train_loss:1.9307976961135864	train_acc:0.3142857142857143	test_acc:0.514	test_f1:0.4983506340117576
epoch:10	train_loss:1.9244805574417114	train_acc:0.37857142857142856	test_acc:0.551	test_f1:0.5362610060589728
epoch:11	train_loss:1.9224921464920044	train_acc:0.44285714285714284	test_acc:0.584	test_f1:0.5674566718499106
epoch:12	train_loss:1.9197893142700195	train_acc:0.4857142857142857	test_acc:0.611	test_f1:0.598576906801949
epoch:13	train_loss:1.9181324243545532	train_acc:0.4928571428571429	test_acc:0.635	test_f1:0.6226858602962967
epoch:14	train_loss:1.9175386428833008	train_acc:0.5142857142857142	test_acc:0.649	test_f1:0.6380607247883301
epoch:15	train_loss:1.9124176502227783	train_acc:0.5785714285714286	test_acc:0.662	test_f1:0.652813563752969
epoch:16	train_loss:1.9150385856628418	train_acc:0.5214285714285715	test_acc:0.672	test_f1:0.6621913594303027
epoch:17	train_loss:1.9061918258666992	train_acc:0.6428571428571429	test_acc:0.682	test_f1:0.6740236884245451
epoch:18	train_loss:1.9089595079421997	train_acc:0.5857142857142857	test_acc:0.694	test_f1:0.6858352954016552
epoch:19	train_loss:1.9045912027359009	train_acc:0.5714285714285714	test_acc:0.701	test_f1:0.6934997378079102
epoch:20	train_loss:1.9026073217391968	train_acc:0.6357142857142857	test_acc:0.71	test_f1:0.7023862348133209
epoch:21	train_loss:1.9012370109558105	train_acc:0.6642857142857143	test_acc:0.716	test_f1:0.7085490972942788
epoch:22	train_loss:1.8985432386398315	train_acc:0.65	test_acc:0.723	test_f1:0.7158619356084254
epoch:23	train_loss:1.8936712741851807	train_acc:0.7	test_acc:0.729	test_f1:0.7226905890760913
epoch:24	train_loss:1.8896260261535645	train_acc:0.7214285714285714	test_acc:0.729	test_f1:0.72276599082176
epoch:25	train_loss:1.8861654996871948	train_acc:0.7642857142857142	test_acc:0.734	test_f1:0.7303429755651446
epoch:26	train_loss:1.8808674812316895	train_acc:0.75	test_acc:0.738	test_f1:0.7350155163375245
epoch:27	train_loss:1.8802965879440308	train_acc:0.7214285714285714	test_acc:0.74	test_f1:0.7362916969096823
epoch:28	train_loss:1.8769742250442505	train_acc:0.7142857142857143	test_acc:0.744	test_f1:0.7411610322671124
epoch:29	train_loss:1.8813321590423584	train_acc:0.7428571428571429	test_acc:0.746	test_f1:0.7425300230701259
epoch:30	train_loss:1.8745051622390747	train_acc:0.7928571428571428	test_acc:0.75	test_f1:0.7461411168917385
epoch:31	train_loss:1.8780741691589355	train_acc:0.75	test_acc:0.754	test_f1:0.7517652401581788
epoch:32	train_loss:1.8799833059310913	train_acc:0.7285714285714285	test_acc:0.758	test_f1:0.7556215127200135
epoch:33	train_loss:1.869576096534729	train_acc:0.7785714285714286	test_acc:0.758	test_f1:0.7561566190938055
epoch:34	train_loss:1.8606035709381104	train_acc:0.8071428571428572	test_acc:0.758	test_f1:0.7577275494214548
epoch:35	train_loss:1.8674808740615845	train_acc:0.7785714285714286	test_acc:0.76	test_f1:0.7589475615730675
epoch:36	train_loss:1.8643007278442383	train_acc:0.7571428571428571	test_acc:0.761	test_f1:0.7599849663550475
epoch:37	train_loss:1.8560696840286255	train_acc:0.75	test_acc:0.764	test_f1:0.7621205126720385
epoch:38	train_loss:1.8518692255020142	train_acc:0.8142857142857143	test_acc:0.765	test_f1:0.7636814510719672
epoch:39	train_loss:1.8502368927001953	train_acc:0.8	test_acc:0.765	test_f1:0.7634443975725862
epoch:40	train_loss:1.848358154296875	train_acc:0.8071428571428572	test_acc:0.764	test_f1:0.761265509504889
epoch:41	train_loss:1.8403754234313965	train_acc:0.85	test_acc:0.764	test_f1:0.7608704269235148
epoch:42	train_loss:1.8439594507217407	train_acc:0.8285714285714286	test_acc:0.763	test_f1:0.7596967382268903
epoch:43	train_loss:1.8352235555648804	train_acc:0.7928571428571428	test_acc:0.764	test_f1:0.7605159481270701
epoch:44	train_loss:1.8447030782699585	train_acc:0.8	test_acc:0.763	test_f1:0.7604576263949939
epoch:45	train_loss:1.836452603340149	train_acc:0.8071428571428572	test_acc:0.765	test_f1:0.7619782198702814
epoch:46	train_loss:1.8442600965499878	train_acc:0.7785714285714286	test_acc:0.766	test_f1:0.7637534440430167
epoch:47	train_loss:1.8353570699691772	train_acc:0.7928571428571428	test_acc:0.767	test_f1:0.764444331482662
epoch:48	train_loss:1.8324848413467407	train_acc:0.8214285714285714	test_acc:0.769	test_f1:0.7665694972877221
epoch:49	train_loss:1.8310478925704956	train_acc:0.8214285714285714	test_acc:0.769	test_f1:0.7665694972877221
epoch:50	train_loss:1.8248450756072998	train_acc:0.8071428571428572	test_acc:0.769	test_f1:0.7674772320096058
训练并测试结束，共训练50轮，总用时265.1135561466217s
最佳正确率为:0.769,对应的macro_f1为:0.7674772320096058,对应的训练轮次为:50



2022-07-01 23:32:52.104237
epoch:1	train_loss:1.9482924938201904	train_acc:0.11428571428571428	test_acc:0.196	test_f1:0.1494775631553038
epoch:2	train_loss:1.9438953399658203	train_acc:0.19642857142857142	test_acc:0.239	test_f1:0.19519508629530646
epoch:3	train_loss:1.9378896951675415	train_acc:0.19285714285714287	test_acc:0.291	test_f1:0.24846693377881604
epoch:4	train_loss:1.9400829076766968	train_acc:0.225	test_acc:0.346	test_f1:0.3049031231691437
epoch:5	train_loss:1.936182975769043	train_acc:0.2714285714285714	test_acc:0.404	test_f1:0.3730611252518704
epoch:6	train_loss:1.9328826665878296	train_acc:0.275	test_acc:0.449	test_f1:0.4247321857149923
epoch:7	train_loss:1.9297500848770142	train_acc:0.35	test_acc:0.499	test_f1:0.4793111044305967
epoch:8	train_loss:1.9295636415481567	train_acc:0.34285714285714286	test_acc:0.551	test_f1:0.5386813128934228
epoch:9	train_loss:1.9253584146499634	train_acc:0.39285714285714285	test_acc:0.586	test_f1:0.5750078500788132
epoch:10	train_loss:1.9236857891082764	train_acc:0.41785714285714287	test_acc:0.613	test_f1:0.6029556157882242
epoch:11	train_loss:1.9189941883087158	train_acc:0.46785714285714286	test_acc:0.641	test_f1:0.6322472771690241
epoch:12	train_loss:1.9184777736663818	train_acc:0.5035714285714286	test_acc:0.653	test_f1:0.644173736567618
epoch:13	train_loss:1.9142438173294067	train_acc:0.48928571428571427	test_acc:0.662	test_f1:0.6499330338665724
epoch:14	train_loss:1.9101817607879639	train_acc:0.5428571428571428	test_acc:0.677	test_f1:0.663492366815966
epoch:15	train_loss:1.9084722995758057	train_acc:0.575	test_acc:0.693	test_f1:0.6816496933776921
epoch:16	train_loss:1.908138394355774	train_acc:0.5928571428571429	test_acc:0.703	test_f1:0.6942905912101605
epoch:17	train_loss:1.9070453643798828	train_acc:0.6	test_acc:0.71	test_f1:0.7011694559897786
epoch:18	train_loss:1.9066194295883179	train_acc:0.5928571428571429	test_acc:0.719	test_f1:0.7114463263127865
epoch:19	train_loss:1.9009615182876587	train_acc:0.6642857142857143	test_acc:0.721	test_f1:0.7147468976297819
epoch:20	train_loss:1.899259328842163	train_acc:0.6642857142857143	test_acc:0.719	test_f1:0.7134964325073959
epoch:21	train_loss:1.8938753604888916	train_acc:0.6928571428571428	test_acc:0.726	test_f1:0.7202938941343796
epoch:22	train_loss:1.8946386575698853	train_acc:0.6428571428571429	test_acc:0.726	test_f1:0.7204848110192338
epoch:23	train_loss:1.8914200067520142	train_acc:0.6857142857142857	test_acc:0.729	test_f1:0.7226084425052954
epoch:24	train_loss:1.8869792222976685	train_acc:0.7	test_acc:0.733	test_f1:0.7266410691084959
epoch:25	train_loss:1.8850018978118896	train_acc:0.6928571428571428	test_acc:0.737	test_f1:0.730452591955414
epoch:26	train_loss:1.8823179006576538	train_acc:0.7464285714285714	test_acc:0.739	test_f1:0.733439368116283
epoch:27	train_loss:1.8790514469146729	train_acc:0.7678571428571429	test_acc:0.743	test_f1:0.7373368687636732
epoch:28	train_loss:1.8814078569412231	train_acc:0.7357142857142858	test_acc:0.745	test_f1:0.7391512556536828
epoch:29	train_loss:1.8792814016342163	train_acc:0.7214285714285714	test_acc:0.748	test_f1:0.74220076906464
epoch:30	train_loss:1.8753496408462524	train_acc:0.725	test_acc:0.747	test_f1:0.7418989001081514
epoch:31	train_loss:1.8695344924926758	train_acc:0.7428571428571429	test_acc:0.748	test_f1:0.743049131895666
epoch:32	train_loss:1.8646589517593384	train_acc:0.7535714285714286	test_acc:0.75	test_f1:0.7449382468397765
epoch:33	train_loss:1.859015941619873	train_acc:0.7714285714285715	test_acc:0.749	test_f1:0.7439674533462414
epoch:34	train_loss:1.8584599494934082	train_acc:0.7535714285714286	test_acc:0.751	test_f1:0.7457925338396524
epoch:35	train_loss:1.8637335300445557	train_acc:0.7571428571428571	test_acc:0.751	test_f1:0.7458802646022662
epoch:36	train_loss:1.850833535194397	train_acc:0.7821428571428571	test_acc:0.751	test_f1:0.7458436805167352
epoch:37	train_loss:1.8552346229553223	train_acc:0.7607142857142857	test_acc:0.754	test_f1:0.7482505405876848
epoch:38	train_loss:1.8542360067367554	train_acc:0.75	test_acc:0.756	test_f1:0.749911513622595
epoch:39	train_loss:1.851198673248291	train_acc:0.7785714285714286	test_acc:0.757	test_f1:0.7506473461547648
epoch:40	train_loss:1.838967204093933	train_acc:0.7821428571428571	test_acc:0.759	test_f1:0.7522978328426264
epoch:41	train_loss:1.8342045545578003	train_acc:0.8285714285714286	test_acc:0.757	test_f1:0.7507398412166838
epoch:42	train_loss:1.8403754234313965	train_acc:0.7607142857142857	test_acc:0.758	test_f1:0.7523394933887969
epoch:43	train_loss:1.8302236795425415	train_acc:0.8035714285714286	test_acc:0.759	test_f1:0.7540140949422364
epoch:44	train_loss:1.8328354358673096	train_acc:0.7642857142857142	test_acc:0.758	test_f1:0.7530758476378985
epoch:45	train_loss:1.837529182434082	train_acc:0.775	test_acc:0.757	test_f1:0.7523735281654863
epoch:46	train_loss:1.8282732963562012	train_acc:0.8107142857142857	test_acc:0.758	test_f1:0.7531469446046168
epoch:47	train_loss:1.8286014795303345	train_acc:0.7892857142857143	test_acc:0.758	test_f1:0.7531469446046168
epoch:48	train_loss:1.8179924488067627	train_acc:0.7892857142857143	test_acc:0.759	test_f1:0.75387910868108
epoch:49	train_loss:1.8142720460891724	train_acc:0.8035714285714286	test_acc:0.758	test_f1:0.7531906546840741
epoch:50	train_loss:1.8185019493103027	train_acc:0.8035714285714286	test_acc:0.759	test_f1:0.7543273975601589
训练并测试结束，共训练50轮，总用时281.5971839427948s
最佳正确率为:0.759,对应的macro_f1为:0.7543273975601589,对应的训练轮次为:50



2022-07-01 23:37:59.647809
epoch:1	train_loss:1.944860577583313	train_acc:0.15714285714285714	test_acc:0.41	test_f1:0.4053726051433187
epoch:2	train_loss:1.9334577322006226	train_acc:0.26071428571428573	test_acc:0.604	test_f1:0.6042995607512139
epoch:3	train_loss:1.9191354513168335	train_acc:0.45714285714285713	test_acc:0.697	test_f1:0.6941437350558053
epoch:4	train_loss:1.9080594778060913	train_acc:0.5964285714285714	test_acc:0.734	test_f1:0.7284215996200657
epoch:5	train_loss:1.896274447441101	train_acc:0.6964285714285714	test_acc:0.755	test_f1:0.7473168654402073
epoch:6	train_loss:1.8860578536987305	train_acc:0.7285714285714285	test_acc:0.765	test_f1:0.758732367354434
epoch:7	train_loss:1.8766008615493774	train_acc:0.7428571428571429	test_acc:0.775	test_f1:0.7663394798718944
epoch:8	train_loss:1.8642009496688843	train_acc:0.7607142857142857	test_acc:0.777	test_f1:0.7670680479613622
epoch:9	train_loss:1.8449678421020508	train_acc:0.7535714285714286	test_acc:0.776	test_f1:0.7665976747248795
epoch:10	train_loss:1.8346476554870605	train_acc:0.825	test_acc:0.775	test_f1:0.7666349975765849
epoch:11	train_loss:1.819327473640442	train_acc:0.775	test_acc:0.774	test_f1:0.7657913471934545
epoch:12	train_loss:1.8094068765640259	train_acc:0.8178571428571428	test_acc:0.773	test_f1:0.7646621226334142
epoch:13	train_loss:1.7995786666870117	train_acc:0.7857142857142857	test_acc:0.772	test_f1:0.7635733952812856
epoch:14	train_loss:1.7871088981628418	train_acc:0.8035714285714286	test_acc:0.771	test_f1:0.7631417634481327
epoch:15	train_loss:1.774492859840393	train_acc:0.8214285714285714	test_acc:0.77	test_f1:0.7626460049105227
epoch:16	train_loss:1.7541313171386719	train_acc:0.8	test_acc:0.775	test_f1:0.7688838198917708
epoch:17	train_loss:1.7466471195220947	train_acc:0.8071428571428572	test_acc:0.779	test_f1:0.7738809602807512
epoch:18	train_loss:1.7276537418365479	train_acc:0.8392857142857143	test_acc:0.779	test_f1:0.7739004427020096
epoch:19	train_loss:1.735571265220642	train_acc:0.8107142857142857	test_acc:0.779	test_f1:0.7739004427020096
epoch:20	train_loss:1.6879328489303589	train_acc:0.8142857142857143	test_acc:0.781	test_f1:0.7767797371211712
epoch:21	train_loss:1.6731884479522705	train_acc:0.8392857142857143	test_acc:0.784	test_f1:0.7803819970865041
epoch:22	train_loss:1.6573681831359863	train_acc:0.85	test_acc:0.784	test_f1:0.7803819970865041
epoch:23	train_loss:1.6628258228302002	train_acc:0.825	test_acc:0.784	test_f1:0.7803819970865041
epoch:24	train_loss:1.6346052885055542	train_acc:0.825	test_acc:0.782	test_f1:0.7779493182503913
epoch:25	train_loss:1.6062853336334229	train_acc:0.8464285714285714	test_acc:0.78	test_f1:0.7762213011101545
epoch:26	train_loss:1.6102617979049683	train_acc:0.8357142857142857	test_acc:0.782	test_f1:0.7779493182503913
epoch:27	train_loss:1.5686041116714478	train_acc:0.8214285714285714	test_acc:0.782	test_f1:0.7779493182503913
epoch:28	train_loss:1.5641523599624634	train_acc:0.8178571428571428	test_acc:0.783	test_f1:0.7786287488859039
epoch:29	train_loss:1.5531470775604248	train_acc:0.8142857142857143	test_acc:0.785	test_f1:0.7801781018842491
epoch:30	train_loss:1.5155696868896484	train_acc:0.8357142857142857	test_acc:0.785	test_f1:0.7801781018842491
epoch:31	train_loss:1.5025607347488403	train_acc:0.8357142857142857	test_acc:0.785	test_f1:0.780251378714113
epoch:32	train_loss:1.4881911277770996	train_acc:0.8571428571428571	test_acc:0.785	test_f1:0.780251378714113
epoch:33	train_loss:1.4696316719055176	train_acc:0.825	test_acc:0.786	test_f1:0.7814502435533921
epoch:34	train_loss:1.5074857473373413	train_acc:0.8178571428571428	test_acc:0.789	test_f1:0.7850091578096174
epoch:35	train_loss:1.4874184131622314	train_acc:0.7714285714285715	test_acc:0.79	test_f1:0.7866292542917355
epoch:36	train_loss:1.435876488685608	train_acc:0.8	test_acc:0.791	test_f1:0.7878744722275349
epoch:37	train_loss:1.3844069242477417	train_acc:0.8571428571428571	test_acc:0.791	test_f1:0.7875963399412392
epoch:38	train_loss:1.3712283372879028	train_acc:0.8642857142857143	test_acc:0.791	test_f1:0.7875963399412392
epoch:39	train_loss:1.3530592918395996	train_acc:0.8214285714285714	test_acc:0.791	test_f1:0.7875877123792804
epoch:40	train_loss:1.3403048515319824	train_acc:0.8071428571428572	test_acc:0.791	test_f1:0.786787954137661
epoch:41	train_loss:1.3342241048812866	train_acc:0.8321428571428572	test_acc:0.792	test_f1:0.7881449609432678
epoch:42	train_loss:1.3058077096939087	train_acc:0.8607142857142858	test_acc:0.791	test_f1:0.7864856592379674
epoch:43	train_loss:1.326324462890625	train_acc:0.8178571428571428	test_acc:0.791	test_f1:0.7864856592379674
epoch:44	train_loss:1.2832255363464355	train_acc:0.8214285714285714	test_acc:0.793	test_f1:0.7886400861628895
epoch:45	train_loss:1.2639433145523071	train_acc:0.8285714285714286	test_acc:0.796	test_f1:0.7912320132383007
epoch:46	train_loss:1.2300794124603271	train_acc:0.8571428571428571	test_acc:0.797	test_f1:0.7920979500314747
epoch:47	train_loss:1.2293407917022705	train_acc:0.8535714285714285	test_acc:0.797	test_f1:0.7921067827883193
epoch:48	train_loss:1.2158442735671997	train_acc:0.8214285714285714	test_acc:0.797	test_f1:0.7921067827883193
epoch:49	train_loss:1.2162820100784302	train_acc:0.7964285714285714	test_acc:0.797	test_f1:0.7916614331063283
epoch:50	train_loss:1.14065420627594	train_acc:0.85	test_acc:0.798	test_f1:0.7927457038860405
训练并测试结束，共训练50轮，总用时181.5292694568634s
最佳正确率为:0.798,对应的macro_f1为:0.7927457038860405,对应的训练轮次为:50



2022-07-01 23:41:30.421006
epoch:1	train_loss:1.9477678537368774	train_acc:0.12857142857142856	test_acc:0.292	test_f1:0.2528378199995356
epoch:2	train_loss:1.9369343519210815	train_acc:0.21428571428571427	test_acc:0.514	test_f1:0.4817450152463403
epoch:3	train_loss:1.927087426185608	train_acc:0.325	test_acc:0.665	test_f1:0.6496111918710901
epoch:4	train_loss:1.9180997610092163	train_acc:0.3678571428571429	test_acc:0.734	test_f1:0.7240734517268701
epoch:5	train_loss:1.907657265663147	train_acc:0.4607142857142857	test_acc:0.758	test_f1:0.7501912434546758
epoch:6	train_loss:1.9011719226837158	train_acc:0.4928571428571429	test_acc:0.771	test_f1:0.7607971143783804
epoch:7	train_loss:1.8894977569580078	train_acc:0.55	test_acc:0.783	test_f1:0.7716652306586838
epoch:8	train_loss:1.880370855331421	train_acc:0.6035714285714285	test_acc:0.78	test_f1:0.7714541705519495
epoch:9	train_loss:1.8768953084945679	train_acc:0.6035714285714285	test_acc:0.785	test_f1:0.7768059803007483
epoch:10	train_loss:1.8669136762619019	train_acc:0.6321428571428571	test_acc:0.784	test_f1:0.7765008084761588
epoch:11	train_loss:1.859857201576233	train_acc:0.6678571428571428	test_acc:0.784	test_f1:0.777838078771767
epoch:12	train_loss:1.8347281217575073	train_acc:0.6821428571428572	test_acc:0.784	test_f1:0.7785117906878601
epoch:13	train_loss:1.828704595565796	train_acc:0.6607142857142857	test_acc:0.786	test_f1:0.7811336358537738
epoch:14	train_loss:1.8245739936828613	train_acc:0.6785714285714286	test_acc:0.784	test_f1:0.7796754460584471
epoch:15	train_loss:1.804965853691101	train_acc:0.7142857142857143	test_acc:0.785	test_f1:0.780549227574911
epoch:16	train_loss:1.8007895946502686	train_acc:0.7178571428571429	test_acc:0.787	test_f1:0.78234933812499
epoch:17	train_loss:1.7771985530853271	train_acc:0.7107142857142857	test_acc:0.788	test_f1:0.7838345638399961
epoch:18	train_loss:1.760170817375183	train_acc:0.7678571428571429	test_acc:0.79	test_f1:0.7857801062896839
epoch:19	train_loss:1.7688484191894531	train_acc:0.7607142857142857	test_acc:0.791	test_f1:0.7869006685176861
epoch:20	train_loss:1.7505918741226196	train_acc:0.7357142857142858	test_acc:0.791	test_f1:0.7867587377816511
epoch:21	train_loss:1.732297658920288	train_acc:0.7107142857142857	test_acc:0.792	test_f1:0.7875331250913425
epoch:22	train_loss:1.7262789011001587	train_acc:0.7535714285714286	test_acc:0.791	test_f1:0.7860413005844048
epoch:23	train_loss:1.728994607925415	train_acc:0.7571428571428571	test_acc:0.792	test_f1:0.7872250336330499
epoch:24	train_loss:1.7077853679656982	train_acc:0.7	test_acc:0.79	test_f1:0.7864419318702468
epoch:25	train_loss:1.6855227947235107	train_acc:0.7357142857142858	test_acc:0.787	test_f1:0.7834447158667056
epoch:26	train_loss:1.6984668970108032	train_acc:0.7392857142857143	test_acc:0.784	test_f1:0.7811471284676618
epoch:27	train_loss:1.6612534523010254	train_acc:0.7142857142857143	test_acc:0.786	test_f1:0.7845613278846828
epoch:28	train_loss:1.6555304527282715	train_acc:0.7392857142857143	test_acc:0.787	test_f1:0.7853187046910478
epoch:29	train_loss:1.6404670476913452	train_acc:0.7678571428571429	test_acc:0.788	test_f1:0.7865945194874381
epoch:30	train_loss:1.6134188175201416	train_acc:0.7892857142857143	test_acc:0.788	test_f1:0.7865139945008447
epoch:31	train_loss:1.6070069074630737	train_acc:0.7357142857142858	test_acc:0.789	test_f1:0.7874683428034385
epoch:32	train_loss:1.5822359323501587	train_acc:0.7428571428571429	test_acc:0.791	test_f1:0.7894987232680583
epoch:33	train_loss:1.58655846118927	train_acc:0.7428571428571429	test_acc:0.791	test_f1:0.7894987232680583
epoch:34	train_loss:1.5593851804733276	train_acc:0.7535714285714286	test_acc:0.794	test_f1:0.7923155457153287
epoch:35	train_loss:1.5538840293884277	train_acc:0.7571428571428571	test_acc:0.797	test_f1:0.7946848323210841
epoch:36	train_loss:1.5369938611984253	train_acc:0.7535714285714286	test_acc:0.799	test_f1:0.7965762814107143
epoch:37	train_loss:1.5021007061004639	train_acc:0.7714285714285715	test_acc:0.8	test_f1:0.7974290530151081
epoch:38	train_loss:1.5059705972671509	train_acc:0.7785714285714286	test_acc:0.801	test_f1:0.7989069673649395
epoch:39	train_loss:1.4794158935546875	train_acc:0.7892857142857143	test_acc:0.8	test_f1:0.798212360628266
epoch:40	train_loss:1.5011099576950073	train_acc:0.7392857142857143	test_acc:0.801	test_f1:0.7987219534873985
epoch:41	train_loss:1.5160880088806152	train_acc:0.725	test_acc:0.802	test_f1:0.8002219209666463
epoch:42	train_loss:1.4186922311782837	train_acc:0.7678571428571429	test_acc:0.802	test_f1:0.8006398028519293
epoch:43	train_loss:1.476341962814331	train_acc:0.7642857142857142	test_acc:0.802	test_f1:0.8001498094445042
epoch:44	train_loss:1.4137704372406006	train_acc:0.7321428571428571	test_acc:0.802	test_f1:0.7992489480656738
epoch:45	train_loss:1.4296997785568237	train_acc:0.7535714285714286	test_acc:0.802	test_f1:0.7990312273924636
epoch:46	train_loss:1.3718187808990479	train_acc:0.7321428571428571	test_acc:0.802	test_f1:0.7990312273924636
epoch:47	train_loss:1.3694814443588257	train_acc:0.7964285714285714	test_acc:0.802	test_f1:0.799302470894321
epoch:48	train_loss:1.4157254695892334	train_acc:0.7357142857142858	test_acc:0.802	test_f1:0.799302470894321
epoch:49	train_loss:1.425527572631836	train_acc:0.7178571428571429	test_acc:0.804	test_f1:0.8005002989963016
epoch:50	train_loss:1.3392950296401978	train_acc:0.7357142857142858	test_acc:0.804	test_f1:0.800759625201917
训练并测试结束，共训练50轮，总用时172.9043140411377s
最佳正确率为:0.804,对应的macro_f1为:0.800759625201917,对应的训练轮次为:50



2022-07-01 23:44:47.448327
epoch:1	train_loss:1.9495538473129272	train_acc:0.1380952380952381	test_acc:0.314	test_f1:0.292694830894811
epoch:2	train_loss:1.9365185499191284	train_acc:0.1976190476190476	test_acc:0.533	test_f1:0.5514352693844831
epoch:3	train_loss:1.9228026866912842	train_acc:0.34523809523809523	test_acc:0.618	test_f1:0.645881697428068
epoch:4	train_loss:1.9112292528152466	train_acc:0.38571428571428573	test_acc:0.657	test_f1:0.6875442008270808
epoch:5	train_loss:1.9032130241394043	train_acc:0.44285714285714284	test_acc:0.688	test_f1:0.7105843342955699
epoch:6	train_loss:1.8988324403762817	train_acc:0.5238095238095238	test_acc:0.706	test_f1:0.7243040331767512
epoch:7	train_loss:1.880515456199646	train_acc:0.6	test_acc:0.72	test_f1:0.7355081544326246
epoch:8	train_loss:1.872610330581665	train_acc:0.6071428571428571	test_acc:0.731	test_f1:0.7429530187706973
epoch:9	train_loss:1.8566926717758179	train_acc:0.638095238095238	test_acc:0.741	test_f1:0.751698679566563
epoch:10	train_loss:1.8508059978485107	train_acc:0.638095238095238	test_acc:0.751	test_f1:0.7605494426178623
epoch:11	train_loss:1.8327393531799316	train_acc:0.669047619047619	test_acc:0.757	test_f1:0.765644321250754
epoch:12	train_loss:1.829825520515442	train_acc:0.6952380952380952	test_acc:0.767	test_f1:0.773532576747497
epoch:13	train_loss:1.8279751539230347	train_acc:0.6642857142857143	test_acc:0.771	test_f1:0.7767784208512778
epoch:14	train_loss:1.7966102361679077	train_acc:0.6666666666666666	test_acc:0.772	test_f1:0.7774655279518735
epoch:15	train_loss:1.8021119832992554	train_acc:0.6452380952380953	test_acc:0.776	test_f1:0.7803155952380971
epoch:16	train_loss:1.794883131980896	train_acc:0.6928571428571428	test_acc:0.775	test_f1:0.7796275285598971
epoch:17	train_loss:1.7608305215835571	train_acc:0.7238095238095238	test_acc:0.779	test_f1:0.7816543311528404
epoch:18	train_loss:1.7482666969299316	train_acc:0.7047619047619048	test_acc:0.781	test_f1:0.7831560708536525
epoch:19	train_loss:1.7431672811508179	train_acc:0.7047619047619048	test_acc:0.776	test_f1:0.7772925059744632
epoch:20	train_loss:1.7231160402297974	train_acc:0.7166666666666667	test_acc:0.775	test_f1:0.7770176859397886
epoch:21	train_loss:1.691988468170166	train_acc:0.7357142857142858	test_acc:0.772	test_f1:0.7735551535207357
epoch:22	train_loss:1.7019615173339844	train_acc:0.7071428571428572	test_acc:0.777	test_f1:0.7787915996615825
epoch:23	train_loss:1.6855875253677368	train_acc:0.7	test_acc:0.776	test_f1:0.7778205048893011
epoch:24	train_loss:1.682381272315979	train_acc:0.7404761904761905	test_acc:0.775	test_f1:0.7769803732073756
epoch:25	train_loss:1.6534578800201416	train_acc:0.7119047619047619	test_acc:0.777	test_f1:0.7797117667731432
epoch:26	train_loss:1.6525483131408691	train_acc:0.6619047619047619	test_acc:0.778	test_f1:0.7806981006384693
epoch:27	train_loss:1.633711338043213	train_acc:0.7285714285714285	test_acc:0.776	test_f1:0.7778386923112299
epoch:28	train_loss:1.6317065954208374	train_acc:0.7071428571428572	test_acc:0.778	test_f1:0.7794018811529483
epoch:29	train_loss:1.6113369464874268	train_acc:0.7619047619047619	test_acc:0.78	test_f1:0.7812011436022216
epoch:30	train_loss:1.5958505868911743	train_acc:0.7309523809523809	test_acc:0.779	test_f1:0.7795255600353687
epoch:31	train_loss:1.5465047359466553	train_acc:0.7404761904761905	test_acc:0.78	test_f1:0.7806392313171129
epoch:32	train_loss:1.5883837938308716	train_acc:0.7285714285714285	test_acc:0.783	test_f1:0.7843744090519241
epoch:33	train_loss:1.557822823524475	train_acc:0.6833333333333333	test_acc:0.783	test_f1:0.783838855025161
epoch:34	train_loss:1.5281862020492554	train_acc:0.7642857142857142	test_acc:0.783	test_f1:0.7835999902705977
epoch:35	train_loss:1.5100148916244507	train_acc:0.7309523809523809	test_acc:0.784	test_f1:0.7836182847774913
epoch:36	train_loss:1.520526647567749	train_acc:0.6904761904761905	test_acc:0.786	test_f1:0.7857146005746928
epoch:37	train_loss:1.5151653289794922	train_acc:0.7547619047619047	test_acc:0.787	test_f1:0.7869574736276478
epoch:38	train_loss:1.4836894273757935	train_acc:0.7547619047619047	test_acc:0.788	test_f1:0.7877788242069393
epoch:39	train_loss:1.4623464345932007	train_acc:0.7452380952380953	test_acc:0.788	test_f1:0.7877788242069393
epoch:40	train_loss:1.4683985710144043	train_acc:0.7476190476190476	test_acc:0.788	test_f1:0.7877788242069393
epoch:41	train_loss:1.4174785614013672	train_acc:0.7380952380952381	test_acc:0.788	test_f1:0.7881888854031607
epoch:42	train_loss:1.46055006980896	train_acc:0.7357142857142858	test_acc:0.789	test_f1:0.7899970768578762
epoch:43	train_loss:1.4261748790740967	train_acc:0.7261904761904762	test_acc:0.793	test_f1:0.7937154994177351
epoch:44	train_loss:1.4751819372177124	train_acc:0.7214285714285714	test_acc:0.793	test_f1:0.7935372071265839
epoch:45	train_loss:1.3742047548294067	train_acc:0.7357142857142858	test_acc:0.794	test_f1:0.7952362481540839
epoch:46	train_loss:1.359703540802002	train_acc:0.7285714285714285	test_acc:0.795	test_f1:0.795922824742679
epoch:47	train_loss:1.3620471954345703	train_acc:0.7285714285714285	test_acc:0.796	test_f1:0.7967903882400644
epoch:48	train_loss:1.3575003147125244	train_acc:0.7428571428571429	test_acc:0.797	test_f1:0.7982059527127953
epoch:49	train_loss:1.3797861337661743	train_acc:0.7309523809523809	test_acc:0.796	test_f1:0.7975476429678109
epoch:50	train_loss:1.32527494430542	train_acc:0.7428571428571429	test_acc:0.797	test_f1:0.7987103303614816
训练并测试结束，共训练50轮，总用时172.02765130996704s
最佳正确率为:0.797,对应的macro_f1为:0.7987103303614816,对应的训练轮次为:50



2022-07-01 23:48:01.213475
epoch:1	train_loss:1.947464108467102	train_acc:0.12857142857142856	test_acc:0.381	test_f1:0.3681416611761737
epoch:2	train_loss:1.9386383295059204	train_acc:0.20714285714285716	test_acc:0.584	test_f1:0.5846274488056373
epoch:3	train_loss:1.9305660724639893	train_acc:0.3261904761904762	test_acc:0.669	test_f1:0.6758664710139684
epoch:4	train_loss:1.9218724966049194	train_acc:0.39285714285714285	test_acc:0.718	test_f1:0.7202140171273658
epoch:5	train_loss:1.9062235355377197	train_acc:0.46904761904761905	test_acc:0.749	test_f1:0.7444613489132461
epoch:6	train_loss:1.8985358476638794	train_acc:0.5023809523809524	test_acc:0.757	test_f1:0.7528956720264228
epoch:7	train_loss:1.8913726806640625	train_acc:0.5523809523809524	test_acc:0.76	test_f1:0.7547284309262722
epoch:8	train_loss:1.8846567869186401	train_acc:0.5880952380952381	test_acc:0.762	test_f1:0.7554614580670044
epoch:9	train_loss:1.8742027282714844	train_acc:0.5976190476190476	test_acc:0.766	test_f1:0.7593366839294509
epoch:10	train_loss:1.8651695251464844	train_acc:0.6476190476190476	test_acc:0.774	test_f1:0.767276585168689
epoch:11	train_loss:1.8559422492980957	train_acc:0.6357142857142857	test_acc:0.776	test_f1:0.7694606162802636
epoch:12	train_loss:1.8434613943099976	train_acc:0.680952380952381	test_acc:0.783	test_f1:0.7757748524398062
epoch:13	train_loss:1.8387372493743896	train_acc:0.6523809523809524	test_acc:0.784	test_f1:0.7758522212809121
epoch:14	train_loss:1.8254574537277222	train_acc:0.669047619047619	test_acc:0.79	test_f1:0.7824968448154508
epoch:15	train_loss:1.7927172183990479	train_acc:0.7	test_acc:0.79	test_f1:0.7820275271783802
epoch:16	train_loss:1.8129065036773682	train_acc:0.6880952380952381	test_acc:0.791	test_f1:0.7827200107422252
epoch:17	train_loss:1.785576343536377	train_acc:0.6833333333333333	test_acc:0.793	test_f1:0.7850391642487081
epoch:18	train_loss:1.7855643033981323	train_acc:0.6880952380952381	test_acc:0.793	test_f1:0.7850264490056776
epoch:19	train_loss:1.756008505821228	train_acc:0.7071428571428572	test_acc:0.795	test_f1:0.7881124690572926
epoch:20	train_loss:1.7714046239852905	train_acc:0.6714285714285714	test_acc:0.793	test_f1:0.7860921694218516
epoch:21	train_loss:1.7584279775619507	train_acc:0.7	test_acc:0.795	test_f1:0.7882286650623721
epoch:22	train_loss:1.7389572858810425	train_acc:0.7357142857142858	test_acc:0.796	test_f1:0.789720317748593
epoch:23	train_loss:1.722806453704834	train_acc:0.6904761904761905	test_acc:0.796	test_f1:0.7890534637864788
epoch:24	train_loss:1.7002133131027222	train_acc:0.7357142857142858	test_acc:0.798	test_f1:0.7918530564220073
epoch:25	train_loss:1.7010807991027832	train_acc:0.7452380952380953	test_acc:0.798	test_f1:0.7910155403349315
epoch:26	train_loss:1.6681725978851318	train_acc:0.7309523809523809	test_acc:0.8	test_f1:0.7932912711879118
epoch:27	train_loss:1.661525011062622	train_acc:0.7285714285714285	test_acc:0.804	test_f1:0.7979463079357672
epoch:28	train_loss:1.6726830005645752	train_acc:0.7285714285714285	test_acc:0.807	test_f1:0.8013451089566731
epoch:29	train_loss:1.6329854726791382	train_acc:0.7261904761904762	test_acc:0.812	test_f1:0.8063578230797638
epoch:30	train_loss:1.637647032737732	train_acc:0.7047619047619048	test_acc:0.811	test_f1:0.8056381678153127
epoch:31	train_loss:1.6027209758758545	train_acc:0.7071428571428572	test_acc:0.809	test_f1:0.803010628405825
epoch:32	train_loss:1.6276174783706665	train_acc:0.7214285714285714	test_acc:0.811	test_f1:0.8049521933915782
epoch:33	train_loss:1.6096515655517578	train_acc:0.7333333333333333	test_acc:0.812	test_f1:0.8062372607381139
epoch:34	train_loss:1.5577908754348755	train_acc:0.7309523809523809	test_acc:0.812	test_f1:0.8064156933772698
epoch:35	train_loss:1.562880277633667	train_acc:0.7333333333333333	test_acc:0.815	test_f1:0.809972990086565
epoch:36	train_loss:1.5581954717636108	train_acc:0.7285714285714285	test_acc:0.816	test_f1:0.8107516416938971
epoch:37	train_loss:1.5275133848190308	train_acc:0.7452380952380953	test_acc:0.815	test_f1:0.8092357032448995
epoch:38	train_loss:1.539634346961975	train_acc:0.6880952380952381	test_acc:0.817	test_f1:0.8112297016829795
epoch:39	train_loss:1.4897652864456177	train_acc:0.7595238095238095	test_acc:0.814	test_f1:0.8079288627619544
epoch:40	train_loss:1.4781701564788818	train_acc:0.7238095238095238	test_acc:0.816	test_f1:0.8098246599315828
epoch:41	train_loss:1.4633303880691528	train_acc:0.7738095238095238	test_acc:0.816	test_f1:0.8097431556320294
epoch:42	train_loss:1.4438363313674927	train_acc:0.7404761904761905	test_acc:0.818	test_f1:0.8115288353983365
epoch:43	train_loss:1.4483107328414917	train_acc:0.7261904761904762	test_acc:0.818	test_f1:0.8115341960745406
epoch:44	train_loss:1.4471852779388428	train_acc:0.7309523809523809	test_acc:0.818	test_f1:0.8119260029254983
epoch:45	train_loss:1.428903579711914	train_acc:0.7380952380952381	test_acc:0.819	test_f1:0.8133115999541758
epoch:46	train_loss:1.3674005270004272	train_acc:0.7880952380952381	test_acc:0.816	test_f1:0.8108515129411612
epoch:47	train_loss:1.3624945878982544	train_acc:0.7595238095238095	test_acc:0.815	test_f1:0.8100858553353267
epoch:48	train_loss:1.358210563659668	train_acc:0.7571428571428571	test_acc:0.814	test_f1:0.809192671470817
epoch:49	train_loss:1.4290030002593994	train_acc:0.7238095238095238	test_acc:0.815	test_f1:0.8100589744914386
epoch:50	train_loss:1.3492605686187744	train_acc:0.7523809523809524	test_acc:0.815	test_f1:0.8105230093241592
训练并测试结束，共训练50轮，总用时172.50472569465637s
最佳正确率为:0.819,对应的macro_f1为:0.8133115999541758,对应的训练轮次为:45



2022-07-01 23:51:04.586363
epoch:1	train_loss:1.9478766918182373	train_acc:0.14523809523809525	test_acc:0.287	test_f1:0.28537254418090213
epoch:2	train_loss:1.9318398237228394	train_acc:0.2714285714285714	test_acc:0.478	test_f1:0.4730466101935097
epoch:3	train_loss:1.9275455474853516	train_acc:0.29523809523809524	test_acc:0.593	test_f1:0.5852720524818303
epoch:4	train_loss:1.91585111618042	train_acc:0.3523809523809524	test_acc:0.652	test_f1:0.6442650790718304
epoch:5	train_loss:1.9086562395095825	train_acc:0.45	test_acc:0.699	test_f1:0.6887522367779646
epoch:6	train_loss:1.8958468437194824	train_acc:0.5047619047619047	test_acc:0.723	test_f1:0.7144525476374167
epoch:7	train_loss:1.8912811279296875	train_acc:0.5380952380952381	test_acc:0.745	test_f1:0.7369212712279124
epoch:8	train_loss:1.875427007675171	train_acc:0.6047619047619047	test_acc:0.749	test_f1:0.740308645872071
epoch:9	train_loss:1.860101580619812	train_acc:0.6285714285714286	test_acc:0.765	test_f1:0.7571183145622532
epoch:10	train_loss:1.8495080471038818	train_acc:0.638095238095238	test_acc:0.768	test_f1:0.7615390236225164
epoch:11	train_loss:1.8491090536117554	train_acc:0.6285714285714286	test_acc:0.772	test_f1:0.7659314451505512
epoch:12	train_loss:1.8348805904388428	train_acc:0.6428571428571429	test_acc:0.777	test_f1:0.7706650541327583
epoch:13	train_loss:1.8233922719955444	train_acc:0.6738095238095239	test_acc:0.779	test_f1:0.7728842510635839
epoch:14	train_loss:1.8164314031600952	train_acc:0.65	test_acc:0.786	test_f1:0.780537505732862
epoch:15	train_loss:1.7894378900527954	train_acc:0.7	test_acc:0.789	test_f1:0.7835406975979222
epoch:16	train_loss:1.7854254245758057	train_acc:0.6928571428571428	test_acc:0.79	test_f1:0.7834427209106443
epoch:17	train_loss:1.7752100229263306	train_acc:0.6904761904761905	test_acc:0.79	test_f1:0.7842006400817685
epoch:18	train_loss:1.7691125869750977	train_acc:0.7023809523809523	test_acc:0.793	test_f1:0.7874239397939193
epoch:19	train_loss:1.7487621307373047	train_acc:0.7	test_acc:0.792	test_f1:0.7858539176909897
epoch:20	train_loss:1.743154525756836	train_acc:0.7380952380952381	test_acc:0.792	test_f1:0.7868411267725165
epoch:21	train_loss:1.722123622894287	train_acc:0.7380952380952381	test_acc:0.794	test_f1:0.7890716759747335
epoch:22	train_loss:1.712424397468567	train_acc:0.7047619047619048	test_acc:0.793	test_f1:0.7880455773819774
epoch:23	train_loss:1.7075591087341309	train_acc:0.719047619047619	test_acc:0.792	test_f1:0.788224029632035
epoch:24	train_loss:1.6936843395233154	train_acc:0.7	test_acc:0.792	test_f1:0.7881295581750398
epoch:25	train_loss:1.6847052574157715	train_acc:0.6904761904761905	test_acc:0.792	test_f1:0.7881295581750398
epoch:26	train_loss:1.663385272026062	train_acc:0.7523809523809524	test_acc:0.788	test_f1:0.7852806123471966
epoch:27	train_loss:1.6694083213806152	train_acc:0.6952380952380952	test_acc:0.787	test_f1:0.7846091109916353
epoch:28	train_loss:1.620416283607483	train_acc:0.7119047619047619	test_acc:0.787	test_f1:0.7843930688363981
epoch:29	train_loss:1.6129093170166016	train_acc:0.7261904761904762	test_acc:0.787	test_f1:0.7852425584824314
epoch:30	train_loss:1.5862693786621094	train_acc:0.7285714285714285	test_acc:0.787	test_f1:0.7853756737548051
epoch:31	train_loss:1.5914567708969116	train_acc:0.7357142857142858	test_acc:0.787	test_f1:0.7854782913482516
epoch:32	train_loss:1.558169960975647	train_acc:0.7428571428571429	test_acc:0.787	test_f1:0.7854782913482516
epoch:33	train_loss:1.548850655555725	train_acc:0.7142857142857143	test_acc:0.786	test_f1:0.7847621818976532
epoch:34	train_loss:1.5461524724960327	train_acc:0.7142857142857143	test_acc:0.787	test_f1:0.7856073987397031
epoch:35	train_loss:1.5258768796920776	train_acc:0.7452380952380953	test_acc:0.789	test_f1:0.786970253414691
epoch:36	train_loss:1.4896423816680908	train_acc:0.7142857142857143	test_acc:0.789	test_f1:0.786970253414691
epoch:37	train_loss:1.4957870244979858	train_acc:0.7428571428571429	test_acc:0.789	test_f1:0.7872923401525158
epoch:38	train_loss:1.4630790948867798	train_acc:0.7214285714285714	test_acc:0.789	test_f1:0.7870223452467594
epoch:39	train_loss:1.4874862432479858	train_acc:0.7642857142857142	test_acc:0.789	test_f1:0.7870223452467594
epoch:40	train_loss:1.5035935640335083	train_acc:0.7261904761904762	test_acc:0.789	test_f1:0.7870223452467594
epoch:41	train_loss:1.4564927816390991	train_acc:0.7523809523809524	test_acc:0.789	test_f1:0.7872130643039069
epoch:42	train_loss:1.4150842428207397	train_acc:0.7261904761904762	test_acc:0.789	test_f1:0.7872130643039069
epoch:43	train_loss:1.483811855316162	train_acc:0.7023809523809523	test_acc:0.789	test_f1:0.7872096906595107
epoch:44	train_loss:1.4124565124511719	train_acc:0.7404761904761905	test_acc:0.79	test_f1:0.787177442366234
epoch:45	train_loss:1.3527040481567383	train_acc:0.7690476190476191	test_acc:0.791	test_f1:0.7875754330322484
epoch:46	train_loss:1.4182440042495728	train_acc:0.7142857142857143	test_acc:0.79	test_f1:0.7865030320564176
epoch:47	train_loss:1.4076135158538818	train_acc:0.7071428571428572	test_acc:0.79	test_f1:0.7865030320564176
epoch:48	train_loss:1.3032894134521484	train_acc:0.7595238095238095	test_acc:0.791	test_f1:0.787270620378348
epoch:49	train_loss:1.3623363971710205	train_acc:0.7023809523809523	test_acc:0.791	test_f1:0.7872322561499836
epoch:50	train_loss:1.3166967630386353	train_acc:0.7333333333333333	test_acc:0.791	test_f1:0.7875397843030768
训练并测试结束，共训练50轮，总用时172.49062657356262s
最佳正确率为:0.794,对应的macro_f1为:0.7890716759747335,对应的训练轮次为:21



2022-07-01 23:54:22.564378
epoch:1	train_loss:1.795597791671753	train_acc:0.125	test_acc:0.28	test_f1:0.2491689151709092
epoch:2	train_loss:1.7851072549819946	train_acc:0.2833333333333333	test_acc:0.405	test_f1:0.3593427790276687
epoch:3	train_loss:1.7824989557266235	train_acc:0.275	test_acc:0.478	test_f1:0.4394189484358038
epoch:4	train_loss:1.769458293914795	train_acc:0.48333333333333334	test_acc:0.525	test_f1:0.4845059379864669
epoch:5	train_loss:1.7669568061828613	train_acc:0.5166666666666667	test_acc:0.561	test_f1:0.5198092888785296
epoch:6	train_loss:1.7632185220718384	train_acc:0.5166666666666667	test_acc:0.6	test_f1:0.5588272299875954
epoch:7	train_loss:1.7578351497650146	train_acc:0.48333333333333334	test_acc:0.619	test_f1:0.5784443611102734
epoch:8	train_loss:1.7462632656097412	train_acc:0.6333333333333333	test_acc:0.629	test_f1:0.5870687647317375
epoch:9	train_loss:1.739453673362732	train_acc:0.6333333333333333	test_acc:0.639	test_f1:0.598245964087887
epoch:10	train_loss:1.732543706893921	train_acc:0.6333333333333333	test_acc:0.65	test_f1:0.609173615190494
epoch:11	train_loss:1.7322489023208618	train_acc:0.625	test_acc:0.655	test_f1:0.6138970836576166
epoch:12	train_loss:1.7214524745941162	train_acc:0.7166666666666667	test_acc:0.659	test_f1:0.6171811157976004
epoch:13	train_loss:1.7073768377304077	train_acc:0.6833333333333333	test_acc:0.661	test_f1:0.619184894412296
epoch:14	train_loss:1.7030856609344482	train_acc:0.7166666666666667	test_acc:0.664	test_f1:0.6236478262475377
epoch:15	train_loss:1.695523977279663	train_acc:0.6833333333333333	test_acc:0.671	test_f1:0.6289459593623767
epoch:16	train_loss:1.6887038946151733	train_acc:0.65	test_acc:0.681	test_f1:0.638318264289146
epoch:17	train_loss:1.6839593648910522	train_acc:0.6833333333333333	test_acc:0.683	test_f1:0.6396411466498405
epoch:18	train_loss:1.6851105690002441	train_acc:0.6583333333333333	test_acc:0.69	test_f1:0.6460974224689982
epoch:19	train_loss:1.6677699089050293	train_acc:0.7333333333333333	test_acc:0.695	test_f1:0.6503229440154511
epoch:20	train_loss:1.6364213228225708	train_acc:0.7	test_acc:0.703	test_f1:0.6590164986316468
epoch:21	train_loss:1.6358526945114136	train_acc:0.7583333333333333	test_acc:0.703	test_f1:0.6588254245440425
epoch:22	train_loss:1.64896821975708	train_acc:0.6833333333333333	test_acc:0.701	test_f1:0.6569745781807202
epoch:23	train_loss:1.6275694370269775	train_acc:0.7166666666666667	test_acc:0.706	test_f1:0.6632106128928205
epoch:24	train_loss:1.6110095977783203	train_acc:0.75	test_acc:0.708	test_f1:0.6649880522097775
epoch:25	train_loss:1.6126664876937866	train_acc:0.7	test_acc:0.71	test_f1:0.6679324506286868
epoch:26	train_loss:1.5697382688522339	train_acc:0.7416666666666667	test_acc:0.71	test_f1:0.6678878377005336
epoch:27	train_loss:1.5827287435531616	train_acc:0.6583333333333333	test_acc:0.712	test_f1:0.6697483439881647
epoch:28	train_loss:1.5601885318756104	train_acc:0.7333333333333333	test_acc:0.711	test_f1:0.6688576016074629
epoch:29	train_loss:1.5756486654281616	train_acc:0.6833333333333333	test_acc:0.708	test_f1:0.665856764476814
epoch:30	train_loss:1.559163212776184	train_acc:0.7083333333333334	test_acc:0.711	test_f1:0.6686414296574504
epoch:31	train_loss:1.5475120544433594	train_acc:0.725	test_acc:0.707	test_f1:0.6646481593833201
epoch:32	train_loss:1.53132164478302	train_acc:0.725	test_acc:0.706	test_f1:0.6634121092148811
epoch:33	train_loss:1.52829909324646	train_acc:0.7666666666666667	test_acc:0.709	test_f1:0.6676780052034097
epoch:34	train_loss:1.5131136178970337	train_acc:0.7333333333333333	test_acc:0.71	test_f1:0.66868997884279
epoch:35	train_loss:1.5265557765960693	train_acc:0.7	test_acc:0.711	test_f1:0.6697298063664031
epoch:36	train_loss:1.4822732210159302	train_acc:0.7666666666666667	test_acc:0.711	test_f1:0.6694887539538952
epoch:37	train_loss:1.5118666887283325	train_acc:0.65	test_acc:0.712	test_f1:0.6701973511262613
epoch:38	train_loss:1.4721503257751465	train_acc:0.725	test_acc:0.713	test_f1:0.6710848810166202
epoch:39	train_loss:1.4694377183914185	train_acc:0.7083333333333334	test_acc:0.713	test_f1:0.6711040000825382
epoch:40	train_loss:1.4528250694274902	train_acc:0.7666666666666667	test_acc:0.712	test_f1:0.6715563456610422
epoch:41	train_loss:1.4097437858581543	train_acc:0.75	test_acc:0.713	test_f1:0.6726827279956059
epoch:42	train_loss:1.3907569646835327	train_acc:0.7833333333333333	test_acc:0.712	test_f1:0.671850482235088
epoch:43	train_loss:1.4094219207763672	train_acc:0.7333333333333333	test_acc:0.709	test_f1:0.6689511584670041
epoch:44	train_loss:1.383658766746521	train_acc:0.725	test_acc:0.707	test_f1:0.6670686118545537
epoch:45	train_loss:1.350229263305664	train_acc:0.6916666666666667	test_acc:0.708	test_f1:0.6681022894379413
epoch:46	train_loss:1.4341329336166382	train_acc:0.7	test_acc:0.709	test_f1:0.6688845893385967
epoch:47	train_loss:1.336356520652771	train_acc:0.725	test_acc:0.709	test_f1:0.6689576712151477
epoch:48	train_loss:1.3718277215957642	train_acc:0.7083333333333334	test_acc:0.712	test_f1:0.671594868925777
epoch:49	train_loss:1.3367741107940674	train_acc:0.775	test_acc:0.712	test_f1:0.6715552650321813
epoch:50	train_loss:1.3810254335403442	train_acc:0.725	test_acc:0.712	test_f1:0.6727222000096842
训练并测试结束，共训练50轮，总用时259.25297832489014s
最佳正确率为:0.713,对应的macro_f1为:0.6726827279956059,对应的训练轮次为:41



2022-07-01 23:58:50.941694
epoch:1	train_loss:1.7888085842132568	train_acc:0.225	test_acc:0.437	test_f1:0.40554654638886306
epoch:2	train_loss:1.7844361066818237	train_acc:0.2833333333333333	test_acc:0.509	test_f1:0.48698613772856475
epoch:3	train_loss:1.7799025774002075	train_acc:0.325	test_acc:0.559	test_f1:0.5330336532551094
epoch:4	train_loss:1.7687894105911255	train_acc:0.4583333333333333	test_acc:0.598	test_f1:0.5747120572145955
epoch:5	train_loss:1.7668837308883667	train_acc:0.5166666666666667	test_acc:0.618	test_f1:0.5966145791551097
epoch:6	train_loss:1.7590692043304443	train_acc:0.5083333333333333	test_acc:0.63	test_f1:0.6072055171275614
epoch:7	train_loss:1.7509180307388306	train_acc:0.6083333333333333	test_acc:0.636	test_f1:0.6121314474501311
epoch:8	train_loss:1.7484385967254639	train_acc:0.5916666666666667	test_acc:0.639	test_f1:0.6154554484396357
epoch:9	train_loss:1.7389683723449707	train_acc:0.5916666666666667	test_acc:0.652	test_f1:0.6290389753618171
epoch:10	train_loss:1.7133170366287231	train_acc:0.75	test_acc:0.658	test_f1:0.6318667134495916
epoch:11	train_loss:1.7211298942565918	train_acc:0.7083333333333334	test_acc:0.658	test_f1:0.6315583626990903
epoch:12	train_loss:1.7047232389450073	train_acc:0.7166666666666667	test_acc:0.661	test_f1:0.6343650353590954
epoch:13	train_loss:1.7070716619491577	train_acc:0.65	test_acc:0.672	test_f1:0.6437902849107303
epoch:14	train_loss:1.6887154579162598	train_acc:0.65	test_acc:0.675	test_f1:0.645996822026652
epoch:15	train_loss:1.6711472272872925	train_acc:0.725	test_acc:0.68	test_f1:0.6507125505355196
epoch:16	train_loss:1.6892346143722534	train_acc:0.6416666666666667	test_acc:0.685	test_f1:0.6556828109447989
epoch:17	train_loss:1.6543887853622437	train_acc:0.7583333333333333	test_acc:0.686	test_f1:0.6556859967152638
epoch:18	train_loss:1.6619771718978882	train_acc:0.7166666666666667	test_acc:0.689	test_f1:0.6591157349941726
epoch:19	train_loss:1.652302861213684	train_acc:0.725	test_acc:0.693	test_f1:0.6623988986858205
epoch:20	train_loss:1.6183834075927734	train_acc:0.725	test_acc:0.689	test_f1:0.6584581105169341
epoch:21	train_loss:1.6417160034179688	train_acc:0.6916666666666667	test_acc:0.693	test_f1:0.660757755133864
epoch:22	train_loss:1.6016900539398193	train_acc:0.7166666666666667	test_acc:0.692	test_f1:0.658859561564538
epoch:23	train_loss:1.5947297811508179	train_acc:0.6916666666666667	test_acc:0.691	test_f1:0.6578852999581346
epoch:24	train_loss:1.5937755107879639	train_acc:0.7416666666666667	test_acc:0.691	test_f1:0.6569764326022972
epoch:25	train_loss:1.5878716707229614	train_acc:0.775	test_acc:0.691	test_f1:0.6569854305818275
epoch:26	train_loss:1.5882794857025146	train_acc:0.675	test_acc:0.69	test_f1:0.6541626557615968
epoch:27	train_loss:1.5572375059127808	train_acc:0.7166666666666667	test_acc:0.69	test_f1:0.6541626557615968
epoch:28	train_loss:1.5343540906906128	train_acc:0.8	test_acc:0.694	test_f1:0.6579960987557317
epoch:29	train_loss:1.5161844491958618	train_acc:0.7583333333333333	test_acc:0.694	test_f1:0.6579328706955891
epoch:30	train_loss:1.5230361223220825	train_acc:0.7166666666666667	test_acc:0.693	test_f1:0.6570109936152934
epoch:31	train_loss:1.507905125617981	train_acc:0.7416666666666667	test_acc:0.697	test_f1:0.6603681279087351
epoch:32	train_loss:1.5158013105392456	train_acc:0.7083333333333334	test_acc:0.698	test_f1:0.6611589978864851
epoch:33	train_loss:1.516421914100647	train_acc:0.7166666666666667	test_acc:0.698	test_f1:0.6611711463426764
epoch:34	train_loss:1.454248070716858	train_acc:0.775	test_acc:0.698	test_f1:0.6611711463426764
epoch:35	train_loss:1.488467812538147	train_acc:0.7	test_acc:0.698	test_f1:0.6612311881839569
epoch:36	train_loss:1.5016318559646606	train_acc:0.7	test_acc:0.698	test_f1:0.661332770818773
epoch:37	train_loss:1.4396843910217285	train_acc:0.7416666666666667	test_acc:0.698	test_f1:0.6612116478237716
epoch:38	train_loss:1.4900665283203125	train_acc:0.6916666666666667	test_acc:0.698	test_f1:0.6610634062484056
epoch:39	train_loss:1.4194200038909912	train_acc:0.7416666666666667	test_acc:0.7	test_f1:0.66407408852074
epoch:40	train_loss:1.3761051893234253	train_acc:0.7416666666666667	test_acc:0.7	test_f1:0.6640048439037918
epoch:41	train_loss:1.361459732055664	train_acc:0.775	test_acc:0.7	test_f1:0.663742345160742
epoch:42	train_loss:1.3890897035598755	train_acc:0.7333333333333333	test_acc:0.701	test_f1:0.6646827586249072
epoch:43	train_loss:1.3877066373825073	train_acc:0.7833333333333333	test_acc:0.701	test_f1:0.6643639353965266
epoch:44	train_loss:1.3609576225280762	train_acc:0.7416666666666667	test_acc:0.701	test_f1:0.6643639353965266
epoch:45	train_loss:1.384316325187683	train_acc:0.6916666666666667	test_acc:0.701	test_f1:0.6644725217541926
epoch:46	train_loss:1.391925573348999	train_acc:0.7333333333333333	test_acc:0.701	test_f1:0.6653578959811421
epoch:47	train_loss:1.3449008464813232	train_acc:0.7333333333333333	test_acc:0.704	test_f1:0.6690002243643223
epoch:48	train_loss:1.27562415599823	train_acc:0.7833333333333333	test_acc:0.703	test_f1:0.6671861519653516
epoch:49	train_loss:1.3554579019546509	train_acc:0.6583333333333333	test_acc:0.705	test_f1:0.6689917000815945
epoch:50	train_loss:1.2870526313781738	train_acc:0.75	test_acc:0.705	test_f1:0.6700726119280477
训练并测试结束，共训练50轮，总用时258.91962933540344s
最佳正确率为:0.705,对应的macro_f1为:0.6700726119280477,对应的训练轮次为:50



2022-07-02 00:03:28.070297
epoch:1	train_loss:1.7897323369979858	train_acc:0.175	test_acc:0.383	test_f1:0.32076449582041006
epoch:2	train_loss:1.7796252965927124	train_acc:0.2833333333333333	test_acc:0.446	test_f1:0.3877658051862179
epoch:3	train_loss:1.7780554294586182	train_acc:0.3333333333333333	test_acc:0.498	test_f1:0.45108626610432934
epoch:4	train_loss:1.768678903579712	train_acc:0.43333333333333335	test_acc:0.524	test_f1:0.4817938212655139
epoch:5	train_loss:1.7655566930770874	train_acc:0.45	test_acc:0.545	test_f1:0.511370719315326
epoch:6	train_loss:1.758168339729309	train_acc:0.475	test_acc:0.565	test_f1:0.5344171555083862
epoch:7	train_loss:1.7407797574996948	train_acc:0.5916666666666667	test_acc:0.575	test_f1:0.5458142813636326
epoch:8	train_loss:1.73874831199646	train_acc:0.65	test_acc:0.582	test_f1:0.5522926836492785
epoch:9	train_loss:1.7332690954208374	train_acc:0.5666666666666667	test_acc:0.595	test_f1:0.5661542614593852
epoch:10	train_loss:1.7178763151168823	train_acc:0.6333333333333333	test_acc:0.609	test_f1:0.5811821011061918
epoch:11	train_loss:1.7167630195617676	train_acc:0.625	test_acc:0.615	test_f1:0.585335893273491
epoch:12	train_loss:1.7118439674377441	train_acc:0.5916666666666667	test_acc:0.625	test_f1:0.5942115367661497
epoch:13	train_loss:1.6952768564224243	train_acc:0.7083333333333334	test_acc:0.628	test_f1:0.5955676342524102
epoch:14	train_loss:1.699699878692627	train_acc:0.6166666666666667	test_acc:0.633	test_f1:0.5995625608698021
epoch:15	train_loss:1.673242449760437	train_acc:0.7416666666666667	test_acc:0.64	test_f1:0.6059505987429772
epoch:16	train_loss:1.6756749153137207	train_acc:0.65	test_acc:0.645	test_f1:0.6108603370070126
epoch:17	train_loss:1.6762408018112183	train_acc:0.675	test_acc:0.651	test_f1:0.6170942686783819
epoch:18	train_loss:1.6610163450241089	train_acc:0.6583333333333333	test_acc:0.652	test_f1:0.6175460161223703
epoch:19	train_loss:1.6477530002593994	train_acc:0.7083333333333334	test_acc:0.654	test_f1:0.6192499353293954
epoch:20	train_loss:1.6408329010009766	train_acc:0.7166666666666667	test_acc:0.659	test_f1:0.6236373653482504
epoch:21	train_loss:1.635495662689209	train_acc:0.7416666666666667	test_acc:0.664	test_f1:0.6293323128564021
epoch:22	train_loss:1.6256088018417358	train_acc:0.7333333333333333	test_acc:0.666	test_f1:0.6291273196265316
epoch:23	train_loss:1.6000524759292603	train_acc:0.6833333333333333	test_acc:0.666	test_f1:0.6293759030341683
epoch:24	train_loss:1.6266130208969116	train_acc:0.6916666666666667	test_acc:0.67	test_f1:0.6329982526958237
epoch:25	train_loss:1.5857181549072266	train_acc:0.7166666666666667	test_acc:0.675	test_f1:0.6372242723652249
epoch:26	train_loss:1.5669045448303223	train_acc:0.7166666666666667	test_acc:0.674	test_f1:0.6359798677479882
epoch:27	train_loss:1.5686147212982178	train_acc:0.725	test_acc:0.677	test_f1:0.6384679867094121
epoch:28	train_loss:1.5614038705825806	train_acc:0.7166666666666667	test_acc:0.679	test_f1:0.6411017533455018
epoch:29	train_loss:1.5172866582870483	train_acc:0.7833333333333333	test_acc:0.68	test_f1:0.6419857459833774
epoch:30	train_loss:1.5269219875335693	train_acc:0.7583333333333333	test_acc:0.68	test_f1:0.6419061609629044
epoch:31	train_loss:1.520753264427185	train_acc:0.725	test_acc:0.679	test_f1:0.639766732565963
epoch:32	train_loss:1.5454427003860474	train_acc:0.7333333333333333	test_acc:0.682	test_f1:0.64248955023064
epoch:33	train_loss:1.4769407510757446	train_acc:0.7416666666666667	test_acc:0.682	test_f1:0.6423595479610289
epoch:34	train_loss:1.496109127998352	train_acc:0.775	test_acc:0.684	test_f1:0.643003349385443
epoch:35	train_loss:1.4759690761566162	train_acc:0.7833333333333333	test_acc:0.687	test_f1:0.6457463983546973
epoch:36	train_loss:1.4675548076629639	train_acc:0.7083333333333334	test_acc:0.686	test_f1:0.6449196986739548
epoch:37	train_loss:1.4697823524475098	train_acc:0.725	test_acc:0.688	test_f1:0.645255374769549
epoch:38	train_loss:1.4311847686767578	train_acc:0.7666666666666667	test_acc:0.692	test_f1:0.647953152820414
epoch:39	train_loss:1.4047602415084839	train_acc:0.725	test_acc:0.694	test_f1:0.6485663783286152
epoch:40	train_loss:1.4474546909332275	train_acc:0.725	test_acc:0.697	test_f1:0.651498507563693
epoch:41	train_loss:1.4188785552978516	train_acc:0.725	test_acc:0.699	test_f1:0.6532939021819794
epoch:42	train_loss:1.41947603225708	train_acc:0.675	test_acc:0.703	test_f1:0.658114204372709
epoch:43	train_loss:1.4451545476913452	train_acc:0.7083333333333334	test_acc:0.703	test_f1:0.658114204372709
epoch:44	train_loss:1.3957701921463013	train_acc:0.7083333333333334	test_acc:0.703	test_f1:0.6582696417271358
epoch:45	train_loss:1.3394955396652222	train_acc:0.7416666666666667	test_acc:0.704	test_f1:0.6605796774688449
epoch:46	train_loss:1.3515079021453857	train_acc:0.7583333333333333	test_acc:0.705	test_f1:0.6616096124523034
epoch:47	train_loss:1.4077705144882202	train_acc:0.7166666666666667	test_acc:0.705	test_f1:0.6615038442540585
epoch:48	train_loss:1.3466836214065552	train_acc:0.7333333333333333	test_acc:0.706	test_f1:0.6624327691338078
epoch:49	train_loss:1.3694992065429688	train_acc:0.6833333333333333	test_acc:0.705	test_f1:0.6615029360484111
epoch:50	train_loss:1.3516228199005127	train_acc:0.675	test_acc:0.704	test_f1:0.661863120652566
训练并测试结束，共训练50轮，总用时258.4583065509796s
最佳正确率为:0.706,对应的macro_f1为:0.6624327691338078,对应的训练轮次为:48



2022-07-02 00:08:03.760542
epoch:1	train_loss:1.7932754755020142	train_acc:0.175	test_acc:0.41	test_f1:0.36572638258710954
epoch:2	train_loss:1.7859723567962646	train_acc:0.2708333333333333	test_acc:0.565	test_f1:0.5006741055330259
epoch:3	train_loss:1.7809044122695923	train_acc:0.32083333333333336	test_acc:0.641	test_f1:0.5760538772493071
epoch:4	train_loss:1.77494478225708	train_acc:0.42916666666666664	test_acc:0.667	test_f1:0.597426425306309
epoch:5	train_loss:1.7668966054916382	train_acc:0.4583333333333333	test_acc:0.697	test_f1:0.6313330344087246
epoch:6	train_loss:1.7590861320495605	train_acc:0.525	test_acc:0.709	test_f1:0.6440076481972082
epoch:7	train_loss:1.7487568855285645	train_acc:0.5833333333333334	test_acc:0.716	test_f1:0.6572363073849049
epoch:8	train_loss:1.7428696155548096	train_acc:0.5958333333333333	test_acc:0.717	test_f1:0.66040260945037
epoch:9	train_loss:1.7298274040222168	train_acc:0.6583333333333333	test_acc:0.724	test_f1:0.6691889875144045
epoch:10	train_loss:1.7324217557907104	train_acc:0.5958333333333333	test_acc:0.727	test_f1:0.6762368468748875
epoch:11	train_loss:1.7200102806091309	train_acc:0.6458333333333334	test_acc:0.731	test_f1:0.679589811175814
epoch:12	train_loss:1.7191680669784546	train_acc:0.6291666666666667	test_acc:0.727	test_f1:0.6755935424316681
epoch:13	train_loss:1.7062312364578247	train_acc:0.6583333333333333	test_acc:0.726	test_f1:0.6740170944438711
epoch:14	train_loss:1.6998786926269531	train_acc:0.6708333333333333	test_acc:0.727	test_f1:0.6751018790584457
epoch:15	train_loss:1.6881568431854248	train_acc:0.625	test_acc:0.729	test_f1:0.6770170771275233
epoch:16	train_loss:1.6833544969558716	train_acc:0.6416666666666667	test_acc:0.732	test_f1:0.6817764890597026
epoch:17	train_loss:1.6754401922225952	train_acc:0.6666666666666666	test_acc:0.734	test_f1:0.6838037945612992
epoch:18	train_loss:1.6566767692565918	train_acc:0.675	test_acc:0.736	test_f1:0.6876124603760604
epoch:19	train_loss:1.6563031673431396	train_acc:0.6708333333333333	test_acc:0.733	test_f1:0.6845043215484976
epoch:20	train_loss:1.6544592380523682	train_acc:0.6791666666666667	test_acc:0.732	test_f1:0.683193669620349
epoch:21	train_loss:1.6154690980911255	train_acc:0.6875	test_acc:0.73	test_f1:0.6812003712150175
epoch:22	train_loss:1.612180471420288	train_acc:0.675	test_acc:0.73	test_f1:0.6811052867024681
epoch:23	train_loss:1.6302343606948853	train_acc:0.6708333333333333	test_acc:0.733	test_f1:0.6841276476192268
epoch:24	train_loss:1.5964001417160034	train_acc:0.7208333333333333	test_acc:0.736	test_f1:0.6874882581300571
epoch:25	train_loss:1.6039748191833496	train_acc:0.6625	test_acc:0.737	test_f1:0.690192553888885
epoch:26	train_loss:1.5869464874267578	train_acc:0.6958333333333333	test_acc:0.737	test_f1:0.6907887175234259
epoch:27	train_loss:1.5507657527923584	train_acc:0.75	test_acc:0.739	test_f1:0.6930257082658859
epoch:28	train_loss:1.5642067193984985	train_acc:0.6916666666666667	test_acc:0.741	test_f1:0.6946703294645643
epoch:29	train_loss:1.5598924160003662	train_acc:0.7166666666666667	test_acc:0.741	test_f1:0.6946703294645643
epoch:30	train_loss:1.5650967359542847	train_acc:0.6125	test_acc:0.739	test_f1:0.6928616203204001
epoch:31	train_loss:1.5623345375061035	train_acc:0.6875	test_acc:0.739	test_f1:0.6913722532794478
epoch:32	train_loss:1.5669200420379639	train_acc:0.6666666666666666	test_acc:0.74	test_f1:0.6921333395369267
epoch:33	train_loss:1.4766621589660645	train_acc:0.7291666666666666	test_acc:0.74	test_f1:0.6900500691001848
epoch:34	train_loss:1.4878528118133545	train_acc:0.7208333333333333	test_acc:0.739	test_f1:0.6890660562196174
epoch:35	train_loss:1.4755651950836182	train_acc:0.675	test_acc:0.739	test_f1:0.6890660562196174
epoch:36	train_loss:1.485404372215271	train_acc:0.7125	test_acc:0.741	test_f1:0.6908319709014119
epoch:37	train_loss:1.4451053142547607	train_acc:0.7541666666666667	test_acc:0.741	test_f1:0.6906389960885423
epoch:38	train_loss:1.4941619634628296	train_acc:0.6791666666666667	test_acc:0.741	test_f1:0.6906389960885423
epoch:39	train_loss:1.4501851797103882	train_acc:0.6916666666666667	test_acc:0.741	test_f1:0.6906389960885423
epoch:40	train_loss:1.4720638990402222	train_acc:0.7041666666666667	test_acc:0.741	test_f1:0.6906389960885423
epoch:41	train_loss:1.424215316772461	train_acc:0.7	test_acc:0.741	test_f1:0.690447845833081
epoch:42	train_loss:1.4150099754333496	train_acc:0.7041666666666667	test_acc:0.742	test_f1:0.691095594175683
epoch:43	train_loss:1.4179543256759644	train_acc:0.6875	test_acc:0.742	test_f1:0.691095594175683
epoch:44	train_loss:1.382761836051941	train_acc:0.7125	test_acc:0.742	test_f1:0.6912977687470042
epoch:45	train_loss:1.3918635845184326	train_acc:0.7125	test_acc:0.743	test_f1:0.6924447755689352
epoch:46	train_loss:1.3799315690994263	train_acc:0.7125	test_acc:0.742	test_f1:0.6915433849885035
epoch:47	train_loss:1.393241286277771	train_acc:0.7	test_acc:0.741	test_f1:0.6907015266360634
epoch:48	train_loss:1.372651219367981	train_acc:0.6916666666666667	test_acc:0.741	test_f1:0.6907179543319238
epoch:49	train_loss:1.426077961921692	train_acc:0.6375	test_acc:0.74	test_f1:0.6896550101267858
epoch:50	train_loss:1.3130563497543335	train_acc:0.7208333333333333	test_acc:0.736	test_f1:0.6860529231936804
训练并测试结束，共训练50轮，总用时259.89964723587036s
最佳正确率为:0.743,对应的macro_f1为:0.6924447755689352,对应的训练轮次为:45



2022-07-02 00:14:27.594527
epoch:1	train_loss:1.7938435077667236	train_acc:0.14583333333333334	test_acc:0.207	test_f1:0.18207631904186214
epoch:2	train_loss:1.7894760370254517	train_acc:0.16666666666666666	test_acc:0.249	test_f1:0.21975062597237485
epoch:3	train_loss:1.7918400764465332	train_acc:0.15416666666666667	test_acc:0.29	test_f1:0.2604473797435715
epoch:4	train_loss:1.789367914199829	train_acc:0.22083333333333333	test_acc:0.337	test_f1:0.30880269154171064
epoch:5	train_loss:1.7862684726715088	train_acc:0.25833333333333336	test_acc:0.378	test_f1:0.3501250256394335
epoch:6	train_loss:1.7884087562561035	train_acc:0.25	test_acc:0.432	test_f1:0.4014733262982568
epoch:7	train_loss:1.7817484140396118	train_acc:0.29583333333333334	test_acc:0.475	test_f1:0.44478767337432296
epoch:8	train_loss:1.782626986503601	train_acc:0.2916666666666667	test_acc:0.497	test_f1:0.4687094814896393
epoch:9	train_loss:1.7793726921081543	train_acc:0.31666666666666665	test_acc:0.535	test_f1:0.504681214208465
epoch:10	train_loss:1.780859351158142	train_acc:0.3375	test_acc:0.561	test_f1:0.5307567526744976
epoch:11	train_loss:1.7771055698394775	train_acc:0.44166666666666665	test_acc:0.585	test_f1:0.554650759973146
epoch:12	train_loss:1.7762454748153687	train_acc:0.42916666666666664	test_acc:0.605	test_f1:0.5731671770395964
epoch:13	train_loss:1.7758532762527466	train_acc:0.44583333333333336	test_acc:0.626	test_f1:0.5921476929333208
epoch:14	train_loss:1.7758440971374512	train_acc:0.425	test_acc:0.64	test_f1:0.6048606795461798
epoch:15	train_loss:1.772039771080017	train_acc:0.4625	test_acc:0.64	test_f1:0.6041661954585885
epoch:16	train_loss:1.772851586341858	train_acc:0.4625	test_acc:0.65	test_f1:0.6140016123501013
epoch:17	train_loss:1.7678316831588745	train_acc:0.5375	test_acc:0.66	test_f1:0.6238403082571397
epoch:18	train_loss:1.7697674036026	train_acc:0.5083333333333333	test_acc:0.662	test_f1:0.6255977717215838
epoch:19	train_loss:1.7722457647323608	train_acc:0.42083333333333334	test_acc:0.664	test_f1:0.627461947397134
epoch:20	train_loss:1.7692278623580933	train_acc:0.4625	test_acc:0.672	test_f1:0.634091190079024
epoch:21	train_loss:1.7686383724212646	train_acc:0.5	test_acc:0.68	test_f1:0.6413912007504299
epoch:22	train_loss:1.7636445760726929	train_acc:0.5208333333333334	test_acc:0.683	test_f1:0.6442109270892823
epoch:23	train_loss:1.7654200792312622	train_acc:0.5041666666666667	test_acc:0.686	test_f1:0.64578367030841
epoch:24	train_loss:1.7628651857376099	train_acc:0.5458333333333333	test_acc:0.686	test_f1:0.645483479290876
epoch:25	train_loss:1.7616103887557983	train_acc:0.575	test_acc:0.688	test_f1:0.6493834664425181
epoch:26	train_loss:1.7536084651947021	train_acc:0.5958333333333333	test_acc:0.695	test_f1:0.6564222185897506
epoch:27	train_loss:1.759059190750122	train_acc:0.5541666666666667	test_acc:0.692	test_f1:0.6507395866743094
epoch:28	train_loss:1.7540981769561768	train_acc:0.6291666666666667	test_acc:0.693	test_f1:0.6511396869471897
epoch:29	train_loss:1.7546361684799194	train_acc:0.6333333333333333	test_acc:0.695	test_f1:0.6526490124504271
epoch:30	train_loss:1.7509855031967163	train_acc:0.5875	test_acc:0.693	test_f1:0.6484453685604136
epoch:31	train_loss:1.7449485063552856	train_acc:0.6291666666666667	test_acc:0.695	test_f1:0.6501162032704565
epoch:32	train_loss:1.7463079690933228	train_acc:0.6083333333333333	test_acc:0.697	test_f1:0.6531376743562217
epoch:33	train_loss:1.7430096864700317	train_acc:0.6125	test_acc:0.698	test_f1:0.6540537173713604
epoch:34	train_loss:1.74772310256958	train_acc:0.6291666666666667	test_acc:0.7	test_f1:0.6558317376199351
epoch:35	train_loss:1.7491514682769775	train_acc:0.6166666666666667	test_acc:0.7	test_f1:0.6558919134827689
epoch:36	train_loss:1.7416495084762573	train_acc:0.6291666666666667	test_acc:0.698	test_f1:0.6538129481799707
epoch:37	train_loss:1.7404074668884277	train_acc:0.6833333333333333	test_acc:0.703	test_f1:0.6581651302813828
epoch:38	train_loss:1.7468960285186768	train_acc:0.5875	test_acc:0.703	test_f1:0.6582119507561354
epoch:39	train_loss:1.740774154663086	train_acc:0.6458333333333334	test_acc:0.701	test_f1:0.6564554777071742
epoch:40	train_loss:1.736656904220581	train_acc:0.6458333333333334	test_acc:0.701	test_f1:0.6563937693387804
epoch:41	train_loss:1.7315051555633545	train_acc:0.6625	test_acc:0.7	test_f1:0.655516147929061
epoch:42	train_loss:1.7362385988235474	train_acc:0.6791666666666667	test_acc:0.7	test_f1:0.6567440874072887
epoch:43	train_loss:1.7362064123153687	train_acc:0.6625	test_acc:0.7	test_f1:0.6557801664853845
epoch:44	train_loss:1.7370980978012085	train_acc:0.625	test_acc:0.701	test_f1:0.6565327323640008
epoch:45	train_loss:1.7382819652557373	train_acc:0.6125	test_acc:0.702	test_f1:0.6572286861862778
epoch:46	train_loss:1.7237279415130615	train_acc:0.6833333333333333	test_acc:0.704	test_f1:0.6604306856229882
epoch:47	train_loss:1.7290757894515991	train_acc:0.6791666666666667	test_acc:0.703	test_f1:0.6581997765710911
epoch:48	train_loss:1.731764554977417	train_acc:0.6458333333333334	test_acc:0.704	test_f1:0.6591552937088814
epoch:49	train_loss:1.7211717367172241	train_acc:0.6708333333333333	test_acc:0.705	test_f1:0.6602853636357512
epoch:50	train_loss:1.7215747833251953	train_acc:0.6375	test_acc:0.707	test_f1:0.662411612267692
训练并测试结束，共训练50轮，总用时261.4124844074249s
最佳正确率为:0.707,对应的macro_f1为:0.662411612267692,对应的训练轮次为:50



2022-07-02 00:19:32.755497
epoch:1	train_loss:1.7925161123275757	train_acc:0.12916666666666668	test_acc:0.244	test_f1:0.2339535742996275
epoch:2	train_loss:1.7881672382354736	train_acc:0.19583333333333333	test_acc:0.392	test_f1:0.3612904611149912
epoch:3	train_loss:1.786793828010559	train_acc:0.2791666666666667	test_acc:0.497	test_f1:0.4600619709235711
epoch:4	train_loss:1.7802183628082275	train_acc:0.3125	test_acc:0.548	test_f1:0.5134336393813121
epoch:5	train_loss:1.7767208814620972	train_acc:0.3875	test_acc:0.6	test_f1:0.5619538241466334
epoch:6	train_loss:1.7729666233062744	train_acc:0.4875	test_acc:0.634	test_f1:0.5919353503185492
epoch:7	train_loss:1.7677381038665771	train_acc:0.43333333333333335	test_acc:0.665	test_f1:0.618721400801649
epoch:8	train_loss:1.7664601802825928	train_acc:0.48333333333333334	test_acc:0.684	test_f1:0.6345991615388167
epoch:9	train_loss:1.760481357574463	train_acc:0.5458333333333333	test_acc:0.691	test_f1:0.6413953310368804
epoch:10	train_loss:1.7547165155410767	train_acc:0.5666666666666667	test_acc:0.702	test_f1:0.650342523140457
epoch:11	train_loss:1.7477511167526245	train_acc:0.5666666666666667	test_acc:0.708	test_f1:0.6554620571245925
epoch:12	train_loss:1.7480329275131226	train_acc:0.6	test_acc:0.718	test_f1:0.666632089694975
epoch:13	train_loss:1.7370880842208862	train_acc:0.6125	test_acc:0.723	test_f1:0.673022767323577
epoch:14	train_loss:1.7307583093643188	train_acc:0.6875	test_acc:0.728	test_f1:0.6792497514284533
epoch:15	train_loss:1.734755277633667	train_acc:0.6291666666666667	test_acc:0.731	test_f1:0.6837722186659616
epoch:16	train_loss:1.7324962615966797	train_acc:0.6083333333333333	test_acc:0.735	test_f1:0.6867110808470787
epoch:17	train_loss:1.719894528388977	train_acc:0.6666666666666666	test_acc:0.735	test_f1:0.6886917182023339
epoch:18	train_loss:1.7264270782470703	train_acc:0.6333333333333333	test_acc:0.736	test_f1:0.6892819571946944
epoch:19	train_loss:1.716559886932373	train_acc:0.6083333333333333	test_acc:0.735	test_f1:0.6880772929959331
epoch:20	train_loss:1.7107102870941162	train_acc:0.6291666666666667	test_acc:0.739	test_f1:0.6918020397199639
epoch:21	train_loss:1.7030906677246094	train_acc:0.6708333333333333	test_acc:0.736	test_f1:0.6889619289926489
epoch:22	train_loss:1.6951369047164917	train_acc:0.6708333333333333	test_acc:0.736	test_f1:0.6887357515978697
epoch:23	train_loss:1.687034249305725	train_acc:0.7083333333333334	test_acc:0.735	test_f1:0.6860917388021602
epoch:24	train_loss:1.695238709449768	train_acc:0.6791666666666667	test_acc:0.734	test_f1:0.6852151913319044
epoch:25	train_loss:1.680090069770813	train_acc:0.675	test_acc:0.735	test_f1:0.6879181691344064
epoch:26	train_loss:1.674235224723816	train_acc:0.6833333333333333	test_acc:0.734	test_f1:0.687057635989284
epoch:27	train_loss:1.6835548877716064	train_acc:0.6541666666666667	test_acc:0.733	test_f1:0.6859791737087376
epoch:28	train_loss:1.6700408458709717	train_acc:0.6708333333333333	test_acc:0.734	test_f1:0.686738097566499
epoch:29	train_loss:1.6646201610565186	train_acc:0.675	test_acc:0.735	test_f1:0.6873991975099599
epoch:30	train_loss:1.669013500213623	train_acc:0.6541666666666667	test_acc:0.733	test_f1:0.6852907263216395
epoch:31	train_loss:1.645706057548523	train_acc:0.7208333333333333	test_acc:0.73	test_f1:0.6823394972129134
epoch:32	train_loss:1.6523319482803345	train_acc:0.6875	test_acc:0.731	test_f1:0.6848120552423334
epoch:33	train_loss:1.6389100551605225	train_acc:0.7166666666666667	test_acc:0.731	test_f1:0.6846862959192551
epoch:34	train_loss:1.6358968019485474	train_acc:0.7083333333333334	test_acc:0.731	test_f1:0.6859388366787346
epoch:35	train_loss:1.6198331117630005	train_acc:0.6958333333333333	test_acc:0.731	test_f1:0.6857398469430561
epoch:36	train_loss:1.603224277496338	train_acc:0.725	test_acc:0.731	test_f1:0.685557265150042
epoch:37	train_loss:1.6166632175445557	train_acc:0.6791666666666667	test_acc:0.731	test_f1:0.6855946852402693
epoch:38	train_loss:1.6041232347488403	train_acc:0.7	test_acc:0.731	test_f1:0.6855946852402693
epoch:39	train_loss:1.5889370441436768	train_acc:0.7083333333333334	test_acc:0.731	test_f1:0.685162993881549
epoch:40	train_loss:1.5818885564804077	train_acc:0.7083333333333334	test_acc:0.731	test_f1:0.6850658154024872
epoch:41	train_loss:1.6040308475494385	train_acc:0.6708333333333333	test_acc:0.73	test_f1:0.6840789249461038
epoch:42	train_loss:1.6021593809127808	train_acc:0.6416666666666667	test_acc:0.73	test_f1:0.684042770398872
epoch:43	train_loss:1.5656834840774536	train_acc:0.7041666666666667	test_acc:0.73	test_f1:0.6842622535528989
epoch:44	train_loss:1.5818805694580078	train_acc:0.7	test_acc:0.728	test_f1:0.682285017738473
epoch:45	train_loss:1.5521278381347656	train_acc:0.7125	test_acc:0.729	test_f1:0.6832781163243502
epoch:46	train_loss:1.5530999898910522	train_acc:0.7	test_acc:0.73	test_f1:0.6840994030732853
epoch:47	train_loss:1.543182134628296	train_acc:0.725	test_acc:0.73	test_f1:0.6840994030732853
epoch:48	train_loss:1.537009835243225	train_acc:0.7083333333333334	test_acc:0.731	test_f1:0.6848649078794171
epoch:49	train_loss:1.5430008172988892	train_acc:0.7041666666666667	test_acc:0.731	test_f1:0.6848649078794171
epoch:50	train_loss:1.5338221788406372	train_acc:0.6666666666666666	test_acc:0.729	test_f1:0.6829983928913514
训练并测试结束，共训练50轮，总用时259.1283423900604s
最佳正确率为:0.739,对应的macro_f1为:0.6918020397199639,对应的训练轮次为:20



2022-07-02 00:24:39.395265
epoch:1	train_loss:1.7933251857757568	train_acc:0.1527777777777778	test_acc:0.322	test_f1:0.2898339944256116
epoch:2	train_loss:1.7872182130813599	train_acc:0.2222222222222222	test_acc:0.484	test_f1:0.4497538135232995
epoch:3	train_loss:1.7848784923553467	train_acc:0.3111111111111111	test_acc:0.615	test_f1:0.5751129662400202
epoch:4	train_loss:1.7829303741455078	train_acc:0.3472222222222222	test_acc:0.665	test_f1:0.6211354780452841
epoch:5	train_loss:1.7724324464797974	train_acc:0.4361111111111111	test_acc:0.677	test_f1:0.6357886193062163
epoch:6	train_loss:1.769156575202942	train_acc:0.45	test_acc:0.682	test_f1:0.6387217465078969
epoch:7	train_loss:1.7675576210021973	train_acc:0.4583333333333333	test_acc:0.686	test_f1:0.6449357782197386
epoch:8	train_loss:1.7641048431396484	train_acc:0.5472222222222223	test_acc:0.688	test_f1:0.652139517463413
epoch:9	train_loss:1.7569941282272339	train_acc:0.5777777777777777	test_acc:0.691	test_f1:0.6558217256136551
epoch:10	train_loss:1.7557944059371948	train_acc:0.5194444444444445	test_acc:0.697	test_f1:0.6622131502416148
epoch:11	train_loss:1.7521477937698364	train_acc:0.6	test_acc:0.701	test_f1:0.665517150097712
epoch:12	train_loss:1.7444326877593994	train_acc:0.5861111111111111	test_acc:0.7	test_f1:0.6650779809879771
epoch:13	train_loss:1.7469979524612427	train_acc:0.5666666666666667	test_acc:0.705	test_f1:0.6699233899214967
epoch:14	train_loss:1.7343804836273193	train_acc:0.5861111111111111	test_acc:0.709	test_f1:0.6735961655767132
epoch:15	train_loss:1.7236263751983643	train_acc:0.6722222222222223	test_acc:0.708	test_f1:0.6727043030835183
epoch:16	train_loss:1.7243990898132324	train_acc:0.6138888888888889	test_acc:0.714	test_f1:0.679261564551897
epoch:17	train_loss:1.7211054563522339	train_acc:0.6194444444444445	test_acc:0.712	test_f1:0.6782822930888979
epoch:18	train_loss:1.7166141271591187	train_acc:0.6638888888888889	test_acc:0.716	test_f1:0.6821781083386714
epoch:19	train_loss:1.7148940563201904	train_acc:0.6444444444444445	test_acc:0.721	test_f1:0.6866977619165598
epoch:20	train_loss:1.7057390213012695	train_acc:0.6444444444444445	test_acc:0.721	test_f1:0.686752442214452
epoch:21	train_loss:1.699275255203247	train_acc:0.6361111111111111	test_acc:0.721	test_f1:0.687721433230359
epoch:22	train_loss:1.7021965980529785	train_acc:0.6305555555555555	test_acc:0.722	test_f1:0.688615655018317
epoch:23	train_loss:1.693313717842102	train_acc:0.6527777777777778	test_acc:0.723	test_f1:0.6897033642996188
epoch:24	train_loss:1.6944471597671509	train_acc:0.6583333333333333	test_acc:0.724	test_f1:0.6907365223689635
epoch:25	train_loss:1.6745827198028564	train_acc:0.6666666666666666	test_acc:0.727	test_f1:0.6936882315190015
epoch:26	train_loss:1.67074453830719	train_acc:0.65	test_acc:0.725	test_f1:0.6907927385279771
epoch:27	train_loss:1.6646060943603516	train_acc:0.6694444444444444	test_acc:0.725	test_f1:0.6908111362864257
epoch:28	train_loss:1.6587649583816528	train_acc:0.6777777777777778	test_acc:0.725	test_f1:0.6909455741648377
epoch:29	train_loss:1.6517345905303955	train_acc:0.6861111111111111	test_acc:0.727	test_f1:0.693130000152971
epoch:30	train_loss:1.6475560665130615	train_acc:0.6527777777777778	test_acc:0.729	test_f1:0.695417113382072
epoch:31	train_loss:1.6464338302612305	train_acc:0.675	test_acc:0.731	test_f1:0.6962207669970449
epoch:32	train_loss:1.638736605644226	train_acc:0.6944444444444444	test_acc:0.731	test_f1:0.6949975480491354
epoch:33	train_loss:1.6195107698440552	train_acc:0.6805555555555556	test_acc:0.732	test_f1:0.6958416910317923
epoch:34	train_loss:1.6217987537384033	train_acc:0.7027777777777777	test_acc:0.732	test_f1:0.6958416910317923
epoch:35	train_loss:1.6338857412338257	train_acc:0.6444444444444445	test_acc:0.732	test_f1:0.6958416910317923
epoch:36	train_loss:1.6332534551620483	train_acc:0.6444444444444445	test_acc:0.731	test_f1:0.6948529632451192
epoch:37	train_loss:1.6187769174575806	train_acc:0.6583333333333333	test_acc:0.732	test_f1:0.6970097477362974
epoch:38	train_loss:1.6203533411026	train_acc:0.6611111111111111	test_acc:0.731	test_f1:0.6959800710547989
epoch:39	train_loss:1.5816179513931274	train_acc:0.7027777777777777	test_acc:0.73	test_f1:0.6949822096749564
epoch:40	train_loss:1.5972915887832642	train_acc:0.6777777777777778	test_acc:0.729	test_f1:0.6939876852774165
epoch:41	train_loss:1.5888447761535645	train_acc:0.6805555555555556	test_acc:0.729	test_f1:0.693875859521175
epoch:42	train_loss:1.5726534128189087	train_acc:0.6833333333333333	test_acc:0.729	test_f1:0.6938466870076545
epoch:43	train_loss:1.5934845209121704	train_acc:0.6388888888888888	test_acc:0.729	test_f1:0.6938214604684595
epoch:44	train_loss:1.5667763948440552	train_acc:0.675	test_acc:0.729	test_f1:0.6938214604684595
epoch:45	train_loss:1.5703262090682983	train_acc:0.6472222222222223	test_acc:0.729	test_f1:0.6938214604684595
epoch:46	train_loss:1.560750126838684	train_acc:0.6638888888888889	test_acc:0.73	test_f1:0.6949242933682215
epoch:47	train_loss:1.5358113050460815	train_acc:0.6888888888888889	test_acc:0.73	test_f1:0.6949242933682215
epoch:48	train_loss:1.5203527212142944	train_acc:0.7	test_acc:0.73	test_f1:0.6949242933682215
epoch:49	train_loss:1.5440858602523804	train_acc:0.6694444444444444	test_acc:0.73	test_f1:0.6949242933682215
epoch:50	train_loss:1.520079493522644	train_acc:0.7083333333333334	test_acc:0.729	test_f1:0.6927374970155568
训练并测试结束，共训练50轮，总用时257.997074842453s
最佳正确率为:0.732,对应的macro_f1为:0.6970097477362974,对应的训练轮次为:37



2022-07-02 00:29:35.233680
epoch:1	train_loss:1.791203498840332	train_acc:0.15833333333333333	test_acc:0.291	test_f1:0.2783262937715992
epoch:2	train_loss:1.7881646156311035	train_acc:0.20833333333333334	test_acc:0.486	test_f1:0.4593518872947242
epoch:3	train_loss:1.7854883670806885	train_acc:0.25833333333333336	test_acc:0.565	test_f1:0.5315666217724296
epoch:4	train_loss:1.7799420356750488	train_acc:0.375	test_acc:0.623	test_f1:0.5813339513990193
epoch:5	train_loss:1.7792624235153198	train_acc:0.38333333333333336	test_acc:0.66	test_f1:0.6142708193303731
epoch:6	train_loss:1.7747581005096436	train_acc:0.41388888888888886	test_acc:0.678	test_f1:0.632047163877137
epoch:7	train_loss:1.7697789669036865	train_acc:0.4888888888888889	test_acc:0.699	test_f1:0.656739357544276
epoch:8	train_loss:1.7659144401550293	train_acc:0.5305555555555556	test_acc:0.698	test_f1:0.6537317799534137
epoch:9	train_loss:1.7621126174926758	train_acc:0.5444444444444444	test_acc:0.707	test_f1:0.6654849660952464
epoch:10	train_loss:1.7567037343978882	train_acc:0.5527777777777778	test_acc:0.712	test_f1:0.6712643475114425
epoch:11	train_loss:1.7551161050796509	train_acc:0.5777777777777777	test_acc:0.714	test_f1:0.6729044373297192
epoch:12	train_loss:1.7494945526123047	train_acc:0.5805555555555556	test_acc:0.716	test_f1:0.6761404684082262
epoch:13	train_loss:1.7478398084640503	train_acc:0.6111111111111112	test_acc:0.717	test_f1:0.6786013932836036
epoch:14	train_loss:1.7410439252853394	train_acc:0.5916666666666667	test_acc:0.718	test_f1:0.6793766717117825
epoch:15	train_loss:1.7349414825439453	train_acc:0.6472222222222223	test_acc:0.725	test_f1:0.686336876530202
epoch:16	train_loss:1.7318685054779053	train_acc:0.6111111111111112	test_acc:0.726	test_f1:0.6868515592065357
epoch:17	train_loss:1.7326436042785645	train_acc:0.5972222222222222	test_acc:0.728	test_f1:0.6932349189213317
epoch:18	train_loss:1.7265713214874268	train_acc:0.6305555555555555	test_acc:0.729	test_f1:0.6942788791292712
epoch:19	train_loss:1.7229336500167847	train_acc:0.625	test_acc:0.734	test_f1:0.6984245246217363
epoch:20	train_loss:1.7187930345535278	train_acc:0.6194444444444445	test_acc:0.733	test_f1:0.6984341474387138
epoch:21	train_loss:1.7154935598373413	train_acc:0.6472222222222223	test_acc:0.733	test_f1:0.6983417839581246
epoch:22	train_loss:1.7050691843032837	train_acc:0.6583333333333333	test_acc:0.734	test_f1:0.6993083486691537
epoch:23	train_loss:1.696988582611084	train_acc:0.6638888888888889	test_acc:0.736	test_f1:0.7012321814161626
epoch:24	train_loss:1.7024953365325928	train_acc:0.6555555555555556	test_acc:0.737	test_f1:0.702032830799693
epoch:25	train_loss:1.6978586912155151	train_acc:0.6555555555555556	test_acc:0.736	test_f1:0.7009226837950076
epoch:26	train_loss:1.6763578653335571	train_acc:0.6833333333333333	test_acc:0.737	test_f1:0.7018768475035028
epoch:27	train_loss:1.6809958219528198	train_acc:0.675	test_acc:0.737	test_f1:0.7005721935247194
epoch:28	train_loss:1.6765024662017822	train_acc:0.6555555555555556	test_acc:0.739	test_f1:0.702405048581685
epoch:29	train_loss:1.6670680046081543	train_acc:0.6555555555555556	test_acc:0.739	test_f1:0.7025105790103715
epoch:30	train_loss:1.6709951162338257	train_acc:0.6694444444444444	test_acc:0.742	test_f1:0.70675445783788
epoch:31	train_loss:1.6597039699554443	train_acc:0.6583333333333333	test_acc:0.741	test_f1:0.705801094847426
epoch:32	train_loss:1.654301643371582	train_acc:0.6472222222222223	test_acc:0.739	test_f1:0.7037821871502775
epoch:33	train_loss:1.652276635169983	train_acc:0.6444444444444445	test_acc:0.737	test_f1:0.7017331830245107
epoch:34	train_loss:1.645848274230957	train_acc:0.7111111111111111	test_acc:0.739	test_f1:0.7049174187610636
epoch:35	train_loss:1.6403319835662842	train_acc:0.6638888888888889	test_acc:0.739	test_f1:0.7049174187610636
epoch:36	train_loss:1.6486433744430542	train_acc:0.6222222222222222	test_acc:0.739	test_f1:0.7052035157116187
epoch:37	train_loss:1.6215016841888428	train_acc:0.6777777777777778	test_acc:0.739	test_f1:0.7052035157116187
epoch:38	train_loss:1.6072331666946411	train_acc:0.7111111111111111	test_acc:0.739	test_f1:0.705033354396691
epoch:39	train_loss:1.6387823820114136	train_acc:0.6166666666666667	test_acc:0.741	test_f1:0.7072133113497667
epoch:40	train_loss:1.6124862432479858	train_acc:0.675	test_acc:0.741	test_f1:0.7072133113497667
epoch:41	train_loss:1.6055799722671509	train_acc:0.6944444444444444	test_acc:0.745	test_f1:0.7106434508738984
epoch:42	train_loss:1.5999394655227661	train_acc:0.6694444444444444	test_acc:0.746	test_f1:0.7116525426106121
epoch:43	train_loss:1.5947988033294678	train_acc:0.6777777777777778	test_acc:0.749	test_f1:0.7143611521504374
epoch:44	train_loss:1.5889309644699097	train_acc:0.7055555555555556	test_acc:0.749	test_f1:0.7143611521504374
epoch:45	train_loss:1.571941614151001	train_acc:0.6388888888888888	test_acc:0.749	test_f1:0.7143611521504374
epoch:46	train_loss:1.584227442741394	train_acc:0.6861111111111111	test_acc:0.75	test_f1:0.7153644558022759
epoch:47	train_loss:1.5933359861373901	train_acc:0.6777777777777778	test_acc:0.751	test_f1:0.7163737654027652
epoch:48	train_loss:1.5642977952957153	train_acc:0.7027777777777777	test_acc:0.751	test_f1:0.7164536239445907
epoch:49	train_loss:1.5632541179656982	train_acc:0.6805555555555556	test_acc:0.751	test_f1:0.7164536239445907
epoch:50	train_loss:1.5568366050720215	train_acc:0.6805555555555556	test_acc:0.752	test_f1:0.7174489138634906
训练并测试结束，共训练50轮，总用时258.88373923301697s
最佳正确率为:0.752,对应的macro_f1为:0.7174489138634906,对应的训练轮次为:50



2022-07-02 00:34:22.449572
epoch:1	train_loss:1.7928603887557983	train_acc:0.14444444444444443	test_acc:0.204	test_f1:0.20247717570363766
epoch:2	train_loss:1.7890264987945557	train_acc:0.19444444444444445	test_acc:0.362	test_f1:0.33906772882802066
epoch:3	train_loss:1.7891043424606323	train_acc:0.25555555555555554	test_acc:0.462	test_f1:0.43308616730320537
epoch:4	train_loss:1.7836689949035645	train_acc:0.3	test_acc:0.544	test_f1:0.5087428124175587
epoch:5	train_loss:1.7814021110534668	train_acc:0.33055555555555555	test_acc:0.601	test_f1:0.5654078830309961
epoch:6	train_loss:1.7780556678771973	train_acc:0.37222222222222223	test_acc:0.642	test_f1:0.6011067108137974
epoch:7	train_loss:1.7757587432861328	train_acc:0.43333333333333335	test_acc:0.654	test_f1:0.6120524478052122
epoch:8	train_loss:1.7696713209152222	train_acc:0.46944444444444444	test_acc:0.669	test_f1:0.6281264722269115
epoch:9	train_loss:1.7692606449127197	train_acc:0.4861111111111111	test_acc:0.681	test_f1:0.6400738203916103
epoch:10	train_loss:1.7643389701843262	train_acc:0.5166666666666667	test_acc:0.69	test_f1:0.6498239288388213
epoch:11	train_loss:1.7628839015960693	train_acc:0.5416666666666666	test_acc:0.699	test_f1:0.6576816342690072
epoch:12	train_loss:1.7594553232192993	train_acc:0.5277777777777778	test_acc:0.705	test_f1:0.6637060211428102
epoch:13	train_loss:1.754433035850525	train_acc:0.5805555555555556	test_acc:0.705	test_f1:0.6637332468721707
epoch:14	train_loss:1.7555261850357056	train_acc:0.5333333333333333	test_acc:0.71	test_f1:0.6682606793417277
epoch:15	train_loss:1.7510623931884766	train_acc:0.6055555555555555	test_acc:0.713	test_f1:0.6705175376543685
epoch:16	train_loss:1.7496446371078491	train_acc:0.55	test_acc:0.723	test_f1:0.680332409466795
epoch:17	train_loss:1.7477279901504517	train_acc:0.5305555555555556	test_acc:0.722	test_f1:0.6804632489244803
epoch:18	train_loss:1.7416064739227295	train_acc:0.6222222222222222	test_acc:0.722	test_f1:0.6803228691081716
epoch:19	train_loss:1.7386194467544556	train_acc:0.6027777777777777	test_acc:0.723	test_f1:0.6807561487442909
epoch:20	train_loss:1.7360855340957642	train_acc:0.5972222222222222	test_acc:0.725	test_f1:0.6820464209427594
epoch:21	train_loss:1.7277406454086304	train_acc:0.6305555555555555	test_acc:0.726	test_f1:0.6834068068022199
epoch:22	train_loss:1.72902250289917	train_acc:0.6083333333333333	test_acc:0.725	test_f1:0.6817890710072488
epoch:23	train_loss:1.726935863494873	train_acc:0.6472222222222223	test_acc:0.725	test_f1:0.683376034082335
epoch:24	train_loss:1.7293174266815186	train_acc:0.5944444444444444	test_acc:0.727	test_f1:0.68664125501415
epoch:25	train_loss:1.7175153493881226	train_acc:0.6666666666666666	test_acc:0.726	test_f1:0.6854364853407295
epoch:26	train_loss:1.711502194404602	train_acc:0.6416666666666667	test_acc:0.725	test_f1:0.6859708725316183
epoch:27	train_loss:1.7142317295074463	train_acc:0.6638888888888889	test_acc:0.725	test_f1:0.6857884002276307
epoch:28	train_loss:1.7059152126312256	train_acc:0.6611111111111111	test_acc:0.726	test_f1:0.6866876308498745
epoch:29	train_loss:1.70027494430542	train_acc:0.6777777777777778	test_acc:0.727	test_f1:0.6876273307480981
epoch:30	train_loss:1.7103091478347778	train_acc:0.6416666666666667	test_acc:0.73	test_f1:0.6903313327472596
epoch:31	train_loss:1.6962991952896118	train_acc:0.6361111111111111	test_acc:0.733	test_f1:0.694355865918852
epoch:32	train_loss:1.6939680576324463	train_acc:0.6416666666666667	test_acc:0.734	test_f1:0.6950898633171575
epoch:33	train_loss:1.6928412914276123	train_acc:0.6416666666666667	test_acc:0.735	test_f1:0.6962297621548702
epoch:34	train_loss:1.6927237510681152	train_acc:0.6583333333333333	test_acc:0.737	test_f1:0.699715328335941
epoch:35	train_loss:1.6860229969024658	train_acc:0.6666666666666666	test_acc:0.739	test_f1:0.7016311158925497
epoch:36	train_loss:1.6853891611099243	train_acc:0.6166666666666667	test_acc:0.739	test_f1:0.7016131515926537
epoch:37	train_loss:1.677480697631836	train_acc:0.6861111111111111	test_acc:0.74	test_f1:0.7029266486581601
epoch:38	train_loss:1.6716363430023193	train_acc:0.6694444444444444	test_acc:0.739	test_f1:0.7019568894715044
epoch:39	train_loss:1.652881145477295	train_acc:0.6861111111111111	test_acc:0.738	test_f1:0.7011596679721842
epoch:40	train_loss:1.6697344779968262	train_acc:0.65	test_acc:0.738	test_f1:0.7011596679721842
epoch:41	train_loss:1.6590462923049927	train_acc:0.6583333333333333	test_acc:0.74	test_f1:0.7031763509671279
epoch:42	train_loss:1.6436710357666016	train_acc:0.6861111111111111	test_acc:0.742	test_f1:0.7049975788578692
epoch:43	train_loss:1.6467386484146118	train_acc:0.6611111111111111	test_acc:0.741	test_f1:0.7040428310031199
epoch:44	train_loss:1.6410478353500366	train_acc:0.7083333333333334	test_acc:0.741	test_f1:0.704099054689194
epoch:45	train_loss:1.6528148651123047	train_acc:0.6555555555555556	test_acc:0.741	test_f1:0.7041509664063018
epoch:46	train_loss:1.6386377811431885	train_acc:0.6805555555555556	test_acc:0.742	test_f1:0.7051013239972512
epoch:47	train_loss:1.6377872228622437	train_acc:0.6694444444444444	test_acc:0.742	test_f1:0.7051013239972512
epoch:48	train_loss:1.645108938217163	train_acc:0.6138888888888889	test_acc:0.741	test_f1:0.7039383161947068
epoch:49	train_loss:1.6165391206741333	train_acc:0.7138888888888889	test_acc:0.741	test_f1:0.7034357646567398
epoch:50	train_loss:1.6390248537063599	train_acc:0.6416666666666667	test_acc:0.741	test_f1:0.7034357646567398
训练并测试结束，共训练50轮，总用时262.2900483608246s
最佳正确率为:0.742,对应的macro_f1为:0.7051013239972512,对应的训练轮次为:47



